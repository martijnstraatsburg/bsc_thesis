{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7581792318634424,
        "std": 0.0900686256279583
      },
      "micro_precision": {
        "mean": 0.7581792318634424,
        "std": 0.0900686256279583
      },
      "micro_recall": {
        "mean": 0.7581792318634424,
        "std": 0.0900686256279583
      },
      "micro_f1": {
        "mean": 0.7581792318634424,
        "std": 0.0900686256279583
      },
      "macro_precision": {
        "mean": 0.7779012681529844,
        "std": 0.05874457398061138
      },
      "macro_recall": {
        "mean": 0.7732740086000957,
        "std": 0.0673880333766127
      },
      "macro_f1": {
        "mean": 0.7484244610887834,
        "std": 0.0873371793743411
      },
      "weighted_precision": {
        "mean": 0.8093114903641221,
        "std": 0.05377441967964306
      },
      "weighted_recall": {
        "mean": 0.7581792318634424,
        "std": 0.0900686256279583
      },
      "weighted_f1": {
        "mean": 0.7562389490523156,
        "std": 0.0931837239040155
      },
      "mcc": {
        "mean": 0.5505694966452257,
        "std": 0.12398140291721549
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3331436699857753,
          "std": 0.0997657152458899
        },
        "off_by_one_accuracy": {
          "mean": 0.8172119487908962,
          "std": 0.04642589168901605
        },
        "level_accuracy": {
          "mean": 0.5968705547652916,
          "std": 0.07381864634421308
        },
        "rmse": {
          "mean": 1.181203929088722,
          "std": 0.1883686285180598
        },
        "mae": {
          "mean": 0.8927453769559033,
          "std": 0.18622714660227294
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3185858116176985,
          "std": 0.17367749515753256
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2689900426742532,
          "std": 0.08243780182493823
        },
        "off_by_one_accuracy": {
          "mean": 0.7425320056899005,
          "std": 0.0855237650554299
        },
        "level_accuracy": {
          "mean": 0.5219061166429587,
          "std": 0.05338433661495073
        },
        "rmse": {
          "mean": 1.4071139524373792,
          "std": 0.1846965847335696
        },
        "mae": {
          "mean": 1.0906116642958747,
          "std": 0.19133617429783764
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3421865996126221,
          "std": 0.10667502353330352
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.23598862019914651,
          "std": 0.08883627523793519
        },
        "off_by_one_accuracy": {
          "mean": 0.7311522048364154,
          "std": 0.07456266616146381
        },
        "level_accuracy": {
          "mean": 0.6018492176386914,
          "std": 0.05145822130612529
        },
        "rmse": {
          "mean": 1.3982073632811112,
          "std": 0.13465284902342176
        },
        "mae": {
          "mean": 1.113371266002845,
          "std": 0.16527152993674868
        },
        "quadratic_weighted_kappa": {
          "mean": 0.26144058752321964,
          "std": 0.12067895223082888
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6216216216216216,
        "micro_precision": 0.6216216216216216,
        "micro_recall": 0.6216216216216216,
        "micro_f1": 0.6216216216216216,
        "macro_precision": 0.7407407407407407,
        "macro_recall": 0.7083333333333334,
        "macro_f1": 0.6191176470588236,
        "weighted_precision": 0.8178178178178178,
        "weighted_recall": 0.6216216216216216,
        "weighted_f1": 0.6099364069952306,
        "mcc": 0.44790320823880836
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.7837837837837838,
          "level_accuracy": 0.7027027027027027,
          "rmse": 1.3355836865519823,
          "mae": 1.027027027027027,
          "quadratic_weighted_kappa": 0.2787950383933846
        },
        "curiosity": {
          "perfect_accuracy": 0.13513513513513514,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.62746694241347,
          "mae": 1.3513513513513513,
          "quadratic_weighted_kappa": 0.2148116067561716
        },
        "surprise": {
          "perfect_accuracy": 0.13513513513513514,
          "off_by_one_accuracy": 0.6216216216216216,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.5509369443679537,
          "mae": 1.3243243243243243,
          "quadratic_weighted_kappa": 0.08856905618599487
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.8129370629370629,
        "macro_recall": 0.7779503105590062,
        "macro_f1": 0.7885714285714287,
        "weighted_precision": 0.8116613116613117,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8052509652509653,
        "mcc": 0.5898506720476968
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.065427207806866,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.27450980392156854
        },
        "curiosity": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.1028219331407116,
          "mae": 0.8378378378378378,
          "quadratic_weighted_kappa": 0.4606413994169096
        },
        "surprise": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.2627725822944504,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.3049984081502707
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7368421052631579,
        "micro_precision": 0.7368421052631579,
        "micro_recall": 0.7368421052631579,
        "micro_f1": 0.7368421052631579,
        "macro_precision": 0.7246376811594203,
        "macro_recall": 0.7246376811594203,
        "macro_f1": 0.7246376811594203,
        "weighted_precision": 0.7368421052631579,
        "weighted_recall": 0.7368421052631579,
        "weighted_f1": 0.7368421052631579,
        "mcc": 0.4492753623188406
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3684210526315789,
          "off_by_one_accuracy": 0.8157894736842105,
          "level_accuracy": 0.5789473684210527,
          "rmse": 1.1470786693528088,
          "mae": 0.8421052631578947,
          "quadratic_weighted_kappa": 0.35064935064935066
        },
        "curiosity": {
          "perfect_accuracy": 0.23684210526315788,
          "off_by_one_accuracy": 0.631578947368421,
          "level_accuracy": 0.4473684210526316,
          "rmse": 1.5474937292620166,
          "mae": 1.236842105263158,
          "quadratic_weighted_kappa": 0.23393885688967653
        },
        "surprise": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.7368421052631579,
          "level_accuracy": 0.6578947368421053,
          "rmse": 1.404878717372541,
          "mae": 1.0263157894736843,
          "quadratic_weighted_kappa": 0.2566510172143974
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "micro_precision": 0.7297297297297297,
        "micro_recall": 0.7297297297297297,
        "micro_f1": 0.7297297297297297,
        "macro_precision": 0.7339181286549707,
        "macro_recall": 0.7564102564102564,
        "macro_f1": 0.7247023809523809,
        "weighted_precision": 0.7799905168326221,
        "weighted_recall": 0.7297297297297297,
        "weighted_f1": 0.7357625482625483,
        "mcc": 0.48981223891376335
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.1891891891891892,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.4425952589278397,
          "mae": 1.162162162162162,
          "quadratic_weighted_kappa": 0.07530022719896146
        },
        "curiosity": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.7297297297297297,
          "level_accuracy": 0.5135135135135135,
          "rmse": 1.4425952589278397,
          "mae": 1.1081081081081081,
          "quadratic_weighted_kappa": 0.33728774133519424
        },
        "surprise": {
          "perfect_accuracy": 0.13513513513513514,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.5421992019121196,
          "mae": 1.2972972972972974,
          "quadratic_weighted_kappa": 0.20196078431372555
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8918918918918919,
        "micro_precision": 0.8918918918918919,
        "micro_recall": 0.8918918918918919,
        "micro_f1": 0.8918918918918919,
        "macro_precision": 0.8772727272727273,
        "macro_recall": 0.8990384615384616,
        "macro_f1": 0.8850931677018633,
        "weighted_precision": 0.9002457002457003,
        "weighted_recall": 0.8918918918918919,
        "weighted_f1": 0.8934027194896761,
        "mcc": 0.7760060017070195
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4864864864864865,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.6486486486486487,
          "rmse": 0.9153348228041135,
          "mae": 0.6216216216216216,
          "quadratic_weighted_kappa": 0.6136746379252274
        },
        "curiosity": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.3151918984428583,
          "mae": 0.918918918918919,
          "quadratic_weighted_kappa": 0.4642533936651584
        },
        "surprise": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.6486486486486487,
          "rmse": 1.2302493704584911,
          "mae": 0.918918918918919,
          "quadratic_weighted_kappa": 0.45502367175170966
        }
      }
    }
  ]
}