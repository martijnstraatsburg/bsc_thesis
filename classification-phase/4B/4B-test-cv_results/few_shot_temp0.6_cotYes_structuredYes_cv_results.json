{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8334281650071123,
        "std": 0.07102753092533746
      },
      "micro_precision": {
        "mean": 0.8334281650071123,
        "std": 0.07102753092533746
      },
      "micro_recall": {
        "mean": 0.8334281650071123,
        "std": 0.07102753092533746
      },
      "micro_f1": {
        "mean": 0.8334281650071123,
        "std": 0.07102753092533748
      },
      "macro_precision": {
        "mean": 0.8387508725700945,
        "std": 0.052981053541265734
      },
      "macro_recall": {
        "mean": 0.8479686255773211,
        "std": 0.0579561109184962
      },
      "macro_f1": {
        "mean": 0.8277901752253968,
        "std": 0.06925767108805232
      },
      "weighted_precision": {
        "mean": 0.8657505520915132,
        "std": 0.046008111573241535
      },
      "weighted_recall": {
        "mean": 0.8334281650071123,
        "std": 0.07102753092533746
      },
      "weighted_f1": {
        "mean": 0.834453813602088,
        "std": 0.0703592213260649
      },
      "mcc": {
        "mean": 0.6865431313215847,
        "std": 0.11014949525512678
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4135135135135135,
          "std": 0.11830307366615833
        },
        "off_by_one_accuracy": {
          "mean": 0.8763869132290184,
          "std": 0.03647865232735207
        },
        "level_accuracy": {
          "mean": 0.6018492176386914,
          "std": 0.0746310210279128
        },
        "rmse": {
          "mean": 1.0342970234374165,
          "std": 0.14825421305893302
        },
        "mae": {
          "mean": 0.7369843527738265,
          "std": 0.1606706884978998
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4767881929230412,
          "std": 0.15349384459777268
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.31721194879089615,
          "std": 0.06917383972883817
        },
        "off_by_one_accuracy": {
          "mean": 0.8442389758179232,
          "std": 0.06439587384670029
        },
        "level_accuracy": {
          "mean": 0.5270270270270271,
          "std": 0.056692370171359543
        },
        "rmse": {
          "mean": 1.1351748245464832,
          "std": 0.1513280082470353
        },
        "mae": {
          "mean": 0.8708392603129445,
          "std": 0.14653399315358157
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4876931666696579,
          "std": 0.1256838561531076
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.2951635846372688,
          "std": 0.06039407838992421
        },
        "off_by_one_accuracy": {
          "mean": 0.8388335704125177,
          "std": 0.02311948751511813
        },
        "level_accuracy": {
          "mean": 0.5590327169274538,
          "std": 0.02318241682783882
        },
        "rmse": {
          "mean": 1.1935010583466519,
          "std": 0.07071391966094387
        },
        "mae": {
          "mean": 0.9142247510668564,
          "std": 0.051762459928508246
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3903432231325541,
          "std": 0.11700460112137133
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "micro_precision": 0.7297297297297297,
        "micro_recall": 0.7297297297297297,
        "micro_f1": 0.7297297297297297,
        "macro_precision": 0.7826086956521738,
        "macro_recall": 0.7916666666666667,
        "macro_f1": 0.72953216374269,
        "weighted_precision": 0.8472385428907169,
        "weighted_recall": 0.7297297297297297,
        "weighted_f1": 0.7317053896001264,
        "mcc": 0.5742039227726821
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.6756756756756757,
          "rmse": 1.138989594902999,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.421875
        },
        "curiosity": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.7837837837837838,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.30487650860252,
          "mae": 1.054054054054054,
          "quadratic_weighted_kappa": 0.3921773142112125
        },
        "surprise": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.2192155209340498,
          "mae": 0.9459459459459459,
          "quadratic_weighted_kappa": 0.40928882438316405
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.814327485380117,
        "macro_recall": 0.8338509316770186,
        "macro_f1": 0.8085735402808574,
        "weighted_precision": 0.8459775565038723,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8136073989732526,
        "mcc": 0.6478843225324918
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.138989594902999,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.3142857142857143
        },
        "curiosity": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.7837837837837838,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.283997137321049,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.322018624211475
        },
        "surprise": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.2627725822944504,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.1947620804131317
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8157894736842105,
        "micro_precision": 0.8157894736842105,
        "micro_recall": 0.8157894736842105,
        "micro_f1": 0.8157894736842104,
        "macro_precision": 0.8068181818181819,
        "macro_recall": 0.8130434782608695,
        "macro_f1": 0.8093189964157707,
        "weighted_precision": 0.81877990430622,
        "weighted_recall": 0.8157894736842105,
        "weighted_f1": 0.8167138275797019,
        "mcc": 0.6198303988351637
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.6578947368421053,
          "rmse": 1.0130724502589556,
          "mae": 0.6578947368421053,
          "quadratic_weighted_kappa": 0.48
        },
        "curiosity": {
          "perfect_accuracy": 0.3157894736842105,
          "off_by_one_accuracy": 0.8157894736842105,
          "level_accuracy": 0.5,
          "rmse": 1.1697953037312037,
          "mae": 0.8947368421052632,
          "quadratic_weighted_kappa": 0.46420824295010843
        },
        "surprise": {
          "perfect_accuracy": 0.39473684210526316,
          "off_by_one_accuracy": 0.8157894736842105,
          "level_accuracy": 0.5789473684210527,
          "rmse": 1.2460463791317595,
          "mae": 0.868421052631579,
          "quadratic_weighted_kappa": 0.3355068168346176
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "micro_precision": 0.8648648648648649,
        "micro_recall": 0.8648648648648649,
        "micro_f1": 0.8648648648648649,
        "macro_precision": 0.8566666666666667,
        "macro_recall": 0.842948717948718,
        "macro_f1": 0.8489795918367347,
        "weighted_precision": 0.8636036036036036,
        "weighted_recall": 0.8648648648648649,
        "weighted_f1": 0.8635410921125207,
        "mcc": 0.6994808819928564
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.1270626736212455,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.40302094061105387
        },
        "curiosity": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5945945945945946,
          "rmse": 0.9586025865388216,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.604153555695406
        },
        "surprise": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.065427207806866,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.5107052896725441
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.9459459459459459,
        "micro_precision": 0.9459459459459459,
        "micro_recall": 0.9459459459459459,
        "micro_f1": 0.9459459459459459,
        "macro_precision": 0.9333333333333333,
        "macro_recall": 0.9583333333333333,
        "macro_f1": 0.9425465838509317,
        "weighted_precision": 0.9531531531531531,
        "weighted_recall": 0.9459459459459459,
        "weighted_f1": 0.946701359744838,
        "mcc": 0.8913161304747292
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5945945945945946,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.6486486486486487,
          "rmse": 0.753370803500884,
          "mae": 0.4594594594594595,
          "quadratic_weighted_kappa": 0.7647593097184378
        },
        "curiosity": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.5945945945945946,
          "rmse": 0.9586025865388216,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.6559080962800875
        },
        "surprise": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.1740436015661335,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.5014531043593131
        }
      }
    }
  ]
}