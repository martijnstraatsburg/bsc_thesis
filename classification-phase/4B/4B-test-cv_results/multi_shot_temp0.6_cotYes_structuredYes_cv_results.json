{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.80099573257468,
        "std": 0.0777463005637251
      },
      "micro_precision": {
        "mean": 0.80099573257468,
        "std": 0.0777463005637251
      },
      "micro_recall": {
        "mean": 0.80099573257468,
        "std": 0.0777463005637251
      },
      "micro_f1": {
        "mean": 0.80099573257468,
        "std": 0.0777463005637251
      },
      "macro_precision": {
        "mean": 0.7937188995215311,
        "std": 0.07208029871308988
      },
      "macro_recall": {
        "mean": 0.8058898709985666,
        "std": 0.07714770552636491
      },
      "macro_f1": {
        "mean": 0.7924475431255186,
        "std": 0.07816214943279898
      },
      "weighted_precision": {
        "mean": 0.8190364455364454,
        "std": 0.06667332616147717
      },
      "weighted_recall": {
        "mean": 0.80099573257468,
        "std": 0.0777463005637251
      },
      "weighted_f1": {
        "mean": 0.8031995533382453,
        "std": 0.07574277214726197
      },
      "mcc": {
        "mean": 0.5993326041917098,
        "std": 0.1485769687111308
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4516358463726885,
          "std": 0.07527030756940514
        },
        "off_by_one_accuracy": {
          "mean": 0.9140825035561877,
          "std": 0.02603712361569855
        },
        "level_accuracy": {
          "mean": 0.5807965860597439,
          "std": 0.04539813201779503
        },
        "rmse": {
          "mean": 0.9083298377652108,
          "std": 0.08989202306768324
        },
        "mae": {
          "mean": 0.6396870554765293,
          "std": 0.09328617344617286
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4822597214394816,
          "std": 0.13803403999947625
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.35490753911806544,
          "std": 0.09595962667148979
        },
        "off_by_one_accuracy": {
          "mean": 0.8499288762446657,
          "std": 0.04779177661913787
        },
        "level_accuracy": {
          "mean": 0.5054054054054055,
          "std": 0.10729423373664437
        },
        "rmse": {
          "mean": 1.0817270839839472,
          "std": 0.0790786254597611
        },
        "mae": {
          "mean": 0.811379800853485,
          "std": 0.11507322483009301
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4281681099022186,
          "std": 0.15008582232937273
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3655761024182077,
          "std": 0.036288452395831235
        },
        "off_by_one_accuracy": {
          "mean": 0.8443812233285918,
          "std": 0.05115059087924183
        },
        "level_accuracy": {
          "mean": 0.5322901849217639,
          "std": 0.055139215975647075
        },
        "rmse": {
          "mean": 1.0718422486309758,
          "std": 0.08055107509999174
        },
        "mae": {
          "mean": 0.8008534850640114,
          "std": 0.07417631440640815
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3866730703700516,
          "std": 0.10784793869704717
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6756756756756757,
        "micro_precision": 0.6756756756756757,
        "micro_recall": 0.6756756756756757,
        "micro_f1": 0.6756756756756757,
        "macro_precision": 0.6798245614035088,
        "macro_recall": 0.6971153846153846,
        "macro_f1": 0.6696428571428572,
        "weighted_precision": 0.7254623044096729,
        "weighted_recall": 0.6756756756756757,
        "weighted_f1": 0.6829150579150579,
        "mcc": 0.3765431586649556
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.6486486486486487,
          "rmse": 0.8853156407653622,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.5376992675570874
        },
        "curiosity": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.138989594902999,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.34992679355783307
        },
        "surprise": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.1624763874381927,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.2949695121951219
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7807017543859649,
        "macro_recall": 0.7981366459627328,
        "macro_f1": 0.7797619047619048,
        "weighted_precision": 0.8084400189663347,
        "weighted_recall": 0.7837837837837838,
        "weighted_f1": 0.787001287001287,
        "mcc": 0.5785757670987834
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5405405405405406,
          "rmse": 0.944400281603035,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.36899224806201547
        },
        "curiosity": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.32432432432432434,
          "rmse": 1.1270626736212455,
          "mae": 0.9459459459459459,
          "quadratic_weighted_kappa": 0.23694602896007022
        },
        "surprise": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.0134234194190634,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.364376130198915
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8157894736842105,
        "micro_precision": 0.8157894736842105,
        "micro_recall": 0.8157894736842105,
        "micro_f1": 0.8157894736842104,
        "macro_precision": 0.8068181818181819,
        "macro_recall": 0.8130434782608695,
        "macro_f1": 0.8093189964157707,
        "weighted_precision": 0.81877990430622,
        "weighted_recall": 0.8157894736842105,
        "weighted_f1": 0.8167138275797019,
        "mcc": 0.6198303988351637
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4473684210526316,
          "off_by_one_accuracy": 0.8947368421052632,
          "level_accuracy": 0.5526315789473685,
          "rmse": 0.9318911162960933,
          "mae": 0.6578947368421053,
          "quadratic_weighted_kappa": 0.42105263157894735
        },
        "curiosity": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.7631578947368421,
          "level_accuracy": 0.5,
          "rmse": 1.1697953037312037,
          "mae": 0.8947368421052632,
          "quadratic_weighted_kappa": 0.34742404227212675
        },
        "surprise": {
          "perfect_accuracy": 0.3684210526315789,
          "off_by_one_accuracy": 0.7894736842105263,
          "level_accuracy": 0.5263157894736842,
          "rmse": 1.1239029738980326,
          "mae": 0.8421052631578947,
          "quadratic_weighted_kappa": 0.3554770318021201
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.7949999999999999,
        "macro_recall": 0.7836538461538461,
        "macro_f1": 0.7885714285714285,
        "weighted_precision": 0.8083783783783783,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8089575289575289,
        "mcc": 0.5785425986576429
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.0266713466606798,
          "mae": 0.7297297297297297,
          "quadratic_weighted_kappa": 0.3566651805617477
        },
        "curiosity": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.5675675675675675,
          "rmse": 0.9863939238321437,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.5708762886597938
        },
        "surprise": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.115008180796555,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.3219123505976096
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.918918918918919,
        "micro_precision": 0.918918918918919,
        "micro_recall": 0.918918918918919,
        "micro_f1": 0.918918918918919,
        "macro_precision": 0.90625,
        "macro_recall": 0.9375,
        "macro_f1": 0.9149425287356322,
        "weighted_precision": 0.9341216216216216,
        "weighted_recall": 0.918918918918919,
        "weighted_f1": 0.9204100652376515,
        "mcc": 0.8431710977020026
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5945945945945946,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.6216216216216216,
          "rmse": 0.753370803500884,
          "mae": 0.4594594594594595,
          "quadratic_weighted_kappa": 0.7268892794376098
        },
        "curiosity": {
          "perfect_accuracy": 0.4864864864864865,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.6486486486486487,
          "rmse": 0.9863939238321437,
          "mae": 0.6486486486486487,
          "quadratic_weighted_kappa": 0.6356673960612692
        },
        "surprise": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5945945945945946,
          "rmse": 0.944400281603035,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.5966303270564915
        }
      }
    }
  ]
}