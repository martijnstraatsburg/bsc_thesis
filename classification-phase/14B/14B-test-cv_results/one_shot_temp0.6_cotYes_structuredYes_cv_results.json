{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.6880512091038407,
        "std": 0.06117238384463132
      },
      "micro_precision": {
        "mean": 0.6880512091038407,
        "std": 0.06117238384463132
      },
      "micro_recall": {
        "mean": 0.6880512091038407,
        "std": 0.06117238384463132
      },
      "micro_f1": {
        "mean": 0.6880512091038407,
        "std": 0.06117238384463132
      },
      "macro_precision": {
        "mean": 0.7652537542417602,
        "std": 0.02791658333138971
      },
      "macro_recall": {
        "mean": 0.7510033444816052,
        "std": 0.04442357343072316
      },
      "macro_f1": {
        "mean": 0.6858260880468839,
        "std": 0.06411332317226957
      },
      "weighted_precision": {
        "mean": 0.8251558824532864,
        "std": 0.019977598487406482
      },
      "weighted_recall": {
        "mean": 0.6880512091038407,
        "std": 0.06117238384463132
      },
      "weighted_f1": {
        "mean": 0.6823559075163695,
        "std": 0.07112849594535463
      },
      "mcc": {
        "mean": 0.5152013297990554,
        "std": 0.07092244076809091
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.23143669985775248,
          "std": 0.056455598044522035
        },
        "off_by_one_accuracy": {
          "mean": 0.6668563300142247,
          "std": 0.04209565074237376
        },
        "level_accuracy": {
          "mean": 0.6076813655761024,
          "std": 0.02466097631040607
        },
        "rmse": {
          "mean": 1.4717623573838,
          "std": 0.07676459982552522
        },
        "mae": {
          "mean": 1.1825035561877666,
          "std": 0.05643767460779634
        },
        "quadratic_weighted_kappa": {
          "mean": 0.16083677685805856,
          "std": 0.09809515087909525
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.220199146514936,
          "std": 0.033989714512216
        },
        "off_by_one_accuracy": {
          "mean": 0.6987197724039829,
          "std": 0.022570336808305776
        },
        "level_accuracy": {
          "mean": 0.4406827880512091,
          "std": 0.04163164482919715
        },
        "rmse": {
          "mean": 1.4530509260420683,
          "std": 0.050825804212105426
        },
        "mae": {
          "mean": 1.167140825035562,
          "std": 0.04729382119655475
        },
        "quadratic_weighted_kappa": {
          "mean": 0.25838596216495036,
          "std": 0.05694559523499179
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.17724039829302987,
          "std": 0.07114423602702273
        },
        "off_by_one_accuracy": {
          "mean": 0.69900426742532,
          "std": 0.04582578123479155
        },
        "level_accuracy": {
          "mean": 0.5641536273115221,
          "std": 0.07102468206380046
        },
        "rmse": {
          "mean": 1.542938534148258,
          "std": 0.1256363485370023
        },
        "mae": {
          "mean": 1.2578947368421054,
          "std": 0.13805309619727965
        },
        "quadratic_weighted_kappa": {
          "mean": 0.1519957424521286,
          "std": 0.10826110474220113
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.5675675675675675,
        "micro_precision": 0.5675675675675675,
        "micro_recall": 0.5675675675675675,
        "micro_f1": 0.5675675675675675,
        "macro_precision": 0.7241379310344828,
        "macro_recall": 0.6666666666666666,
        "macro_f1": 0.5595238095238095,
        "weighted_precision": 0.8061509785647717,
        "weighted_recall": 0.5675675675675675,
        "weighted_f1": 0.5418275418275418,
        "mcc": 0.3865556717425342
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.16216216216216217,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.6486486486486487,
          "rmse": 1.3656005509902465,
          "mae": 1.162162162162162,
          "quadratic_weighted_kappa": 0.2786097767730997
        },
        "curiosity": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.5156837721956706,
          "mae": 1.2162162162162162,
          "quadratic_weighted_kappa": 0.2170774209609162
        },
        "surprise": {
          "perfect_accuracy": 0.16216216216216217,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.506741607001768,
          "mae": 1.2432432432432432,
          "quadratic_weighted_kappa": 0.1568095496473142
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "micro_precision": 0.7297297297297297,
        "micro_recall": 0.7297297297297297,
        "micro_f1": 0.7297297297297297,
        "macro_precision": 0.7916666666666667,
        "macro_recall": 0.7826086956521738,
        "macro_f1": 0.72953216374269,
        "weighted_precision": 0.8423423423423424,
        "weighted_recall": 0.7297297297297297,
        "weighted_f1": 0.727754069859333,
        "mcc": 0.5742039227726821
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.6216216216216216,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.5156837721956706,
          "mae": 1.2162162162162162,
          "quadratic_weighted_kappa": 0.06980183377698912
        },
        "curiosity": {
          "perfect_accuracy": 0.16216216216216217,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.3783783783783784,
          "rmse": 1.4142135623730951,
          "mae": 1.1891891891891893,
          "quadratic_weighted_kappa": 0.2248018120045301
        },
        "surprise": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.7297297297297297,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.4977460543240444,
          "mae": 1.2702702702702702,
          "quadratic_weighted_kappa": 0.15282758620689652
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7105263157894737,
        "micro_precision": 0.7105263157894737,
        "micro_recall": 0.7105263157894737,
        "micro_f1": 0.7105263157894737,
        "macro_precision": 0.7884615384615384,
        "macro_recall": 0.7608695652173914,
        "macro_f1": 0.7087108013937282,
        "weighted_precision": 0.832995951417004,
        "weighted_recall": 0.7105263157894737,
        "weighted_f1": 0.7038694296717402,
        "mcc": 0.5486377169695913
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.18421052631578946,
          "off_by_one_accuracy": 0.631578947368421,
          "level_accuracy": 0.5789473684210527,
          "rmse": 1.4779074823262075,
          "mae": 1.236842105263158,
          "quadratic_weighted_kappa": 0.17821782178217827
        },
        "curiosity": {
          "perfect_accuracy": 0.2631578947368421,
          "off_by_one_accuracy": 0.7368421052631579,
          "level_accuracy": 0.47368421052631576,
          "rmse": 1.3860204297119676,
          "mae": 1.0789473684210527,
          "quadratic_weighted_kappa": 0.294147582697201
        },
        "surprise": {
          "perfect_accuracy": 0.21052631578947367,
          "off_by_one_accuracy": 0.6842105263157895,
          "level_accuracy": 0.631578947368421,
          "rmse": 1.6303051054456357,
          "mae": 1.2894736842105263,
          "quadratic_weighted_kappa": 0.12891511575124814
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7027027027027027,
        "micro_precision": 0.7027027027027027,
        "micro_recall": 0.7027027027027027,
        "micro_f1": 0.7027027027027027,
        "macro_precision": 0.7393939393939394,
        "macro_recall": 0.7532051282051282,
        "macro_f1": 0.7018315018315018,
        "weighted_precision": 0.797051597051597,
        "weighted_recall": 0.7027027027027027,
        "weighted_f1": 0.7066231066231066,
        "mcc": 0.4924054147377875
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.7297297297297297,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.58540641903378,
          "mae": 1.2162162162162162,
          "quadratic_weighted_kappa": 0.027691438259395462
        },
        "curiosity": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.506741607001768,
          "mae": 1.1891891891891893,
          "quadratic_weighted_kappa": 0.202668034889687
        },
        "surprise": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.6216216216216216,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.7242311251607114,
          "mae": 1.4594594594594594,
          "quadratic_weighted_kappa": -0.00942460317460303
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "micro_precision": 0.7297297297297297,
        "micro_recall": 0.7297297297297297,
        "micro_f1": 0.7297297297297297,
        "macro_precision": 0.7826086956521738,
        "macro_recall": 0.7916666666666667,
        "macro_f1": 0.72953216374269,
        "weighted_precision": 0.8472385428907169,
        "weighted_recall": 0.7297297297297297,
        "weighted_f1": 0.7317053896001264,
        "mcc": 0.5742039227726821
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.6486486486486487,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.4142135623730951,
          "mae": 1.0810810810810811,
          "quadratic_weighted_kappa": 0.24986301369863018
        },
        "curiosity": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.40540540540540543,
          "rmse": 1.4425952589278397,
          "mae": 1.162162162162162,
          "quadratic_weighted_kappa": 0.35323496027241763
        },
        "surprise": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.35566877880913,
          "mae": 1.027027027027027,
          "quadratic_weighted_kappa": 0.33085106382978724
        }
      }
    }
  ]
}