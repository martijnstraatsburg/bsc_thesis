{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.6844159315690992,
        "std": 0.04636748828219004
      },
      "micro_precision": {
        "mean": 0.6844159315690992,
        "std": 0.04636748828219004
      },
      "micro_recall": {
        "mean": 0.6844159315690992,
        "std": 0.04636748828219004
      },
      "micro_f1": {
        "mean": 0.6844159315690992,
        "std": 0.046367488282190054
      },
      "macro_precision": {
        "mean": 0.7341431707871424,
        "std": 0.05830344853308808
      },
      "macro_recall": {
        "mean": 0.7079743753819902,
        "std": 0.051487044286839354
      },
      "macro_f1": {
        "mean": 0.6797208007066198,
        "std": 0.04649824272036711
      },
      "weighted_precision": {
        "mean": 0.7517840973736222,
        "std": 0.0637969544914264
      },
      "weighted_recall": {
        "mean": 0.6844159315690992,
        "std": 0.04636748828219004
      },
      "weighted_f1": {
        "mean": 0.6759004260371919,
        "std": 0.04683152062969884
      },
      "mcc": {
        "mean": 0.44118161892437036,
        "std": 0.10878141942947248
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.28567228013900026,
          "std": 0.04819216319049697
        },
        "off_by_one_accuracy": {
          "mean": 0.7788024592354985,
          "std": 0.030302424239871315
        },
        "level_accuracy": {
          "mean": 0.47473937449879705,
          "std": 0.04108275816121145
        },
        "rmse": {
          "mean": 1.2884888585965402,
          "std": 0.07577199866754904
        },
        "mae": {
          "mean": 0.9931301790964984,
          "std": 0.08497002610767747
        },
        "quadratic_weighted_kappa": {
          "mean": 0.11252653842033108,
          "std": 0.08866983645273668
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3412723870622828,
          "std": 0.06208814151594825
        },
        "off_by_one_accuracy": {
          "mean": 0.7996257685110933,
          "std": 0.029130266694651203
        },
        "level_accuracy": {
          "mean": 0.5025661587810746,
          "std": 0.06762878602955068
        },
        "rmse": {
          "mean": 1.2099848298391866,
          "std": 0.05789508790488899
        },
        "mae": {
          "mean": 0.9006148088746325,
          "std": 0.08265408343557275
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2805650367945896,
          "std": 0.10125628029780978
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.31344560278000533,
          "std": 0.052131433004162286
        },
        "off_by_one_accuracy": {
          "mean": 0.7557872226677359,
          "std": 0.030098761598251516
        },
        "level_accuracy": {
          "mean": 0.5115744453354718,
          "std": 0.034536551292210074
        },
        "rmse": {
          "mean": 1.3160070473538035,
          "std": 0.08441397173057706
        },
        "mae": {
          "mean": 0.9928896017107725,
          "std": 0.09261025420952115
        },
        "quadratic_weighted_kappa": {
          "mean": 0.11014052919938933,
          "std": 0.10439929785441449
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.76875,
        "macro_recall": 0.7598901098901099,
        "macro_f1": 0.7238095238095239,
        "weighted_precision": 0.8017241379310345,
        "weighted_recall": 0.7241379310344828,
        "weighted_f1": 0.7219485495347564,
        "mcc": 0.5285658597865247
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.21839080459770116,
          "off_by_one_accuracy": 0.7241379310344828,
          "level_accuracy": 0.41379310344827586,
          "rmse": 1.4182715723279387,
          "mae": 1.1379310344827587,
          "quadratic_weighted_kappa": -0.042308482234544975
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8045977011494253,
          "level_accuracy": 0.5172413793103449,
          "rmse": 1.2640020369545641,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.256958525345622
        },
        "surprise": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.7011494252873564,
          "level_accuracy": 0.45977011494252873,
          "rmse": 1.4423798979862907,
          "mae": 1.1379310344827587,
          "quadratic_weighted_kappa": -0.03482946704343837
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7011494252873564,
        "micro_precision": 0.7011494252873564,
        "micro_recall": 0.7011494252873564,
        "micro_f1": 0.7011494252873564,
        "macro_precision": 0.7527777777777778,
        "macro_recall": 0.7178191489361703,
        "macro_f1": 0.6943243243243243,
        "weighted_precision": 0.7637292464878671,
        "weighted_recall": 0.7011494252873564,
        "weighted_f1": 0.6906492699596148,
        "mcc": 0.46929666704775097
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7816091954022989,
          "level_accuracy": 0.5287356321839081,
          "rmse": 1.259447059844805,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.12886373530692197
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7471264367816092,
          "level_accuracy": 0.41379310344827586,
          "rmse": 1.2775695315895637,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.10659531385594423
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7471264367816092,
          "level_accuracy": 0.5287356321839081,
          "rmse": 1.3304566669113036,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.10321285140562242
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.5977011494252874,
        "micro_precision": 0.5977011494252874,
        "micro_recall": 0.5977011494252874,
        "micro_f1": 0.5977011494252874,
        "macro_precision": 0.6226958525345623,
        "macro_recall": 0.6137820512820513,
        "macro_f1": 0.5942704863424384,
        "weighted_precision": 0.6316939456539011,
        "weighted_recall": 0.5977011494252874,
        "weighted_f1": 0.5904109903742333,
        "mcc": 0.23630984562800222
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7931034482758621,
          "level_accuracy": 0.45977011494252873,
          "rmse": 1.2820601237537732,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.10567177054129828
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8045977011494253,
          "level_accuracy": 0.45977011494252873,
          "rmse": 1.2223963651627971,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.2766692248656947
        },
        "surprise": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7816091954022989,
          "level_accuracy": 0.4827586206896552,
          "rmse": 1.3603583030377249,
          "mae": 1.0459770114942528,
          "quadratic_weighted_kappa": 0.02991896945771877
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6781609195402298,
        "micro_precision": 0.6781609195402298,
        "micro_recall": 0.6781609195402298,
        "micro_f1": 0.6781609195402298,
        "macro_precision": 0.737389659520807,
        "macro_recall": 0.7011217948717949,
        "macro_f1": 0.6708108108108108,
        "weighted_precision": 0.752619906944384,
        "weighted_recall": 0.6781609195402298,
        "weighted_f1": 0.6657222739981361,
        "mcc": 0.4370090818590799
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8160919540229885,
          "level_accuracy": 0.45977011494252873,
          "rmse": 1.18418699983352,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.2324269597917269
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8045977011494253,
          "level_accuracy": 0.5057471264367817,
          "rmse": 1.1346172578623508,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.3732149749131609
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.7816091954022989,
          "level_accuracy": 0.5517241379310345,
          "rmse": 1.2364204916548043,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.23152022315202225
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7891025641025642,
        "macro_recall": 0.7472587719298246,
        "macro_f1": 0.7153888582460011,
        "weighted_precision": 0.8091532498509242,
        "weighted_recall": 0.7209302325581395,
        "weighted_f1": 0.7107710463192191,
        "mcc": 0.5347266403004937
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.26744186046511625,
          "off_by_one_accuracy": 0.7790697674418605,
          "level_accuracy": 0.5116279069767442,
          "rmse": 1.2984785372226633,
          "mae": 1.0116279069767442,
          "quadratic_weighted_kappa": 0.13797870869625328
        },
        "curiosity": {
          "perfect_accuracy": 0.45348837209302323,
          "off_by_one_accuracy": 0.8372093023255814,
          "level_accuracy": 0.6162790697674418,
          "rmse": 1.151338957626657,
          "mae": 0.7674418604651163,
          "quadratic_weighted_kappa": 0.38938714499252625
        },
        "surprise": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.7674418604651163,
          "level_accuracy": 0.5348837209302325,
          "rmse": 1.2104198771788934,
          "mae": 0.9069767441860465,
          "quadratic_weighted_kappa": 0.22088006902502155
        }
      }
    }
  ]
}