{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.46770981507823606,
        "std": 0.04651645849057593
      },
      "micro_precision": {
        "mean": 0.46770981507823606,
        "std": 0.04651645849057593
      },
      "micro_recall": {
        "mean": 0.46770981507823606,
        "std": 0.04651645849057593
      },
      "micro_f1": {
        "mean": 0.46770981507823606,
        "std": 0.04651645849057595
      },
      "macro_precision": {
        "mean": 0.7039529802634641,
        "std": 0.012283156282049734
      },
      "macro_recall": {
        "mean": 0.5804347826086956,
        "std": 0.03570909059943661
      },
      "macro_f1": {
        "mean": 0.4246936907708315,
        "std": 0.06502645531274279
      },
      "weighted_precision": {
        "mean": 0.7838964141914058,
        "std": 0.008543521547511977
      },
      "weighted_recall": {
        "mean": 0.46770981507823606,
        "std": 0.04651645849057593
      },
      "weighted_f1": {
        "mean": 0.38363872962900986,
        "std": 0.07830104105784916
      },
      "mcc": {
        "mean": 0.24908666312122335,
        "std": 0.06925533366703418
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.14523470839260316,
          "std": 0.07769423086451477
        },
        "off_by_one_accuracy": {
          "mean": 0.6398293029871978,
          "std": 0.031672359374549215
        },
        "level_accuracy": {
          "mean": 0.57524893314367,
          "std": 0.031456968421428866
        },
        "rmse": {
          "mean": 1.6471996499863775,
          "std": 0.039077540791185215
        },
        "mae": {
          "mean": 1.3708392603129442,
          "std": 0.0854475480344094
        },
        "quadratic_weighted_kappa": {
          "mean": 0.07664436211792831,
          "std": 0.07253614748639543
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.08591749644381223,
          "std": 0.03942694553326122
        },
        "off_by_one_accuracy": {
          "mean": 0.47311522048364163,
          "std": 0.012090201627809832
        },
        "level_accuracy": {
          "mean": 0.40853485064011374,
          "std": 0.03026096392733938
        },
        "rmse": {
          "mean": 1.9816666515140924,
          "std": 0.06764783548159864
        },
        "mae": {
          "mean": 1.7261735419630155,
          "std": 0.06506482617242089
        },
        "quadratic_weighted_kappa": {
          "mean": 0.05755743709164589,
          "std": 0.031027095942247965
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.11834992887624467,
          "std": 0.06974133026513256
        },
        "off_by_one_accuracy": {
          "mean": 0.6076813655761024,
          "std": 0.03853201241157783
        },
        "level_accuracy": {
          "mean": 0.5860597439544808,
          "std": 0.020356806623042185
        },
        "rmse": {
          "mean": 1.7525655233072208,
          "std": 0.08387319240338087
        },
        "mae": {
          "mean": 1.4779516358463727,
          "std": 0.09982086669258339
        },
        "quadratic_weighted_kappa": {
          "mean": 0.0432476329235574,
          "std": 0.06059285339386948
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.3783783783783784,
        "micro_precision": 0.3783783783783784,
        "micro_recall": 0.3783783783783784,
        "micro_f1": 0.37837837837837834,
        "macro_precision": 0.6805555555555556,
        "macro_recall": 0.5208333333333334,
        "macro_f1": 0.30530612244897953,
        "weighted_precision": 0.7755255255255254,
        "weighted_recall": 0.3783783783783784,
        "weighted_f1": 0.238323221180364,
        "mcc": 0.12266334536566455
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.08108108108108109,
          "off_by_one_accuracy": 0.6216216216216216,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.652189374657073,
          "mae": 1.4324324324324325,
          "quadratic_weighted_kappa": 0.08114089009097603
        },
        "curiosity": {
          "perfect_accuracy": 0.02702702702702703,
          "off_by_one_accuracy": 0.4594594594594595,
          "level_accuracy": 0.3783783783783784,
          "rmse": 2.0533426933213597,
          "mae": 1.837837837837838,
          "quadratic_weighted_kappa": 0.02893674293405113
        },
        "surprise": {
          "perfect_accuracy": 0.13513513513513514,
          "off_by_one_accuracy": 0.5675675675675675,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.7242311251607114,
          "mae": 1.4594594594594594,
          "quadratic_weighted_kappa": 0.01738290680830512
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.4864864864864865,
        "micro_precision": 0.4864864864864865,
        "micro_recall": 0.4864864864864865,
        "micro_f1": 0.4864864864864865,
        "macro_precision": 0.7121212121212122,
        "macro_recall": 0.5869565217391304,
        "macro_f1": 0.44602048857368004,
        "weighted_precision": 0.7821457821457821,
        "weighted_recall": 0.4864864864864865,
        "weighted_f1": 0.4096010904521543,
        "mcc": 0.2716271178888358
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.5945945945945946,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.7084843923544981,
          "mae": 1.4594594594594594,
          "quadratic_weighted_kappa": -0.04607329842931929
        },
        "curiosity": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.4864864864864865,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.9451950503185493,
          "mae": 1.6756756756756757,
          "quadratic_weighted_kappa": 0.013333333333333197
        },
        "surprise": {
          "perfect_accuracy": 0.05405405405405406,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.652189374657073,
          "mae": 1.4324324324324325,
          "quadratic_weighted_kappa": 0.15164585698070376
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.47368421052631576,
        "micro_precision": 0.47368421052631576,
        "micro_recall": 0.47368421052631576,
        "micro_f1": 0.47368421052631576,
        "macro_precision": 0.7142857142857143,
        "macro_recall": 0.5652173913043478,
        "macro_f1": 0.41538461538461535,
        "weighted_precision": 0.7744360902255639,
        "weighted_recall": 0.47368421052631576,
        "weighted_f1": 0.3765182186234818,
        "mcc": 0.2364331218717302
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.13157894736842105,
          "off_by_one_accuracy": 0.631578947368421,
          "level_accuracy": 0.5789473684210527,
          "rmse": 1.6622749155109218,
          "mae": 1.394736842105263,
          "quadratic_weighted_kappa": 0.05405405405405406
        },
        "curiosity": {
          "perfect_accuracy": 0.10526315789473684,
          "off_by_one_accuracy": 0.47368421052631576,
          "level_accuracy": 0.42105263157894735,
          "rmse": 1.9125623484849077,
          "mae": 1.6578947368421053,
          "quadratic_weighted_kappa": 0.06843033509700158
        },
        "surprise": {
          "perfect_accuracy": 0.10526315789473684,
          "off_by_one_accuracy": 0.5789473684210527,
          "level_accuracy": 0.5789473684210527,
          "rmse": 1.8637822325921867,
          "mae": 1.5789473684210527,
          "quadratic_weighted_kappa": -0.025766871165644245
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.5135135135135135,
        "micro_precision": 0.5135135135135135,
        "micro_recall": 0.5135135135135135,
        "micro_f1": 0.5135135135135135,
        "macro_precision": 0.7096774193548387,
        "macro_recall": 0.625,
        "macro_f1": 0.4954545454545455,
        "weighted_precision": 0.7959895379250218,
        "weighted_recall": 0.5135135135135135,
        "weighted_f1": 0.46707616707616717,
        "mcc": 0.32378806290136664
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.5939073186796466,
          "mae": 1.3513513513513513,
          "quadratic_weighted_kappa": 0.12700803212851408
        },
        "curiosity": {
          "perfect_accuracy": 0.05405405405405406,
          "off_by_one_accuracy": 0.4864864864864865,
          "level_accuracy": 0.3783783783783784,
          "rmse": 1.9242408120354122,
          "mae": 1.7027027027027026,
          "quadratic_weighted_kappa": 0.08847329616975363
        },
        "surprise": {
          "perfect_accuracy": 0.05405405405405406,
          "off_by_one_accuracy": 0.5945945945945946,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.8380365552345195,
          "mae": 1.5945945945945945,
          "quadratic_weighted_kappa": 0.05976824557836957
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.4864864864864865,
        "micro_precision": 0.4864864864864865,
        "micro_recall": 0.4864864864864865,
        "micro_f1": 0.4864864864864865,
        "macro_precision": 0.703125,
        "macro_recall": 0.6041666666666666,
        "macro_f1": 0.46130268199233715,
        "weighted_precision": 0.7913851351351351,
        "weighted_recall": 0.4864864864864865,
        "weighted_f1": 0.42667495081288187,
        "mcc": 0.2909216675785196
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.6756756756756757,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.6191422487297469,
          "mae": 1.2162162162162162,
          "quadratic_weighted_kappa": 0.16709213274541668
        },
        "curiosity": {
          "perfect_accuracy": 0.13513513513513514,
          "off_by_one_accuracy": 0.4594594594594595,
          "level_accuracy": 0.40540540540540543,
          "rmse": 2.0729923534102332,
          "mae": 1.7567567567567568,
          "quadratic_weighted_kappa": 0.08861347792408991
        },
        "surprise": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.6216216216216216,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.684588328891613,
          "mae": 1.3243243243243243,
          "quadratic_weighted_kappa": 0.013208026416052787
        }
      }
    }
  ]
}