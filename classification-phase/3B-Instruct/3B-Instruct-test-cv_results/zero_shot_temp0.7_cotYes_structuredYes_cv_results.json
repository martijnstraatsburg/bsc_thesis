{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.49459459459459454,
        "std": 0.043243243243243225
      },
      "micro_precision": {
        "mean": 0.49459459459459454,
        "std": 0.043243243243243225
      },
      "micro_recall": {
        "mean": 0.49459459459459454,
        "std": 0.043243243243243225
      },
      "micro_f1": {
        "mean": 0.49459459459459454,
        "std": 0.043243243243243225
      },
      "macro_precision": {
        "mean": 0.7102297698076095,
        "std": 0.011981805165630873
      },
      "macro_recall": {
        "mean": 0.6014492753623187,
        "std": 0.03520743731219296
      },
      "macro_f1": {
        "mean": 0.46176488660190584,
        "std": 0.055399752734813124
      },
      "weighted_precision": {
        "mean": 0.7884165063551473,
        "std": 0.009728215034448068
      },
      "weighted_recall": {
        "mean": 0.49459459459459454,
        "std": 0.043243243243243225
      },
      "weighted_f1": {
        "mean": 0.42752503083286014,
        "std": 0.06535038810687176
      },
      "mcc": {
        "mean": 0.2889436637333231,
        "std": 0.05462646152820398
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.15604551920341395,
          "std": 0.07153168931175073
        },
        "off_by_one_accuracy": {
          "mean": 0.661593172119488,
          "std": 0.0609516889455802
        },
        "level_accuracy": {
          "mean": 0.586344238975818,
          "std": 0.04668146334217621
        },
        "rmse": {
          "mean": 1.6109486957650478,
          "std": 0.12568754088759138
        },
        "mae": {
          "mean": 1.3327169274537696,
          "std": 0.15059866961058843
        },
        "quadratic_weighted_kappa": {
          "mean": 0.11568550110160644,
          "std": 0.12815939121879344
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.1182076813655761,
          "std": 0.027177837828888746
        },
        "off_by_one_accuracy": {
          "mean": 0.47297297297297297,
          "std": 0.017093392757666907
        },
        "level_accuracy": {
          "mean": 0.40853485064011374,
          "std": 0.018203235588103994
        },
        "rmse": {
          "mean": 1.9046806181468565,
          "std": 0.04045957938611493
        },
        "mae": {
          "mean": 1.6399715504978665,
          "std": 0.05413709276442517
        },
        "quadratic_weighted_kappa": {
          "mean": 0.07699789344211602,
          "std": 0.050201752220856696
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.16116642958748223,
          "std": 0.07986358508305834
        },
        "off_by_one_accuracy": {
          "mean": 0.6236130867709815,
          "std": 0.02449963031762274
        },
        "level_accuracy": {
          "mean": 0.5913229018492177,
          "std": 0.021221116584889354
        },
        "rmse": {
          "mean": 1.7416259744856544,
          "std": 0.09702174084948367
        },
        "mae": {
          "mean": 1.4301564722617357,
          "std": 0.12913253776241837
        },
        "quadratic_weighted_kappa": {
          "mean": 0.02101976412406321,
          "std": 0.028186770647444986
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.4864864864864865,
        "micro_precision": 0.4864864864864865,
        "micro_recall": 0.4864864864864865,
        "micro_f1": 0.4864864864864865,
        "macro_precision": 0.703125,
        "macro_recall": 0.6041666666666666,
        "macro_f1": 0.46130268199233715,
        "weighted_precision": 0.7913851351351351,
        "weighted_recall": 0.4864864864864865,
        "weighted_f1": 0.42667495081288187,
        "mcc": 0.2909216675785196
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.13513513513513514,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.5156837721956706,
          "mae": 1.2702702702702702,
          "quadratic_weighted_kappa": 0.19585783687036573
        },
        "curiosity": {
          "perfect_accuracy": 0.08108108108108109,
          "off_by_one_accuracy": 0.4594594594594595,
          "level_accuracy": 0.40540540540540543,
          "rmse": 1.9382354750537296,
          "mae": 1.7027027027027026,
          "quadratic_weighted_kappa": 0.06063926940639264
        },
        "surprise": {
          "perfect_accuracy": 0.16216216216216217,
          "off_by_one_accuracy": 0.5945945945945946,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.7320508075688772,
          "mae": 1.4324324324324325,
          "quadratic_weighted_kappa": -0.009835259404966878
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.4864864864864865,
        "micro_precision": 0.4864864864864865,
        "micro_recall": 0.4864864864864865,
        "micro_f1": 0.4864864864864865,
        "macro_precision": 0.7121212121212122,
        "macro_recall": 0.5869565217391304,
        "macro_f1": 0.44602048857368004,
        "weighted_precision": 0.7821457821457821,
        "weighted_recall": 0.4864864864864865,
        "weighted_f1": 0.4096010904521543,
        "mcc": 0.2716271178888358
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.6486486486486487,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.5768596914394402,
          "mae": 1.3513513513513513,
          "quadratic_weighted_kappa": 0.10890052356020952
        },
        "curiosity": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.4594594594594595,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.8599622199011085,
          "mae": 1.6216216216216217,
          "quadratic_weighted_kappa": 0.075361187036314
        },
        "surprise": {
          "perfect_accuracy": 0.08108108108108109,
          "off_by_one_accuracy": 0.6486486486486487,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.7084843923544981,
          "mae": 1.4594594594594594,
          "quadratic_weighted_kappa": 0.04811815150071441
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.5,
        "micro_precision": 0.5,
        "micro_recall": 0.5,
        "micro_f1": 0.5,
        "macro_precision": 0.7205882352941176,
        "macro_recall": 0.5869565217391304,
        "macro_f1": 0.45427059712774,
        "weighted_precision": 0.7794117647058824,
        "weighted_recall": 0.5,
        "weighted_f1": 0.4210128495842782,
        "mcc": 0.27699520340792444
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.13157894736842105,
          "off_by_one_accuracy": 0.6052631578947368,
          "level_accuracy": 0.5263157894736842,
          "rmse": 1.7244373605690395,
          "mae": 1.4473684210526316,
          "quadratic_weighted_kappa": -0.03669724770642202
        },
        "curiosity": {
          "perfect_accuracy": 0.13157894736842105,
          "off_by_one_accuracy": 0.5,
          "level_accuracy": 0.42105263157894735,
          "rmse": 1.8848425873126298,
          "mae": 1.605263157894737,
          "quadratic_weighted_kappa": 0.05245659401551528
        },
        "surprise": {
          "perfect_accuracy": 0.18421052631578946,
          "off_by_one_accuracy": 0.631578947368421,
          "level_accuracy": 0.6052631578947368,
          "rmse": 1.7621756887140216,
          "mae": 1.4210526315789473,
          "quadratic_weighted_kappa": 0.020532983835735985
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.43243243243243246,
        "micro_precision": 0.43243243243243246,
        "micro_recall": 0.43243243243243246,
        "micro_f1": 0.43243243243243246,
        "macro_precision": 0.6911764705882353,
        "macro_recall": 0.5625,
        "macro_f1": 0.3877068557919622,
        "weighted_precision": 0.7829888712241653,
        "weighted_recall": 0.43243243243243246,
        "weighted_f1": 0.3385087214874449,
        "mcc": 0.21861865804880154
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.5945945945945946,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.785830112073707,
          "mae": 1.5135135135135136,
          "quadratic_weighted_kappa": -0.0018357044515833199
        },
        "curiosity": {
          "perfect_accuracy": 0.10810810810810811,
          "off_by_one_accuracy": 0.4594594594594595,
          "level_accuracy": 0.3783783783783784,
          "rmse": 1.9659259560992792,
          "mae": 1.7027027027027026,
          "quadratic_weighted_kappa": 0.024700460829493176
        },
        "surprise": {
          "perfect_accuracy": 0.08108108108108109,
          "off_by_one_accuracy": 0.5945945945945946,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.9030558640306967,
          "mae": 1.6216216216216217,
          "quadratic_weighted_kappa": -0.010599266204647462
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.5675675675675675,
        "micro_precision": 0.5675675675675675,
        "micro_recall": 0.5675675675675675,
        "micro_f1": 0.5675675675675675,
        "macro_precision": 0.7241379310344828,
        "macro_recall": 0.6666666666666666,
        "macro_f1": 0.5595238095238095,
        "weighted_precision": 0.8061509785647717,
        "weighted_recall": 0.5675675675675675,
        "weighted_f1": 0.5418275418275418,
        "mcc": 0.3865556717425342
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.6486486486486487,
          "rmse": 1.451932542547383,
          "mae": 1.0810810810810811,
          "quadratic_weighted_kappa": 0.31220209723546233
        },
        "curiosity": {
          "perfect_accuracy": 0.16216216216216217,
          "off_by_one_accuracy": 0.4864864864864865,
          "level_accuracy": 0.40540540540540543,
          "rmse": 1.8744368523675354,
          "mae": 1.5675675675675675,
          "quadratic_weighted_kappa": 0.17183195592286504
        },
        "surprise": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.6486486486486487,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.602363119760177,
          "mae": 1.2162162162162162,
          "quadratic_weighted_kappa": 0.05688221089348
        }
      }
    }
  ]
}