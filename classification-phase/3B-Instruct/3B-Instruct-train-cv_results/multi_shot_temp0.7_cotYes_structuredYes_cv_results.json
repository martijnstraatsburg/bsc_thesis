{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.6129377171879178,
        "std": 0.014647904350501242
      },
      "micro_precision": {
        "mean": 0.6129377171879178,
        "std": 0.014647904350501242
      },
      "micro_recall": {
        "mean": 0.6129377171879178,
        "std": 0.014647904350501242
      },
      "micro_f1": {
        "mean": 0.6129377171879178,
        "std": 0.014647904350501242
      },
      "macro_precision": {
        "mean": 0.7117525304362783,
        "std": 0.032540429910023656
      },
      "macro_recall": {
        "mean": 0.6487507178338646,
        "std": 0.022815165032103953
      },
      "macro_f1": {
        "mean": 0.5934156350126617,
        "std": 0.018511920753337425
      },
      "weighted_precision": {
        "mean": 0.7343996411821808,
        "std": 0.044023459237347455
      },
      "weighted_recall": {
        "mean": 0.6129377171879178,
        "std": 0.014647904350501242
      },
      "weighted_f1": {
        "mean": 0.5831664978797029,
        "std": 0.0185025702833197
      },
      "mcc": {
        "mean": 0.35480067467639553,
        "std": 0.05359495000338979
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4031809676557071,
          "std": 0.03866681348151928
        },
        "off_by_one_accuracy": {
          "mean": 0.8365143009890403,
          "std": 0.033247639540087866
        },
        "level_accuracy": {
          "mean": 0.5991178829190057,
          "std": 0.02976829446925782
        },
        "rmse": {
          "mean": 1.0844714877416453,
          "std": 0.05731839795634249
        },
        "mae": {
          "mean": 0.7787222667735899,
          "std": 0.04938113793000963
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2795929300492715,
          "std": 0.0626149108851234
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.40783213044640465,
          "std": 0.07641853081929934
        },
        "off_by_one_accuracy": {
          "mean": 0.7902699812884255,
          "std": 0.05080420136448536
        },
        "level_accuracy": {
          "mean": 0.5253675487837477,
          "std": 0.0689380764282489
        },
        "rmse": {
          "mean": 1.1849227989870421,
          "std": 0.11395390816452512
        },
        "mae": {
          "mean": 0.841031809676557,
          "std": 0.13091105496467834
        },
        "quadratic_weighted_kappa": {
          "mean": 0.21773006316946067,
          "std": 0.15181856775245528
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.32253408179631116,
          "std": 0.025631832521766203
        },
        "off_by_one_accuracy": {
          "mean": 0.7212510024057739,
          "std": 0.019044954659878963
        },
        "level_accuracy": {
          "mean": 0.5851643945469126,
          "std": 0.027627101678216512
        },
        "rmse": {
          "mean": 1.3508620454392706,
          "std": 0.06604385154087991
        },
        "mae": {
          "mean": 1.018390804597701,
          "std": 0.05171136496184824
        },
        "quadratic_weighted_kappa": {
          "mean": 0.16792347983236405,
          "std": 0.04622204301805669
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6206896551724138,
        "micro_precision": 0.6206896551724138,
        "micro_recall": 0.6206896551724138,
        "micro_f1": 0.6206896551724138,
        "macro_precision": 0.7573529411764706,
        "macro_recall": 0.6826923076923077,
        "macro_f1": 0.6074114590455353,
        "weighted_precision": 0.8047667342799188,
        "weighted_recall": 0.6206896551724138,
        "weighted_f1": 0.5933033756607269,
        "mcc": 0.43366532125560664
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8045977011494253,
          "level_accuracy": 0.6091954022988506,
          "rmse": 1.18418699983352,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.26393897364771157
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7701149425287356,
          "level_accuracy": 0.4827586206896552,
          "rmse": 1.308680128282278,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.15158060082466118
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.6896551724137931,
          "level_accuracy": 0.5632183908045977,
          "rmse": 1.4463588845748159,
          "mae": 1.103448275862069,
          "quadratic_weighted_kappa": 0.11084905660377375
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6091954022988506,
        "micro_precision": 0.6091954022988506,
        "micro_recall": 0.6091954022988506,
        "micro_f1": 0.6091954022988506,
        "macro_precision": 0.693111455108359,
        "macro_recall": 0.6327127659574469,
        "macro_f1": 0.585016835016835,
        "weighted_precision": 0.7050994626525745,
        "weighted_recall": 0.6091954022988506,
        "weighted_f1": 0.5769573125894965,
        "mcc": 0.3201771718626902
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8505747126436781,
          "level_accuracy": 0.6091954022988506,
          "rmse": 1.0985884360051028,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.19337748344370853
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7241379310344828,
          "level_accuracy": 0.4367816091954023,
          "rmse": 1.2640020369545641,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": -0.007833986165513895
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7126436781609196,
          "level_accuracy": 0.6091954022988506,
          "rmse": 1.3771534860493695,
          "mae": 1.0459770114942528,
          "quadratic_weighted_kappa": 0.15633264766382593
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6206896551724138,
        "micro_precision": 0.6206896551724138,
        "micro_recall": 0.6206896551724138,
        "micro_f1": 0.6206896551724138,
        "macro_precision": 0.6864809782608696,
        "macro_recall": 0.6466346153846154,
        "macro_f1": 0.6074114590455353,
        "weighted_precision": 0.7009229760119939,
        "weighted_recall": 0.6206896551724138,
        "weighted_f1": 0.5999424737241662,
        "mcc": 0.33072385171819363
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.7931034482758621,
          "level_accuracy": 0.6206896551724138,
          "rmse": 1.072112534837795,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.3048897411313518
        },
        "curiosity": {
          "perfect_accuracy": 0.5402298850574713,
          "off_by_one_accuracy": 0.8735632183908046,
          "level_accuracy": 0.6436781609195402,
          "rmse": 0.9767410038007758,
          "mae": 0.6091954022988506,
          "quadratic_weighted_kappa": 0.4601121495327102
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.735632183908046,
          "level_accuracy": 0.5862068965517241,
          "rmse": 1.2548755490797328,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.2523991720504297
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.5862068965517241,
        "micro_precision": 0.5862068965517241,
        "micro_recall": 0.5862068965517241,
        "micro_f1": 0.5862068965517241,
        "macro_precision": 0.677536231884058,
        "macro_recall": 0.6177884615384616,
        "macro_f1": 0.5606060606060607,
        "weighted_precision": 0.6936531734132932,
        "weighted_recall": 0.5862068965517241,
        "weighted_f1": 0.5496342737722049,
        "mcc": 0.289217700848055
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8505747126436781,
          "level_accuracy": 0.5402298850574713,
          "rmse": 1.0559083903140614,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.2532519246084418
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8160919540229885,
          "level_accuracy": 0.5287356321839081,
          "rmse": 1.18903032065977,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.23895882227437593
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.7241379310344828,
          "level_accuracy": 0.6206896551724138,
          "rmse": 1.3729739514150907,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.16385372714486623
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.627906976744186,
        "micro_precision": 0.627906976744186,
        "micro_recall": 0.627906976744186,
        "micro_f1": 0.627906976744186,
        "macro_precision": 0.744281045751634,
        "macro_recall": 0.6639254385964912,
        "macro_f1": 0.6066323613493425,
        "weighted_precision": 0.7675558595531234,
        "weighted_recall": 0.627906976744186,
        "weighted_f1": 0.5959950536519207,
        "mcc": 0.4002193276974322
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.8837209302325582,
          "level_accuracy": 0.6162790697674418,
          "rmse": 1.0115610777177464,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.38250652741514357
        },
        "curiosity": {
          "perfect_accuracy": 0.4069767441860465,
          "off_by_one_accuracy": 0.7674418604651163,
          "level_accuracy": 0.5348837209302325,
          "rmse": 1.1861605052378226,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.24583272938106981
        },
        "surprise": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.7441860465116279,
          "level_accuracy": 0.5465116279069767,
          "rmse": 1.3029483560773432,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.15618279569892468
        }
      }
    }
  ]
}