{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8064011379800855,
        "std": 0.060314286466189776
      },
      "micro_precision": {
        "mean": 0.8064011379800855,
        "std": 0.060314286466189776
      },
      "micro_recall": {
        "mean": 0.8064011379800855,
        "std": 0.060314286466189776
      },
      "micro_f1": {
        "mean": 0.8064011379800853,
        "std": 0.060314286466189804
      },
      "macro_precision": {
        "mean": 0.802783415564409,
        "std": 0.05506118373411068
      },
      "macro_recall": {
        "mean": 0.8192455008759356,
        "std": 0.05308473304031924
      },
      "macro_f1": {
        "mean": 0.800604092696822,
        "std": 0.05993553628395857
      },
      "weighted_precision": {
        "mean": 0.8317384435112258,
        "std": 0.047322778092760184
      },
      "weighted_recall": {
        "mean": 0.8064011379800855,
        "std": 0.060314286466189776
      },
      "weighted_f1": {
        "mean": 0.8092486022196932,
        "std": 0.05896944520030446
      },
      "mcc": {
        "mean": 0.6217836372181406,
        "std": 0.10816813601001739
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4251778093883357,
          "std": 0.05772585557724905
        },
        "off_by_one_accuracy": {
          "mean": 0.9192034139402561,
          "std": 0.03842684268541233
        },
        "level_accuracy": {
          "mean": 0.5,
          "std": 0.027027027027027025
        },
        "rmse": {
          "mean": 0.9021943125066292,
          "std": 0.05707338496696138
        },
        "mae": {
          "mean": 0.6556187766714083,
          "std": 0.053931132226789344
        },
        "quadratic_weighted_kappa": {
          "mean": 0.391707113995016,
          "std": 0.13343630168544446
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.44637268847795164,
          "std": 0.06378274324934863
        },
        "off_by_one_accuracy": {
          "mean": 0.8655761024182077,
          "std": 0.01715247828732047
        },
        "level_accuracy": {
          "mean": 0.49459459459459454,
          "std": 0.057713936497466534
        },
        "rmse": {
          "mean": 0.9770270586648232,
          "std": 0.04813658592161911
        },
        "mae": {
          "mean": 0.6880512091038407,
          "std": 0.07007707791500978
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4128249299499986,
          "std": 0.1288122910266584
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.34409672830725463,
          "std": 0.06703224337112793
        },
        "off_by_one_accuracy": {
          "mean": 0.881792318634424,
          "std": 0.0211293822220508
        },
        "level_accuracy": {
          "mean": 0.39758179231863444,
          "std": 0.06508037369496646
        },
        "rmse": {
          "mean": 1.015755675826219,
          "std": 0.07611668570899581
        },
        "mae": {
          "mean": 0.779516358463727,
          "std": 0.0895730214050365
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2387415257029064,
          "std": 0.11647969047300279
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "micro_precision": 0.7567567567567568,
        "micro_recall": 0.7567567567567568,
        "micro_f1": 0.7567567567567567,
        "macro_precision": 0.7705882352941176,
        "macro_recall": 0.7948717948717949,
        "macro_f1": 0.753880266075388,
        "weighted_precision": 0.8213036565977742,
        "weighted_recall": 0.7567567567567568,
        "weighted_f1": 0.761790615449152,
        "mcc": 0.5649383634074359
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4594594594594595,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.5135135135135135,
          "rmse": 0.8853156407653622,
          "mae": 0.6216216216216216,
          "quadratic_weighted_kappa": 0.28131279303415946
        },
        "curiosity": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.4594594594594595,
          "rmse": 0.9863939238321437,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.3392857142857143
        },
        "surprise": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.0134234194190634,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.10445859872611474
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "micro_precision": 0.7567567567567568,
        "micro_recall": 0.7567567567567568,
        "micro_f1": 0.7567567567567567,
        "macro_precision": 0.7602339181286549,
        "macro_recall": 0.7763975155279503,
        "macro_f1": 0.753880266075388,
        "weighted_precision": 0.7915283704757389,
        "weighted_recall": 0.7567567567567568,
        "weighted_f1": 0.7603523701084677,
        "mcc": 0.5363879507478305
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.972972972972973,
          "level_accuracy": 0.4594594594594595,
          "rmse": 0.8219949365267865,
          "mae": 0.6216216216216216,
          "quadratic_weighted_kappa": 0.4656268053148469
        },
        "curiosity": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.40540540540540543,
          "rmse": 1.0266713466606798,
          "mae": 0.7837837837837838,
          "quadratic_weighted_kappa": 0.24647519582245425
        },
        "surprise": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.40540540540540543,
          "rmse": 0.9299811099505543,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.2985781990521327
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8157894736842105,
        "micro_precision": 0.8157894736842105,
        "micro_recall": 0.8157894736842105,
        "micro_f1": 0.8157894736842104,
        "macro_precision": 0.8111111111111111,
        "macro_recall": 0.8246376811594203,
        "macro_f1": 0.8125440451021846,
        "weighted_precision": 0.8298245614035087,
        "weighted_recall": 0.8157894736842105,
        "weighted_f1": 0.8177367308334261,
        "mcc": 0.6356048762998656
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.9473684210526315,
          "level_accuracy": 0.5,
          "rmse": 0.9032106474595007,
          "mae": 0.7105263157894737,
          "quadratic_weighted_kappa": 0.36734693877551017
        },
        "curiosity": {
          "perfect_accuracy": 0.42105263157894735,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.5,
          "rmse": 0.9867543820659302,
          "mae": 0.7105263157894737,
          "quadratic_weighted_kappa": 0.4117154811715481
        },
        "surprise": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.4473684210526316,
          "rmse": 1.025978352085154,
          "mae": 0.7894736842105263,
          "quadratic_weighted_kappa": 0.24528301886792447
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7651515151515151,
        "macro_recall": 0.780448717948718,
        "macro_f1": 0.7701863354037266,
        "weighted_precision": 0.7944307944307943,
        "weighted_recall": 0.7837837837837838,
        "weighted_f1": 0.786805438979352,
        "mcc": 0.5453857441716
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.0,
          "mae": 0.7297297297297297,
          "quadratic_weighted_kappa": 0.2364751812604574
        },
        "curiosity": {
          "perfect_accuracy": 0.4864864864864865,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.0,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.43124221022019116
        },
        "surprise": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.2702702702702703,
          "rmse": 1.150792911137501,
          "mae": 0.9459459459459459,
          "quadratic_weighted_kappa": 0.12457749879285362
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.918918918918919,
        "micro_precision": 0.918918918918919,
        "micro_recall": 0.918918918918919,
        "micro_f1": 0.918918918918919,
        "macro_precision": 0.9068322981366459,
        "macro_recall": 0.9198717948717949,
        "macro_f1": 0.9125295508274232,
        "weighted_precision": 0.9216048346483129,
        "weighted_recall": 0.918918918918919,
        "weighted_f1": 0.9195578557280684,
        "mcc": 0.8266012514639709
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5135135135135135,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5405405405405406,
          "rmse": 0.9004503377814963,
          "mae": 0.5945945945945946,
          "quadratic_weighted_kappa": 0.607773851590106
        },
        "curiosity": {
          "perfect_accuracy": 0.5405405405405406,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5675675675675675,
          "rmse": 0.8853156407653622,
          "mae": 0.5675675675675675,
          "quadratic_weighted_kappa": 0.635406048250085
        },
        "surprise": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.43243243243243246,
          "rmse": 0.9586025865388216,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.42081031307550654
        }
      }
    }
  ]
}