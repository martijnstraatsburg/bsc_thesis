{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7795163584637269,
        "std": 0.046686664522858516
      },
      "micro_precision": {
        "mean": 0.7795163584637269,
        "std": 0.046686664522858516
      },
      "micro_recall": {
        "mean": 0.7795163584637269,
        "std": 0.046686664522858516
      },
      "micro_f1": {
        "mean": 0.7795163584637268,
        "std": 0.04668666452285853
      },
      "macro_precision": {
        "mean": 0.7671249949255066,
        "std": 0.045545289073157955
      },
      "macro_recall": {
        "mean": 0.7696444497531454,
        "std": 0.051638765161838227
      },
      "macro_f1": {
        "mean": 0.7639846223052484,
        "std": 0.050660578933790806
      },
      "weighted_precision": {
        "mean": 0.7878940785294265,
        "std": 0.04237488476194655
      },
      "weighted_recall": {
        "mean": 0.7795163584637269,
        "std": 0.046686664522858516
      },
      "weighted_f1": {
        "mean": 0.7797909641856814,
        "std": 0.04663978404398778
      },
      "mcc": {
        "mean": 0.5363971395127143,
        "std": 0.09587526545540354
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3332859174964439,
          "std": 0.06931060134241906
        },
        "off_by_one_accuracy": {
          "mean": 0.908534850640114,
          "std": 0.013611236089793113
        },
        "level_accuracy": {
          "mean": 0.4354196301564722,
          "std": 0.0386860928604755
        },
        "rmse": {
          "mean": 0.9955906710850172,
          "std": 0.0570224756776748
        },
        "mae": {
          "mean": 0.7688477951635846,
          "std": 0.07357648501472443
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3973892761332527,
          "std": 0.08643830045912865
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.40839260312944525,
          "std": 0.05840537975102883
        },
        "off_by_one_accuracy": {
          "mean": 0.7900426742532006,
          "std": 0.03285394033172583
        },
        "level_accuracy": {
          "mean": 0.5159317211948791,
          "std": 0.04689769049812947
        },
        "rmse": {
          "mean": 1.1400501058134238,
          "std": 0.04620577749040321
        },
        "mae": {
          "mean": 0.8176386913229019,
          "std": 0.07369135001687499
        },
        "quadratic_weighted_kappa": {
          "mean": 0.38776336381617005,
          "std": 0.09995109954211466
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.30085348506401144,
          "std": 0.0721799247918038
        },
        "off_by_one_accuracy": {
          "mean": 0.8601706970128025,
          "std": 0.03599058799628671
        },
        "level_accuracy": {
          "mean": 0.39743954480796584,
          "std": 0.0638981137932605
        },
        "rmse": {
          "mean": 1.102157320395,
          "std": 0.10620986560607314
        },
        "mae": {
          "mean": 0.8604551920341393,
          "std": 0.10686035952694319
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2963444760607278,
          "std": 0.1735272949202559
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "micro_precision": 0.7297297297297297,
        "micro_recall": 0.7297297297297297,
        "micro_f1": 0.7297297297297297,
        "macro_precision": 0.7191176470588235,
        "macro_recall": 0.7387820512820513,
        "macro_f1": 0.7196969696969697,
        "weighted_precision": 0.7580286168521463,
        "weighted_recall": 0.7297297297297297,
        "weighted_f1": 0.7354627354627356,
        "mcc": 0.45747726167232583
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.0,
          "mae": 0.8378378378378378,
          "quadratic_weighted_kappa": 0.40863930885529154
        },
        "curiosity": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.7837837837837838,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.2080808993852437,
          "mae": 0.918918918918919,
          "quadratic_weighted_kappa": 0.33311081441922563
        },
        "surprise": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.2411851354816252,
          "mae": 0.9459459459459459,
          "quadratic_weighted_kappa": 0.11794228356336267
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "micro_precision": 0.7567567567567568,
        "micro_recall": 0.7567567567567568,
        "micro_f1": 0.7567567567567567,
        "macro_precision": 0.7485294117647059,
        "macro_recall": 0.7624223602484472,
        "macro_f1": 0.7501875468867216,
        "weighted_precision": 0.7732114467408585,
        "weighted_recall": 0.7567567567567568,
        "weighted_f1": 0.7600413616917743,
        "mcc": 0.5107628601472598
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.40540540540540543,
          "rmse": 0.9299811099505543,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.36819637139807904
        },
        "curiosity": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.1740436015661335,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.24125452352231613
        },
        "surprise": {
          "perfect_accuracy": 0.1891891891891892,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.2972972972972973,
          "rmse": 1.138989594902999,
          "mae": 0.972972972972973,
          "quadratic_weighted_kappa": 0.11817279046673279
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7894736842105263,
        "micro_precision": 0.7894736842105263,
        "micro_recall": 0.7894736842105263,
        "micro_f1": 0.7894736842105263,
        "macro_precision": 0.7797101449275362,
        "macro_recall": 0.7797101449275362,
        "macro_f1": 0.7797101449275362,
        "weighted_precision": 0.7894736842105263,
        "weighted_recall": 0.7894736842105263,
        "weighted_f1": 0.7894736842105263,
        "mcc": 0.5594202898550724
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.9210526315789473,
          "level_accuracy": 0.4473684210526316,
          "rmse": 1.0130724502589556,
          "mae": 0.7631578947368421,
          "quadratic_weighted_kappa": 0.3606557377049181
        },
        "curiosity": {
          "perfect_accuracy": 0.4473684210526316,
          "off_by_one_accuracy": 0.8421052631578947,
          "level_accuracy": 0.5526315789473685,
          "rmse": 1.0760551736979407,
          "mae": 0.7368421052631579,
          "quadratic_weighted_kappa": 0.49394673123486676
        },
        "surprise": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.47368421052631576,
          "rmse": 1.0882143751650175,
          "mae": 0.8157894736842105,
          "quadratic_weighted_kappa": 0.35858964741185295
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "micro_precision": 0.7567567567567568,
        "micro_recall": 0.7567567567567568,
        "micro_f1": 0.7567567567567567,
        "macro_precision": 0.7388888888888889,
        "macro_recall": 0.7067307692307692,
        "macro_f1": 0.7161125319693095,
        "weighted_precision": 0.7504504504504504,
        "weighted_recall": 0.7567567567567568,
        "weighted_f1": 0.7480472800165895,
        "mcc": 0.44445779894466364
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.3783783783783784,
          "rmse": 1.0904995136125413,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.2952380952380953
        },
        "curiosity": {
          "perfect_accuracy": 0.4594594594594595,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.1270626736212455,
          "mae": 0.7837837837837838,
          "quadratic_weighted_kappa": 0.3655600145932143
        },
        "surprise": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.35135135135135137,
          "rmse": 1.1270626736212455,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.30244685118331316
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "micro_precision": 0.8648648648648649,
        "micro_recall": 0.8648648648648649,
        "micro_f1": 0.8648648648648649,
        "macro_precision": 0.8493788819875776,
        "macro_recall": 0.8605769230769231,
        "macro_f1": 0.8542159180457052,
        "weighted_precision": 0.8683061943931509,
        "weighted_recall": 0.8648648648648649,
        "weighted_f1": 0.8659297595467808,
        "mcc": 0.7098674869442498
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.4864864864864865,
          "rmse": 0.944400281603035,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.5542168674698795
        },
        "curiosity": {
          "perfect_accuracy": 0.4594594594594595,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.115008180796555,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.5049447353112274
        },
        "surprise": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.43243243243243246,
          "rmse": 0.9153348228041135,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.5845708076783774
        }
      }
    }
  ]
}