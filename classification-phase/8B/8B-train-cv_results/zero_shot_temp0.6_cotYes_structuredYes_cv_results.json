{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7674151296444801,
        "std": 0.06016895751172035
      },
      "micro_precision": {
        "mean": 0.7674151296444801,
        "std": 0.06016895751172035
      },
      "micro_recall": {
        "mean": 0.7674151296444801,
        "std": 0.06016895751172035
      },
      "micro_f1": {
        "mean": 0.7674151296444801,
        "std": 0.06016895751172034
      },
      "macro_precision": {
        "mean": 0.7674551663862583,
        "std": 0.06087328469815434
      },
      "macro_recall": {
        "mean": 0.7611906300120186,
        "std": 0.056720348117213916
      },
      "macro_f1": {
        "mean": 0.7625196263767064,
        "std": 0.058666266221887156
      },
      "weighted_precision": {
        "mean": 0.768702867852729,
        "std": 0.05970090003062331
      },
      "weighted_recall": {
        "mean": 0.7674151296444801,
        "std": 0.06016895751172035
      },
      "weighted_f1": {
        "mean": 0.7663327138187934,
        "std": 0.0599513901452525
      },
      "mcc": {
        "mean": 0.528556843370619,
        "std": 0.11728265889673188
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.37097032878909386,
          "std": 0.03361432314809432
        },
        "off_by_one_accuracy": {
          "mean": 0.7949478748997595,
          "std": 0.019584116416722298
        },
        "level_accuracy": {
          "mean": 0.5553595295375569,
          "std": 0.024739861887403156
        },
        "rmse": {
          "mean": 1.2108105566407767,
          "std": 0.037143726150839766
        },
        "mae": {
          "mean": 0.8778134188719593,
          "std": 0.039129064280531894
        },
        "quadratic_weighted_kappa": {
          "mean": 0.32106638186457415,
          "std": 0.05124603679171571
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.26035819299652496,
          "std": 0.013547015335149511
        },
        "off_by_one_accuracy": {
          "mean": 0.8273456295108259,
          "std": 0.057414442608872164
        },
        "level_accuracy": {
          "mean": 0.4978348035284683,
          "std": 0.03860678298034594
        },
        "rmse": {
          "mean": 1.2344204287881977,
          "std": 0.12112743655276656
        },
        "mae": {
          "mean": 0.967548783747661,
          "std": 0.07701753883677494
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3630238058429661,
          "std": 0.11909502950009475
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.33635391606522325,
          "std": 0.058042553235876516
        },
        "off_by_one_accuracy": {
          "mean": 0.7651162790697674,
          "std": 0.03384100778083945
        },
        "level_accuracy": {
          "mean": 0.5506014434643143,
          "std": 0.032963079792194296
        },
        "rmse": {
          "mean": 1.2912727083669395,
          "std": 0.06996378796903487
        },
        "mae": {
          "mean": 0.9584068430900828,
          "std": 0.07659443206724328
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2543049268928912,
          "std": 0.07191032651068517
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.8505747126436781,
        "micro_precision": 0.8505747126436781,
        "micro_recall": 0.8505747126436781,
        "micro_f1": 0.8505747126436781,
        "macro_precision": 0.8543859649122807,
        "macro_recall": 0.832967032967033,
        "macro_f1": 0.8403669724770643,
        "weighted_precision": 0.8519862875579755,
        "weighted_recall": 0.8505747126436781,
        "weighted_f1": 0.8482547716967206,
        "mcc": 0.6870191940899502
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.7931034482758621,
          "level_accuracy": 0.5287356321839081,
          "rmse": 1.2502873232999676,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.26307922272047823
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.896551724137931,
          "level_accuracy": 0.45977011494252873,
          "rmse": 1.0827805840074194,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.48141654978962134
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.7701149425287356,
          "level_accuracy": 0.5977011494252874,
          "rmse": 1.2364204916548043,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.3029937955544847
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7129120879120879,
        "macro_recall": 0.7061170212765957,
        "macro_f1": 0.7070707070707071,
        "weighted_precision": 0.7128015662498421,
        "weighted_recall": 0.7126436781609196,
        "weighted_f1": 0.710321606873331,
        "mcc": 0.41897401043129273
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8045977011494253,
          "level_accuracy": 0.5517241379310345,
          "rmse": 1.1986582537134602,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.2986133505320866
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7701149425287356,
          "level_accuracy": 0.47126436781609193,
          "rmse": 1.3433531557819876,
          "mae": 1.0229885057471264,
          "quadratic_weighted_kappa": 0.18807584854068826
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7241379310344828,
          "level_accuracy": 0.5172413793103449,
          "rmse": 1.3347693416475743,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.17081719239992632
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7464285714285714,
        "macro_recall": 0.7395833333333333,
        "macro_f1": 0.7413513513513514,
        "weighted_precision": 0.7467980295566503,
        "weighted_recall": 0.7471264367816092,
        "weighted_f1": 0.7453494874184529,
        "mcc": 0.48596369646889703
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7586206896551724,
          "level_accuracy": 0.5287356321839081,
          "rmse": 1.2548755490797328,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.27942687866513505
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.8045977011494253,
          "level_accuracy": 0.47126436781609193,
          "rmse": 1.2502873232999676,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.3441241685144124
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7586206896551724,
          "level_accuracy": 0.5747126436781609,
          "rmse": 1.2865350418053538,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.20799089644708557
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7011494252873564,
        "micro_precision": 0.7011494252873564,
        "micro_recall": 0.7011494252873564,
        "micro_f1": 0.7011494252873564,
        "macro_precision": 0.7005813953488372,
        "macro_recall": 0.702724358974359,
        "macro_f1": 0.7001590668080594,
        "weighted_precision": 0.7056936647955092,
        "weighted_recall": 0.7011494252873564,
        "weighted_f1": 0.7019417120707938,
        "mcc": 0.4033000609683836
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8160919540229885,
          "level_accuracy": 0.5862068965517241,
          "rmse": 1.1938539928826468,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.37583892617449666
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.7701149425287356,
          "level_accuracy": 0.5287356321839081,
          "rmse": 1.3854747308720783,
          "mae": 1.0689655172413792,
          "quadratic_weighted_kappa": 0.2933022034145628
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7471264367816092,
          "level_accuracy": 0.5517241379310345,
          "rmse": 1.3978637231524922,
          "mae": 1.0574712643678161,
          "quadratic_weighted_kappa": 0.22043010752688175
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8255813953488372,
        "micro_precision": 0.8255813953488372,
        "micro_recall": 0.8255813953488372,
        "micro_f1": 0.8255813953488372,
        "macro_precision": 0.8229678123295144,
        "macro_recall": 0.8245614035087719,
        "macro_f1": 0.82365003417635,
        "weighted_precision": 0.8262347911036679,
        "weighted_recall": 0.8255813953488372,
        "weighted_f1": 0.825795991034669,
        "mcc": 0.6475272548945715
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8023255813953488,
          "level_accuracy": 0.5813953488372093,
          "rmse": 1.156377664228076,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.3883735312306742
        },
        "curiosity": {
          "perfect_accuracy": 0.2558139534883721,
          "off_by_one_accuracy": 0.8953488372093024,
          "level_accuracy": 0.5581395348837209,
          "rmse": 1.1102063499795358,
          "mae": 0.8837209302325582,
          "quadratic_weighted_kappa": 0.508200258955546
        },
        "surprise": {
          "perfect_accuracy": 0.313953488372093,
          "off_by_one_accuracy": 0.8255813953488372,
          "level_accuracy": 0.5116279069767442,
          "rmse": 1.200774943574473,
          "mae": 0.9069767441860465,
          "quadratic_weighted_kappa": 0.3692926425360775
        }
      }
    }
  ]
}