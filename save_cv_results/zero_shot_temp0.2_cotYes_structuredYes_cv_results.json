{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8332859174964439,
        "std": 0.0578190200419243
      },
      "precision": {
        "mean": 0.8227256053835337,
        "std": 0.048407386907745216
      },
      "recall": {
        "mean": 0.8368901566269988,
        "std": 0.05708376998909248
      },
      "f1": {
        "mean": 0.8222233112623627,
        "std": 0.056519117063678924
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.3120910384068279,
          "std": 0.04538208365859998
        },
        "tolerance1_accuracy": {
          "mean": 0.881792318634424,
          "std": 0.03210636922825808
        },
        "tolerance2_accuracy": {
          "mean": 0.9678520625889047,
          "std": 0.0102418207681366
        },
        "rmse": {
          "mean": 1.094379551976203,
          "std": 0.07486714207008308
        },
        "kappa": {
          "mean": 0.08883138570688776,
          "std": 0.05340437048772547
        },
        "weighted_kappa": {
          "mean": 0.384380790032356,
          "std": 0.07480811722300795
        },
        "pearson_correlation": {
          "mean": 0.4827374001373282,
          "std": 0.10127115158479205
        },
        "pearson_p_value": {
          "mean": 0.007115947960380844,
          "std": 0.007040375863741293
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.2745376955903272,
          "std": 0.0681185886972458
        },
        "tolerance1_accuracy": {
          "mean": 0.8170697012802275,
          "std": 0.04692529564539409
        },
        "tolerance2_accuracy": {
          "mean": 0.9354196301564723,
          "std": 0.0405303074105448
        },
        "rmse": {
          "mean": 1.2554135299802702,
          "std": 0.14523057022922503
        },
        "kappa": {
          "mean": 0.08839354385820353,
          "std": 0.07777407707115844
        },
        "weighted_kappa": {
          "mean": 0.4199651447159498,
          "std": 0.08822912368867672
        },
        "pearson_correlation": {
          "mean": 0.5033969361163272,
          "std": 0.09567502206160966
        },
        "pearson_p_value": {
          "mean": 0.0067931200816133365,
          "std": 0.008308932432468264
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.3443812233285918,
          "std": 0.033992095661436926
        },
        "tolerance1_accuracy": {
          "mean": 0.7580369843527739,
          "std": 0.05134406114149087
        },
        "tolerance2_accuracy": {
          "mean": 0.946230440967283,
          "std": 0.029612091745978418
        },
        "rmse": {
          "mean": 1.2842104868693156,
          "std": 0.03404473808897718
        },
        "kappa": {
          "mean": 0.06820656184549789,
          "std": 0.05385589841957421
        },
        "weighted_kappa": {
          "mean": 0.22553888360485277,
          "std": 0.0727569162495113
        },
        "pearson_correlation": {
          "mean": 0.4007416814954309,
          "std": 0.10656859232788683
        },
        "pearson_p_value": {
          "mean": 0.04781901579229971,
          "std": 0.07740254728703823
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.8421052631578947,
        "precision": 0.8210227272727273,
        "recall": 0.8621794871794872,
        "f1": 0.8303571428571428
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2631578947368421,
          "tolerance1_accuracy": 0.868421052631579,
          "tolerance2_accuracy": 0.9473684210526315,
          "rmse": 1.180989772227204,
          "kappa": 0.04230423042304232,
          "weighted_kappa": 0.341399607586658,
          "pearson_correlation": 0.47091740939276416,
          "pearson_p_value": 0.002845130097930506
        },
        "curiosity": {
          "accuracy": 0.21052631578947367,
          "tolerance1_accuracy": 0.8421052631578947,
          "tolerance2_accuracy": 0.9473684210526315,
          "rmse": 1.2354415362426845,
          "kappa": 0.006968641114982632,
          "weighted_kappa": 0.46243902439024387,
          "pearson_correlation": 0.537850719699426,
          "pearson_p_value": 0.0004965317481096206
        },
        "surprise": {
          "accuracy": 0.2894736842105263,
          "tolerance1_accuracy": 0.7631578947368421,
          "tolerance2_accuracy": 0.9473684210526315,
          "rmse": 1.2977713690461004,
          "kappa": 0.0320754716981132,
          "weighted_kappa": 0.3015508328546811,
          "pearson_correlation": 0.5244074920562485,
          "pearson_p_value": 0.0007258695717112002
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "precision": 0.835,
        "recall": 0.8513986013986015,
        "f1": 0.8422847399829497
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2702702702702703,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1624763874381927,
          "kappa": 0.06983240223463683,
          "weighted_kappa": 0.3791946308724833,
          "pearson_correlation": 0.4262651918936272,
          "pearson_p_value": 0.00852064340120801
        },
        "curiosity": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0266713466606798,
          "kappa": 0.2225405921680994,
          "weighted_kappa": 0.5617977528089888,
          "pearson_correlation": 0.6301300450116416,
          "pearson_p_value": 2.9225666278573897e-05
        },
        "surprise": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.6756756756756757,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.3151918984428583,
          "kappa": 0.1060924369747901,
          "weighted_kappa": 0.2026936026936026,
          "pearson_correlation": 0.41015635831351316,
          "pearson_p_value": 0.01169267911988177
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "precision": 0.7772435897435898,
        "recall": 0.7529239766081872,
        "f1": 0.7501875468867216
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0134234194190634,
          "kappa": 0.12684365781710916,
          "weighted_kappa": 0.5303941215764862,
          "pearson_correlation": 0.6752325664137214,
          "pearson_p_value": 4.5510395677537824e-06
        },
        "curiosity": {
          "accuracy": 0.2702702702702703,
          "tolerance1_accuracy": 0.7567567567567568,
          "tolerance2_accuracy": 0.8648648648648649,
          "rmse": 1.461210161179813,
          "kappa": 0.11749116607773846,
          "weighted_kappa": 0.4199245882119468,
          "pearson_correlation": 0.5638864196499147,
          "pearson_p_value": 0.00027847661927627804
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.8918918918918919,
          "rmse": 1.30487650860252,
          "kappa": 0.09224730127576053,
          "weighted_kappa": 0.24391826143366835,
          "pearson_correlation": 0.3752651996088275,
          "pearson_p_value": 0.022099059568651307
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.918918918918919,
        "precision": 0.9068322981366459,
        "recall": 0.9198717948717949,
        "f1": 0.9125295508274232
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.115008180796555,
          "kappa": 0.032193158953722434,
          "weighted_kappa": 0.33515624999999993,
          "pearson_correlation": 0.4605284637299595,
          "pearson_p_value": 0.004127427558216994
        },
        "curiosity": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.2080808993852437,
          "kappa": 0.020793950850661713,
          "weighted_kappa": 0.3313253012048193,
          "pearson_correlation": 0.3804960021559912,
          "pearson_p_value": 0.020169634008827552
        },
        "surprise": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.7567567567567568,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.2192155209340498,
          "kappa": 0.12896622313203676,
          "weighted_kappa": 0.28269298554811406,
          "pearson_correlation": 0.4791593697642221,
          "pearson_p_value": 0.0026958687270173705
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "precision": 0.7735294117647059,
        "recall": 0.7980769230769231,
        "f1": 0.7757575757575759
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0,
          "kappa": 0.17298347910592804,
          "weighted_kappa": 0.3357593401261524,
          "pearson_correlation": 0.38074336925656876,
          "pearson_p_value": 0.020081987704980958
        },
        "curiosity": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.918918918918919,
          "rmse": 1.34566370643293,
          "kappa": 0.07417336907953542,
          "weighted_kappa": 0.3243390569637503,
          "pearson_correlation": 0.4046214940646622,
          "pearson_p_value": 0.012991732365574658
        },
        "surprise": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.7567567567567568,
          "tolerance2_accuracy": 0.9459459459459459,
          "rmse": 1.283997137321049,
          "kappa": -0.01834862385321112,
          "weighted_kappa": 0.09683873549419775,
          "pearson_correlation": 0.2147199877343429,
          "pearson_p_value": 0.20188160197423693
        }
      }
    }
  ]
}