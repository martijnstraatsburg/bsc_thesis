{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8118065433854907,
        "std": 0.04526869188761847
      },
      "precision": {
        "mean": 0.7950331198592069,
        "std": 0.038044252368667465
      },
      "recall": {
        "mean": 0.8006246677299309,
        "std": 0.05411982844820915
      },
      "f1": {
        "mean": 0.7938495653803562,
        "std": 0.04643311514205011
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.3226173541963016,
          "std": 0.054161755397609174
        },
        "tolerance1_accuracy": {
          "mean": 0.8657183499288763,
          "std": 0.04474447397174967
        },
        "tolerance2_accuracy": {
          "mean": 0.9677098150782362,
          "std": 0.010885420466406273
        },
        "rmse": {
          "mean": 1.1102229236705348,
          "std": 0.09530781910388449
        },
        "kappa": {
          "mean": 0.10818454186532153,
          "std": 0.06154359097585365
        },
        "weighted_kappa": {
          "mean": 0.38663879933889767,
          "std": 0.09205194092222095
        },
        "pearson_correlation": {
          "mean": 0.4749755567035712,
          "std": 0.11629443707545539
        },
        "pearson_p_value": {
          "mean": 0.012150595629411705,
          "std": 0.01443563721736935
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.2638691322901849,
          "std": 0.09033556932749603
        },
        "tolerance1_accuracy": {
          "mean": 0.8062588904694167,
          "std": 0.05565060044981529
        },
        "tolerance2_accuracy": {
          "mean": 0.9406827880512092,
          "std": 0.031665970082483966
        },
        "rmse": {
          "mean": 1.2617832407343612,
          "std": 0.1477948221265279
        },
        "kappa": {
          "mean": 0.07726544767317174,
          "std": 0.09533386072762771
        },
        "weighted_kappa": {
          "mean": 0.3877813244671177,
          "std": 0.08971142954258067
        },
        "pearson_correlation": {
          "mean": 0.4735170228003459,
          "std": 0.09789957388348915
        },
        "pearson_p_value": {
          "mean": 0.01191153738375815,
          "std": 0.01457688762169142
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.31152204836415365,
          "std": 0.041060034091068405
        },
        "tolerance1_accuracy": {
          "mean": 0.7796586059743955,
          "std": 0.04267520150677016
        },
        "tolerance2_accuracy": {
          "mean": 0.9568990042674252,
          "std": 0.02172990777118442
        },
        "rmse": {
          "mean": 1.2492452315232452,
          "std": 0.06628320972891028
        },
        "kappa": {
          "mean": 0.0523609107715987,
          "std": 0.05157414158748997
        },
        "weighted_kappa": {
          "mean": 0.2539198106479789,
          "std": 0.061554287906568354
        },
        "pearson_correlation": {
          "mean": 0.4004523006754793,
          "std": 0.08551534716271376
        },
        "pearson_p_value": {
          "mean": 0.03487690779720089,
          "std": 0.05199358948317646
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.8157894736842105,
        "precision": 0.7861538461538462,
        "recall": 0.7980769230769231,
        "f1": 0.7913725490196077
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3157894736842105,
          "tolerance1_accuracy": 0.8421052631578947,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.1355499479153377,
          "kappa": 0.08940092165898628,
          "weighted_kappa": 0.3679565512559402,
          "pearson_correlation": 0.48896022201317657,
          "pearson_p_value": 0.0018389475826004094
        },
        "curiosity": {
          "accuracy": 0.18421052631578946,
          "tolerance1_accuracy": 0.8421052631578947,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.1920791213585393,
          "kappa": -0.01727115716753036,
          "weighted_kappa": 0.42488789237668156,
          "pearson_correlation": 0.48711594916591394,
          "pearson_p_value": 0.0019249289988908748
        },
        "surprise": {
          "accuracy": 0.3684210526315789,
          "tolerance1_accuracy": 0.7631578947368421,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.2139539573337679,
          "kappa": 0.12223291626564003,
          "weighted_kappa": 0.32615579480683976,
          "pearson_correlation": 0.48699355338001016,
          "pearson_p_value": 0.0019307581838393585
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.7759259259259259,
        "recall": 0.7604895104895104,
        "f1": 0.7672955974842768
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.9459459459459459,
          "rmse": 1.2302493704584911,
          "kappa": 0.035381750465549255,
          "weighted_kappa": 0.3046979865771813,
          "pearson_correlation": 0.3425210568490385,
          "pearson_p_value": 0.037967679248886325
        },
        "curiosity": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0266713466606798,
          "kappa": 0.2135265700483091,
          "weighted_kappa": 0.5301204819277108,
          "pearson_correlation": 0.5917798401635781,
          "pearson_p_value": 0.00011444432610306583
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1740436015661335,
          "kappa": 0.048353909465020606,
          "weighted_kappa": 0.3195095564370717,
          "pearson_correlation": 0.4750113762628242,
          "pearson_p_value": 0.0029701013201588284
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "precision": 0.7406832298136645,
        "recall": 0.7266081871345029,
        "f1": 0.724702380952381
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0134234194190634,
          "kappa": 0.11377245508982037,
          "weighted_kappa": 0.5417209908735332,
          "pearson_correlation": 0.680101963698979,
          "pearson_p_value": 3.6522056858168897e-06
        },
        "curiosity": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.7297297297297297,
          "tolerance2_accuracy": 0.8918918918918919,
          "rmse": 1.451932542547383,
          "kappa": 0.08883025505716802,
          "weighted_kappa": 0.392421052631579,
          "pearson_correlation": 0.5646058964132049,
          "pearson_p_value": 0.00027243143425093524
        },
        "surprise": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.918918918918919,
          "rmse": 1.2944789205219511,
          "kappa": 0.04658077304261643,
          "weighted_kappa": 0.2527687296416937,
          "pearson_correlation": 0.409726082617532,
          "pearson_p_value": 0.01178955342641302
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "precision": 0.8212121212121212,
        "recall": 0.8397435897435898,
        "f1": 0.8276397515527949
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1854979567276382,
          "kappa": 0.08206106870229002,
          "weighted_kappa": 0.28951255539143284,
          "pearson_correlation": 0.3866434292163298,
          "pearson_p_value": 0.018083781755127374
        },
        "curiosity": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.9459459459459459,
          "rmse": 1.2627725822944504,
          "kappa": 0.1411327762302692,
          "weighted_kappa": 0.3243577839678118,
          "pearson_correlation": 0.3793613024803621,
          "pearson_p_value": 0.020575777053011078
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.7027027027027027,
          "tolerance2_accuracy": 0.9459459459459459,
          "rmse": 1.35566877880913,
          "kappa": 0.07960199004975121,
          "weighted_kappa": 0.1920359666024406,
          "pearson_correlation": 0.38203446406217273,
          "pearson_p_value": 0.019629672723223662
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "precision": 0.8511904761904762,
        "recall": 0.8782051282051282,
        "f1": 0.8582375478927203
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 0.9863939238321437,
          "kappa": 0.22030651340996177,
          "weighted_kappa": 0.42930591259640105,
          "pearson_correlation": 0.47665111174033215,
          "pearson_p_value": 0.00285891735475859
        },
        "curiosity": {
          "accuracy": 0.16216216216216217,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.918918918918919,
          "rmse": 1.3754606108107539,
          "kappa": -0.03989120580235728,
          "weighted_kappa": 0.2671194114318053,
          "pearson_correlation": 0.34472212577867045,
          "pearson_p_value": 0.036670105106534796
        },
        "surprise": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.2080808993852437,
          "kappa": -0.03496503496503478,
          "weighted_kappa": 0.17912900575184887,
          "pearson_correlation": 0.24849602705485774,
          "pearson_p_value": 0.13806445333236958
        }
      }
    }
  ]
}