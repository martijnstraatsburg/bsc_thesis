{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7745376955903271,
        "std": 0.047986138814887634
      },
      "precision": {
        "mean": 0.7556558054051661,
        "std": 0.048884436068493714
      },
      "recall": {
        "mean": 0.770264384738069,
        "std": 0.05451831201519329
      },
      "f1": {
        "mean": 0.7586391456011479,
        "std": 0.04983352070471059
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.3813655761024183,
          "std": 0.051924043594501625
        },
        "tolerance1_accuracy": {
          "mean": 0.9409672830725462,
          "std": 0.019782123546164983
        },
        "tolerance2_accuracy": {
          "mean": 1.0,
          "std": 0.0
        },
        "rmse": {
          "mean": 0.8913202825043502,
          "std": 0.03578726975208218
        },
        "kappa": {
          "mean": 0.12897351936835688,
          "std": 0.06834576077249808
        },
        "weighted_kappa": {
          "mean": 0.37191191408574087,
          "std": 0.11482232273303938
        },
        "pearson_correlation": {
          "mean": 0.44036296351626386,
          "std": 0.1388276397316295
        },
        "pearson_p_value": {
          "mean": 0.027229120658848537,
          "std": 0.03310658386488561
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.4780938833570413,
          "std": 0.0633926154980989
        },
        "tolerance1_accuracy": {
          "mean": 0.8601706970128022,
          "std": 0.020463875400687854
        },
        "tolerance2_accuracy": {
          "mean": 1.0,
          "std": 0.0
        },
        "rmse": {
          "mean": 0.9682164284853151,
          "std": 0.062856767461367
        },
        "kappa": {
          "mean": 0.2413669712398451,
          "std": 0.0926232739312004
        },
        "weighted_kappa": {
          "mean": 0.4271260084168561,
          "std": 0.1272352899114147
        },
        "pearson_correlation": {
          "mean": 0.4427038724777156,
          "std": 0.12426933491327385
        },
        "pearson_p_value": {
          "mean": 0.038330672076320196,
          "std": 0.06675065178030143
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.37069701280227596,
          "std": 0.046951160730301554
        },
        "tolerance1_accuracy": {
          "mean": 0.908534850640114,
          "std": 0.013611236089793113
        },
        "tolerance2_accuracy": {
          "mean": 0.9945945945945945,
          "std": 0.010810810810810789
        },
        "rmse": {
          "mean": 0.9629861424008335,
          "std": 0.0581648678187396
        },
        "kappa": {
          "mean": 0.08861602687093366,
          "std": 0.059251543862744664
        },
        "weighted_kappa": {
          "mean": 0.27986759857651505,
          "std": 0.13227681277190856
        },
        "pearson_correlation": {
          "mean": 0.3056944471145978,
          "std": 0.14174109081330374
        },
        "pearson_p_value": {
          "mean": 0.18110719523075333,
          "std": 0.2406335861751531
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7105263157894737,
        "precision": 0.6797101449275362,
        "recall": 0.6987179487179487,
        "f1": 0.6840513983371126
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.4473684210526316,
          "tolerance1_accuracy": 0.9210526315789473,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8885233166386386,
          "kappa": 0.17561983471074383,
          "weighted_kappa": 0.24403183023872688,
          "pearson_correlation": 0.2796210504641787,
          "pearson_p_value": 0.08908909745912408
        },
        "curiosity": {
          "accuracy": 0.5526315789473685,
          "tolerance1_accuracy": 0.868421052631579,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9176629354822471,
          "kappa": 0.3298755186721992,
          "weighted_kappa": 0.5182250396196513,
          "pearson_correlation": 0.5260526270817658,
          "pearson_p_value": 0.0006934939036495868
        },
        "surprise": {
          "accuracy": 0.42105263157894735,
          "tolerance1_accuracy": 0.9210526315789473,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9032106474595007,
          "kappa": 0.15810674723061435,
          "weighted_kappa": 0.380651945320715,
          "pearson_correlation": 0.39576954615194515,
          "pearson_p_value": 0.013911306775398397
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.7733333333333333,
        "recall": 0.7867132867132867,
        "f1": 0.7791986359761296
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9586025865388216,
          "kappa": 0.13873370577281197,
          "weighted_kappa": 0.4408888888888889,
          "pearson_correlation": 0.4601596290990386,
          "pearson_p_value": 0.0041614014611436176
        },
        "curiosity": {
          "accuracy": 0.5405405405405406,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8853156407653622,
          "kappa": 0.3522142121524202,
          "weighted_kappa": 0.5797101449275363,
          "pearson_correlation": 0.5866191471555662,
          "pearson_p_value": 0.00013574103221082468
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9586025865388216,
          "kappa": 0.08777120315581843,
          "weighted_kappa": 0.4032258064516129,
          "pearson_correlation": 0.44550147355482644,
          "pearson_p_value": 0.005723242915882406
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "precision": 0.7321428571428572,
        "recall": 0.7280701754385965,
        "f1": 0.7279411764705883
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8853156407653622,
          "kappa": 0.20318352059925093,
          "weighted_kappa": 0.5618619844834627,
          "pearson_correlation": 0.6885855466778688,
          "pearson_p_value": 2.464471213148769e-06
        },
        "curiosity": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0397504898200727,
          "kappa": 0.1777777777777777,
          "weighted_kappa": 0.4398183194549583,
          "pearson_correlation": 0.4809194008265554,
          "pearson_p_value": 0.002586363704006763
        },
        "surprise": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0526671402243484,
          "kappa": 0.13534566699123662,
          "weighted_kappa": 0.3671255736337089,
          "pearson_correlation": 0.40970047580706664,
          "pearson_p_value": 0.011795340055671738
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "precision": 0.8279411764705882,
        "recall": 0.8573717948717949,
        "f1": 0.8318181818181818
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.43243243243243246,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8542421961772491,
          "kappa": 0.12302483069977421,
          "weighted_kappa": 0.297962052002811,
          "pearson_correlation": 0.34952864391217064,
          "pearson_p_value": 0.033961924253500114
        },
        "curiosity": {
          "accuracy": 0.4864864864864865,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9586025865388216,
          "kappa": 0.2424568965517241,
          "weighted_kappa": 0.38932038834951455,
          "pearson_correlation": 0.3901376318542011,
          "pearson_p_value": 0.016980908492839134
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0,
          "kappa": -0.013143483023001057,
          "weighted_kappa": 0.06934058463630188,
          "pearson_correlation": 0.08291466342456831,
          "pearson_p_value": 0.6256340067706564
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "precision": 0.7651515151515151,
        "recall": 0.780448717948718,
        "f1": 0.7701863354037266
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.972972972972973,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.86991767240168,
          "kappa": 0.0043057050592034685,
          "weighted_kappa": 0.3148148148148149,
          "pearson_correlation": 0.4239199474280625,
          "pearson_p_value": 0.008930715649261728
        },
        "curiosity": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0397504898200727,
          "kappa": 0.10451045104510437,
          "weighted_kappa": 0.20855614973262016,
          "pearson_correlation": 0.2297905554704895,
          "pearson_p_value": 0.17125685324889467
        },
        "surprise": {
          "accuracy": 0.43243243243243246,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9004503377814963,
          "kappa": 0.07499999999999996,
          "weighted_kappa": 0.17899408284023666,
          "pearson_correlation": 0.1945860766345823,
          "pearson_p_value": 0.24847207963615775
        }
      }
    }
  ]
}