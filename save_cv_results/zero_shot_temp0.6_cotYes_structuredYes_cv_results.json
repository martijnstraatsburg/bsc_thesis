{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8495021337126601,
        "std": 0.036448686743919295
      },
      "precision": {
        "mean": 0.8376479113384484,
        "std": 0.04577700558656684
      },
      "recall": {
        "mean": 0.8512626262626263,
        "std": 0.0319470179048512
      },
      "f1": {
        "mean": 0.8381552401259167,
        "std": 0.03787531483293783
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.322475106685633,
          "std": 0.0677396924172764
        },
        "tolerance1_accuracy": {
          "mean": 0.8443812233285918,
          "std": 0.03399209566143692
        },
        "tolerance2_accuracy": {
          "mean": 0.97325746799431,
          "std": 0.01664721347178129
        },
        "rmse": {
          "mean": 1.126845669668754,
          "std": 0.09117411971507332
        },
        "kappa": {
          "mean": 0.10635396926134884,
          "std": 0.06979779110507936
        },
        "weighted_kappa": {
          "mean": 0.35923290947997744,
          "std": 0.08797319438631547
        },
        "pearson_correlation": {
          "mean": 0.4546762168302256,
          "std": 0.11128259356468878
        },
        "pearson_p_value": {
          "mean": 0.012226338248938212,
          "std": 0.008922654084861585
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.3227596017069701,
          "std": 0.09718160041585347
        },
        "tolerance1_accuracy": {
          "mean": 0.8064011379800853,
          "std": 0.07916735334490058
        },
        "tolerance2_accuracy": {
          "mean": 0.9354196301564723,
          "std": 0.036749445476434134
        },
        "rmse": {
          "mean": 1.2425664693020622,
          "std": 0.1922690899146818
        },
        "kappa": {
          "mean": 0.1530416358168319,
          "std": 0.10169694917057871
        },
        "weighted_kappa": {
          "mean": 0.3888784930853487,
          "std": 0.163670748419056
        },
        "pearson_correlation": {
          "mean": 0.4676663792289723,
          "std": 0.17441506763522907
        },
        "pearson_p_value": {
          "mean": 0.03887282297342898,
          "std": 0.05845976780856385
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.3330014224751067,
          "std": 0.036804464589009905
        },
        "tolerance1_accuracy": {
          "mean": 0.7849217638691324,
          "std": 0.017244247465936544
        },
        "tolerance2_accuracy": {
          "mean": 0.9300142247510669,
          "std": 0.027734981751246526
        },
        "rmse": {
          "mean": 1.2871274548921012,
          "std": 0.07392615927494371
        },
        "kappa": {
          "mean": 0.07180049100552663,
          "std": 0.05786216896935507
        },
        "weighted_kappa": {
          "mean": 0.21997353205326756,
          "std": 0.10272210006370427
        },
        "pearson_correlation": {
          "mean": 0.35356632582841807,
          "std": 0.17172393584489667
        },
        "pearson_p_value": {
          "mean": 0.16593008727586328,
          "std": 0.2716038764278128
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.8421052631578947,
        "precision": 0.8154761904761905,
        "recall": 0.8397435897435898,
        "f1": 0.8246153846153845
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.34210526315789475,
          "tolerance1_accuracy": 0.7894736842105263,
          "tolerance2_accuracy": 0.9473684210526315,
          "rmse": 1.2460463791317595,
          "kappa": 0.12764003673094582,
          "weighted_kappa": 0.25712392312789933,
          "pearson_correlation": 0.3786211032095429,
          "pearson_p_value": 0.019076686217279964
        },
        "curiosity": {
          "accuracy": 0.2894736842105263,
          "tolerance1_accuracy": 0.8157894736842105,
          "tolerance2_accuracy": 0.9473684210526315,
          "rmse": 1.2354415362426845,
          "kappa": 0.12457337883959052,
          "weighted_kappa": 0.3401197604790419,
          "pearson_correlation": 0.3893905277236798,
          "pearson_p_value": 0.01567421380154552
        },
        "surprise": {
          "accuracy": 0.39473684210526316,
          "tolerance1_accuracy": 0.7894736842105263,
          "tolerance2_accuracy": 0.9473684210526315,
          "rmse": 1.224744871391589,
          "kappa": 0.16523400191021975,
          "weighted_kappa": 0.31063017186505404,
          "pearson_correlation": 0.45016687947540435,
          "pearson_p_value": 0.004569681604
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "precision": 0.835,
        "recall": 0.8513986013986015,
        "f1": 0.8422847399829497
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1740436015661335,
          "kappa": 0.04162812210915823,
          "weighted_kappa": 0.3749585955614442,
          "pearson_correlation": 0.4410475901536433,
          "pearson_p_value": 0.006288236958468765
        },
        "curiosity": {
          "accuracy": 0.5135135135135135,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 0.8853156407653622,
          "kappa": 0.3476983349657199,
          "weighted_kappa": 0.6588235294117647,
          "pearson_correlation": 0.7018995964368842,
          "pearson_p_value": 1.2937102317184724e-06
        },
        "surprise": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.196842693269434,
          "kappa": 0.07306889352818369,
          "weighted_kappa": 0.31791304347826077,
          "pearson_correlation": 0.5531536509474498,
          "pearson_p_value": 0.0003840790202432002
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8918918918918919,
        "precision": 0.9130434782608696,
        "recall": 0.8888888888888888,
        "f1": 0.8898809523809523
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0134234194190634,
          "kappa": 0.14814814814814803,
          "weighted_kappa": 0.5184931506849315,
          "pearson_correlation": 0.6710792491648093,
          "pearson_p_value": 5.472981789363519e-06
        },
        "curiosity": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.8918918918918919,
          "rmse": 1.34566370643293,
          "kappa": 0.1479185119574845,
          "weighted_kappa": 0.46905118869136864,
          "pearson_correlation": 0.6385140328522289,
          "pearson_p_value": 2.115483612616066e-05
        },
        "surprise": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.7567567567567568,
          "tolerance2_accuracy": 0.8918918918918919,
          "rmse": 1.404625563263382,
          "kappa": 0.05221674876847293,
          "weighted_kappa": 0.1827534039334342,
          "pearson_correlation": 0.2631624666993679,
          "pearson_p_value": 0.11555781653451422
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "precision": 0.8511904761904762,
        "recall": 0.8782051282051282,
        "f1": 0.8582375478927203
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1740436015661335,
          "kappa": 0.012392755004766554,
          "weighted_kappa": 0.3214670981661273,
          "pearson_correlation": 0.41465962640259196,
          "pearson_p_value": 0.010718647463620598
        },
        "curiosity": {
          "accuracy": 0.2702702702702703,
          "tolerance1_accuracy": 0.7297297297297297,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.2944789205219511,
          "kappa": 0.07500000000000007,
          "weighted_kappa": 0.29675045984058857,
          "pearson_correlation": 0.36953671630070234,
          "pearson_p_value": 0.0243856956181198
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.918918918918919,
          "rmse": 1.283997137321049,
          "kappa": 0.08325074331020821,
          "weighted_kappa": 0.24941802460924523,
          "pearson_correlation": 0.4363250556837064,
          "pearson_p_value": 0.00693909543850942
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "precision": 0.7735294117647059,
        "recall": 0.7980769230769231,
        "f1": 0.7757575757575759
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0266713466606798,
          "kappa": 0.20196078431372555,
          "weighted_kappa": 0.32412177985948476,
          "pearson_correlation": 0.36797351522054056,
          "pearson_p_value": 0.02504264762353237
        },
        "curiosity": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.7297297297297297,
          "tolerance2_accuracy": 0.8918918918918919,
          "rmse": 1.451932542547383,
          "kappa": 0.07001795332136451,
          "weighted_kappa": 0.17964752700397957,
          "pearson_correlation": 0.2389910228313663,
          "pearson_p_value": 0.15428175690112167
        },
        "surprise": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.918918918918919,
          "rmse": 1.3254270092150517,
          "kappa": -0.014767932489451407,
          "weighted_kappa": 0.03915301638034352,
          "pearson_correlation": 0.06502357633616197,
          "pearson_p_value": 0.7021997637820496
        }
      }
    }
  ]
}