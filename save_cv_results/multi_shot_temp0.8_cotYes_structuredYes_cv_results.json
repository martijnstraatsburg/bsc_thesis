{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.785064011379801,
        "std": 0.033257942554903434
      },
      "precision": {
        "mean": 0.7736561272106096,
        "std": 0.026310777925675235
      },
      "recall": {
        "mean": 0.7954090500143132,
        "std": 0.03863458328846886
      },
      "f1": {
        "mean": 0.773918141457158,
        "std": 0.03170625330673225
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.36543385490753916,
          "std": 0.030143049698083995
        },
        "tolerance1_accuracy": {
          "mean": 0.9300142247510669,
          "std": 0.021841362978855448
        },
        "tolerance2_accuracy": {
          "mean": 1.0,
          "std": 0.0
        },
        "rmse": {
          "mean": 0.9184754233528389,
          "std": 0.030436286502852024
        },
        "kappa": {
          "mean": 0.1114346482770983,
          "std": 0.07968919253687026
        },
        "weighted_kappa": {
          "mean": 0.3596970141593016,
          "std": 0.10615419992902939
        },
        "pearson_correlation": {
          "mean": 0.4055758178669288,
          "std": 0.12494854986248848
        },
        "pearson_p_value": {
          "mean": 0.03925769994188939,
          "std": 0.041072816275630246
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.4728307254623044,
          "std": 0.06718300384515064
        },
        "tolerance1_accuracy": {
          "mean": 0.8226173541963016,
          "std": 0.04023266590589141
        },
        "tolerance2_accuracy": {
          "mean": 0.9945945945945945,
          "std": 0.010810810810810789
        },
        "rmse": {
          "mean": 1.040909305727502,
          "std": 0.053404646106005094
        },
        "kappa": {
          "mean": 0.2470183895298932,
          "std": 0.08727805923623104
        },
        "weighted_kappa": {
          "mean": 0.3610733134670146,
          "std": 0.051458670239388965
        },
        "pearson_correlation": {
          "mean": 0.39399148056988015,
          "std": 0.05083111603146058
        },
        "pearson_p_value": {
          "mean": 0.021494245267866238,
          "std": 0.016720580373272044
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.42460881934566147,
          "std": 0.07822578491013114
        },
        "tolerance1_accuracy": {
          "mean": 0.8817923186344239,
          "std": 0.03637310848675289
        },
        "tolerance2_accuracy": {
          "mean": 0.9945945945945945,
          "std": 0.010810810810810789
        },
        "rmse": {
          "mean": 0.9740482734817704,
          "std": 0.09094620775643103
        },
        "kappa": {
          "mean": 0.18005563475154412,
          "std": 0.12524642768204314
        },
        "weighted_kappa": {
          "mean": 0.33152426634083804,
          "std": 0.12297423050588199
        },
        "pearson_correlation": {
          "mean": 0.35696864462166034,
          "std": 0.13442161092512714
        },
        "pearson_p_value": {
          "mean": 0.0879584725313983,
          "std": 0.11488577001206492
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7631578947368421,
        "precision": 0.7464985994397759,
        "recall": 0.782051282051282,
        "f1": 0.7490829053558328
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.39473684210526316,
          "tolerance1_accuracy": 0.9473684210526315,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8735890880367281,
          "kappa": 0.11088504577822988,
          "weighted_kappa": 0.2980891719745222,
          "pearson_correlation": 0.33205020646854416,
          "pearson_p_value": 0.0416789037521763
        },
        "curiosity": {
          "accuracy": 0.5263157894736842,
          "tolerance1_accuracy": 0.8157894736842105,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0130724502589556,
          "kappa": 0.3062880324543611,
          "weighted_kappa": 0.4105011933174223,
          "pearson_correlation": 0.4422361866062092,
          "pearson_p_value": 0.005435830286935623
        },
        "surprise": {
          "accuracy": 0.4473684210526316,
          "tolerance1_accuracy": 0.868421052631579,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9733285267845752,
          "kappa": 0.21379310344827585,
          "weighted_kappa": 0.39091718610863757,
          "pearson_correlation": 0.3990564466131534,
          "pearson_p_value": 0.01307037849479193
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.7779503105590062,
        "recall": 0.8129370629370629,
        "f1": 0.7885714285714287
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.944400281603035,
          "kappa": 0.15105162523900562,
          "weighted_kappa": 0.45515394912985274,
          "pearson_correlation": 0.47143473031528904,
          "pearson_p_value": 0.0032257823224346584
        },
        "curiosity": {
          "accuracy": 0.5405405405405406,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0526671402243484,
          "kappa": 0.36400404448938317,
          "weighted_kappa": 0.4225352112676056,
          "pearson_correlation": 0.4621612059612603,
          "pearson_p_value": 0.003979906735410421
        },
        "surprise": {
          "accuracy": 0.5675675675675675,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.86991767240168,
          "kappa": 0.4002026342451874,
          "weighted_kappa": 0.5282331511839709,
          "pearson_correlation": 0.5810235028415003,
          "pearson_p_value": 0.00016280664456773823
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "precision": 0.7406832298136645,
        "recall": 0.7266081871345029,
        "f1": 0.724702380952381
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9586025865388216,
          "kappa": 0.235680751173709,
          "weighted_kappa": 0.5055031446540881,
          "pearson_correlation": 0.6165331156162387,
          "pearson_p_value": 4.8400296898025456e-05
        },
        "curiosity": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.138989594902999,
          "kappa": 0.11022044088176364,
          "weighted_kappa": 0.29186602870813383,
          "pearson_correlation": 0.37204114216642004,
          "pearson_p_value": 0.023362986172834662
        },
        "surprise": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.115008180796555,
          "kappa": 0.16404715127701386,
          "weighted_kappa": 0.29377593360995846,
          "pearson_correlation": 0.33248011900440777,
          "pearson_p_value": 0.04436887091485198
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.8070175438596491,
        "recall": 0.8365384615384616,
        "f1": 0.805701425356339
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9004503377814963,
          "kappa": 0.056323060573857386,
          "weighted_kappa": 0.3248175182481752,
          "pearson_correlation": 0.3436216599823005,
          "pearson_p_value": 0.037314261514396645
        },
        "curiosity": {
          "accuracy": 0.4864864864864865,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 0.9863939238321437,
          "kappa": 0.25371549893842893,
          "weighted_kappa": 0.3663177925784966,
          "pearson_correlation": 0.3691290437221823,
          "pearson_p_value": 0.024555632082411308
        },
        "surprise": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0266713466606798,
          "kappa": 0.04925053533190582,
          "weighted_kappa": 0.15860058309037905,
          "pearson_correlation": 0.17065937905658035,
          "pearson_p_value": 0.3125508900324852
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.7961309523809523,
        "recall": 0.8189102564102564,
        "f1": 0.8015325670498084
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9153348228041135,
          "kappa": 0.003232758620689613,
          "weighted_kappa": 0.21492128678986988,
          "pearson_correlation": 0.26423937695227173,
          "pearson_p_value": 0.11402115182354135
        },
        "curiosity": {
          "accuracy": 0.4594594594594595,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0134234194190634,
          "kappa": 0.20086393088552912,
          "weighted_kappa": 0.3141463414634146,
          "pearson_correlation": 0.32438982439332875,
          "pearson_p_value": 0.050136871061739176
        },
        "surprise": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8853156407653622,
          "kappa": 0.07298474945533773,
          "weighted_kappa": 0.2860944777112443,
          "pearson_correlation": 0.3016237755926596,
          "pearson_p_value": 0.06963941657029458
        }
      }
    }
  ]
}