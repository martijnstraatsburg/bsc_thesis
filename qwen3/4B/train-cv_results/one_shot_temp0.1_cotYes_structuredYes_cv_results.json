{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7488372093023256,
        "std": 0.025678623054544877
      },
      "micro_precision": {
        "mean": 0.7488372093023256,
        "std": 0.025678623054544877
      },
      "micro_recall": {
        "mean": 0.7488372093023256,
        "std": 0.025678623054544877
      },
      "micro_f1": {
        "mean": 0.7488372093023256,
        "std": 0.025678623054544877
      },
      "macro_precision": {
        "mean": 0.7452283633707937,
        "std": 0.027817647018458434
      },
      "macro_recall": {
        "mean": 0.7448531457436338,
        "std": 0.029170102050567807
      },
      "macro_f1": {
        "mean": 0.7441169109582555,
        "std": 0.02873351775547686
      },
      "mcc": {
        "mean": 0.4900574404314478,
        "std": 0.05682123477025984
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4007484629778134,
          "std": 0.048889611345185095
        },
        "off_by_one_accuracy": {
          "mean": 0.8525527933707565,
          "std": 0.028431642727423486
        },
        "rmse": {
          "mean": 1.1057920914718995,
          "std": 0.05591078281220682
        },
        "mae": {
          "mean": 0.7835605453087411,
          "std": 0.06762388342668908
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4338298695491554,
          "std": 0.05511002192726929
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3017642341619887,
          "std": 0.022492107341047604
        },
        "off_by_one_accuracy": {
          "mean": 0.799572306869821,
          "std": 0.030283271076546544
        },
        "rmse": {
          "mean": 1.2028858847288575,
          "std": 0.04909830154380909
        },
        "mae": {
          "mean": 0.9286287089013634,
          "std": 0.03656440158319799
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4453137535715189,
          "std": 0.0408744265957359
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3386260358192996,
          "std": 0.04962997089619545
        },
        "off_by_one_accuracy": {
          "mean": 0.8087409783480354,
          "std": 0.036849577888404365
        },
        "rmse": {
          "mean": 1.2165626813635444,
          "std": 0.11401095617306352
        },
        "mae": {
          "mean": 0.9032878909382518,
          "std": 0.10394122782615589
        },
        "quadratic_weighted_kappa": {
          "mean": 0.37740276918216276,
          "std": 0.10152907539500124
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7061598224195338,
        "macro_recall": 0.7008108108108109,
        "macro_f1": 0.7025844386708602,
        "mcc": 0.406935479390428
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0339078862458586,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4517178288269974
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2129568697262454,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.45443856554967665
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2909944487358056,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.35350791779839075
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7419871794871795,
        "macro_recall": 0.7448648648648648,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48684353956546655
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1596670152276025,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.37394673719170923
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2317635241028795,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.43137254901960775
        },
        "surprise": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.3896166675593025,
          "mae": 1.0574712643678161,
          "quadratic_weighted_kappa": 0.18854097268487668
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7475490196078431,
        "macro_recall": 0.7417553191489361,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48927003685204506
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1646123127807209,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.3639405204460967
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.109001829336302,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.4917280917280916
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0827805840074194,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4601533033215719
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7928571428571429,
        "macro_recall": 0.7928571428571429,
        "macro_f1": 0.7928571428571429,
        "mcc": 0.5857142857142857
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0449660391555822,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4815256257449344
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.2502873232999676,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.3742331288343559
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.109001829336302,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.44354115607627476
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7441860465116279,
        "micro_precision": 0.7441860465116279,
        "micro_recall": 0.7441860465116279,
        "micro_f1": 0.7441860465116278,
        "macro_precision": 0.7375886524822695,
        "macro_recall": 0.7439775910364146,
        "macro_f1": 0.7391064533921676,
        "mcc": 0.48152386063501346
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.8604651162790697,
          "rmse": 1.1258072039497333,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.4980186355360394
        },
        "curiosity": {
          "perfect_accuracy": 0.26744186046511625,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.2104198771788934,
          "mae": 0.9534883720930233,
          "quadratic_weighted_kappa": 0.4747964327258627
        },
        "surprise": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.2104198771788934,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.4412704960296999
        }
      }
    }
  ]
}