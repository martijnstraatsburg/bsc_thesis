{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.741860465116279,
        "std": 0.03590155209993317
      },
      "micro_precision": {
        "mean": 0.741860465116279,
        "std": 0.03590155209993317
      },
      "micro_recall": {
        "mean": 0.741860465116279,
        "std": 0.03590155209993317
      },
      "micro_f1": {
        "mean": 0.7418604651162791,
        "std": 0.035901552099933176
      },
      "macro_precision": {
        "mean": 0.7369367898489093,
        "std": 0.03864356920591867
      },
      "macro_recall": {
        "mean": 0.7362136945635068,
        "std": 0.039692387800482114
      },
      "macro_f1": {
        "mean": 0.7364147451149867,
        "std": 0.03918479819913162
      },
      "mcc": {
        "mean": 0.4731474146953493,
        "std": 0.07833078054499405
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.39160652232023524,
          "std": 0.02258651530569845
        },
        "off_by_one_accuracy": {
          "mean": 0.8433841218925421,
          "std": 0.0372626489129288
        },
        "rmse": {
          "mean": 1.152743416602283,
          "std": 0.05321566605191316
        },
        "mae": {
          "mean": 0.8156909917134456,
          "std": 0.03549305439523321
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3869394034993251,
          "std": 0.0621059843867117
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2880245923549853,
          "std": 0.007391446514605754
        },
        "off_by_one_accuracy": {
          "mean": 0.8042234696605186,
          "std": 0.032119992552926066
        },
        "rmse": {
          "mean": 1.1984660251519546,
          "std": 0.03627922287253646
        },
        "mae": {
          "mean": 0.9354183373429563,
          "std": 0.034732214277937434
        },
        "quadratic_weighted_kappa": {
          "mean": 0.426656427131049,
          "std": 0.04964713457581805
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.34784816893878645,
          "std": 0.06913189721689765
        },
        "off_by_one_accuracy": {
          "mean": 0.8041165463779738,
          "std": 0.043754817977378506
        },
        "rmse": {
          "mean": 1.2148579620124207,
          "std": 0.10016481248299594
        },
        "mae": {
          "mean": 0.8963378775728413,
          "std": 0.11674685836352601
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3842281435103686,
          "std": 0.08011557595430446
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7058823529411764,
        "macro_recall": 0.7043243243243243,
        "macro_f1": 0.7050047470500476,
        "mcc": 0.41020371843759756
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1193183475751618,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.38633275092215114
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1938539928826468,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.4518292682926829
        },
        "surprise": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.735632183908046,
          "rmse": 1.3433531557819876,
          "mae": 1.0459770114942528,
          "quadratic_weighted_kappa": 0.31824307461941603
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7532223415682062,
        "macro_recall": 0.7548648648648648,
        "macro_f1": 0.7539393939393939,
        "mcc": 0.5080845514854611
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.18418699983352,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.33951462352209094
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.203443335628631,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.4292408622305529
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.3261299671054765,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.26013006503251634
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7226100966702471,
        "macro_recall": 0.7204787234042553,
        "macro_f1": 0.721153846153846,
        "mcc": 0.443083693813049
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.2410599844719317,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.30258435032304387
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1596670152276025,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.452418096723869
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.124441112772009,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.46048032472657574
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8044397463002114,
        "macro_recall": 0.8047619047619048,
        "macro_f1": 0.8044943820224719,
        "mcc": 0.6092015658800738
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.093344547181068,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.42907622412922763
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.2640020369545641,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.3306581059390049
        },
        "surprise": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.109001829336302,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.4363988617787735
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7093023255813954,
        "micro_precision": 0.7093023255813954,
        "micro_recall": 0.7093023255813954,
        "micro_f1": 0.7093023255813953,
        "macro_precision": 0.6985294117647058,
        "macro_recall": 0.6966386554621848,
        "macro_f1": 0.6974813564091741,
        "mcc": 0.3951635438605653
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.872093023255814,
          "rmse": 1.1258072039497333,
          "mae": 0.8255813953488372,
          "quadratic_weighted_kappa": 0.47718906860011157
        },
        "curiosity": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.1713637450663281,
          "mae": 0.9069767441860465,
          "quadratic_weighted_kappa": 0.4691358024691358
        },
        "surprise": {
          "perfect_accuracy": 0.313953488372093,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.1713637450663281,
          "mae": 0.9069767441860465,
          "quadratic_weighted_kappa": 0.4458883913945616
        }
      }
    }
  ]
}