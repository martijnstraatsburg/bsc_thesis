{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7419406575781877,
        "std": 0.03743941297019246
      },
      "micro_precision": {
        "mean": 0.7419406575781877,
        "std": 0.03743941297019246
      },
      "micro_recall": {
        "mean": 0.7419406575781877,
        "std": 0.03743941297019246
      },
      "micro_f1": {
        "mean": 0.7419406575781877,
        "std": 0.03743941297019246
      },
      "macro_precision": {
        "mean": 0.7391319085664385,
        "std": 0.03908357740346316
      },
      "macro_recall": {
        "mean": 0.7401485823388201,
        "std": 0.036566869563234856
      },
      "macro_f1": {
        "mean": 0.7384967175274957,
        "std": 0.03818679444218052
      },
      "mcc": {
        "mean": 0.4792630350002115,
        "std": 0.07559331244022387
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4170008019246191,
          "std": 0.043975246667049
        },
        "off_by_one_accuracy": {
          "mean": 0.8434108527131784,
          "std": 0.046084244878081895
        },
        "rmse": {
          "mean": 1.114638145573701,
          "std": 0.07757610086105055
        },
        "mae": {
          "mean": 0.7787222667735899,
          "std": 0.06301637749879835
        },
        "quadratic_weighted_kappa": {
          "mean": 0.43992305983272056,
          "std": 0.0831123883363377
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3317829457364341,
          "std": 0.014866181937429054
        },
        "off_by_one_accuracy": {
          "mean": 0.8156642608928093,
          "std": 0.01782735324005804
        },
        "rmse": {
          "mean": 1.1498328374322644,
          "std": 0.05187145180979079
        },
        "mae": {
          "mean": 0.8732691793638064,
          "std": 0.03331869998090395
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4405182848924644,
          "std": 0.0503374323605356
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.36856455493183643,
          "std": 0.05523945912763947
        },
        "off_by_one_accuracy": {
          "mean": 0.806495589414595,
          "std": 0.04545578996569151
        },
        "rmse": {
          "mean": 1.2238912222795646,
          "std": 0.13374674210246645
        },
        "mae": {
          "mean": 0.884790163058006,
          "std": 0.11654184100309362
        },
        "quadratic_weighted_kappa": {
          "mean": 0.38456925816719567,
          "std": 0.1026254263843861
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7079787234042554,
        "macro_recall": 0.7113513513513514,
        "macro_f1": 0.7087963582808943,
        "mcc": 0.4193165116892884
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.144702942944678,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4235731721492503
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.203443335628631,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.4098837209302326
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7241379310344828,
          "rmse": 1.4142135623730951,
          "mae": 1.0344827586206897,
          "quadratic_weighted_kappa": 0.2975406032482599
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6896551724137931,
        "micro_precision": 0.6896551724137931,
        "micro_recall": 0.6896551724137931,
        "micro_f1": 0.6896551724137931,
        "macro_precision": 0.6873015873015873,
        "macro_recall": 0.6913513513513514,
        "macro_f1": 0.6870086608927382,
        "mcc": 0.37863128154135306
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2223963651627971,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.32039418339141923
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.18418699983352,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.3987083616587357
        },
        "surprise": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.3433531557819876,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.240787060196765
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7712418300653594,
        "macro_recall": 0.7648936170212766,
        "macro_f1": 0.7663802363050483,
        "mcc": 0.5360978621613167
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1547005383792515,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.3973486205661053
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0559083903140614,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.5283103236264044
        },
        "surprise": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0559083903140614,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.5181844133599771
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7933403805496828,
        "macro_recall": 0.7936507936507937,
        "macro_f1": 0.7930761099365751,
        "mcc": 0.5869910921240294
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0170952554312156,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.49561968564802883
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1695366997037857,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.3999999999999999
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1346172578623508,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.4028679985292315
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7441860465116279,
        "micro_precision": 0.7441860465116279,
        "micro_recall": 0.7441860465116279,
        "micro_f1": 0.7441860465116278,
        "macro_precision": 0.7357970215113072,
        "macro_recall": 0.7394957983193278,
        "macro_f1": 0.7372222222222222,
        "mcc": 0.4752784274850699
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3953488372093023,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.034295625950562,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.5626796374087994
        },
        "curiosity": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.1360887616813242,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.4656890182469495
        },
        "surprise": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.1713637450663281,
          "mae": 0.8837209302325582,
          "quadratic_weighted_kappa": 0.4634662155017448
        }
      }
    }
  ]
}