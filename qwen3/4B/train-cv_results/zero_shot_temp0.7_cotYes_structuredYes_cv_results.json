{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7049452018176957,
        "std": 0.05046150269607809
      },
      "micro_precision": {
        "mean": 0.7049452018176957,
        "std": 0.05046150269607809
      },
      "micro_recall": {
        "mean": 0.7049452018176957,
        "std": 0.05046150269607809
      },
      "micro_f1": {
        "mean": 0.7049452018176959,
        "std": 0.05046150269607814
      },
      "macro_precision": {
        "mean": 0.71022656422476,
        "std": 0.04813482409698595
      },
      "macro_recall": {
        "mean": 0.7120713287039945,
        "std": 0.04628101935498758
      },
      "macro_f1": {
        "mean": 0.7043073371909163,
        "std": 0.050855678828428404
      },
      "mcc": {
        "mean": 0.4222841475192062,
        "std": 0.09441289875599494
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3501202886928628,
          "std": 0.04672174301858869
        },
        "off_by_one_accuracy": {
          "mean": 0.8088211708099438,
          "std": 0.029248159871832838
        },
        "rmse": {
          "mean": 1.224643957851116,
          "std": 0.06824779779396714
        },
        "mae": {
          "mean": 0.8963378775728416,
          "std": 0.06579310267501823
        },
        "quadratic_weighted_kappa": {
          "mean": 0.362030410537204,
          "std": 0.0746387709718089
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.35934242181234965,
          "std": 0.034955247281496786
        },
        "off_by_one_accuracy": {
          "mean": 0.8318096765570703,
          "std": 0.019925778391776054
        },
        "rmse": {
          "mean": 1.137585881361508,
          "std": 0.03087330091301075
        },
        "mae": {
          "mean": 0.838813151563753,
          "std": 0.02956530270065846
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4637384258591789,
          "std": 0.03845405868279236
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.28781074578989574,
          "std": 0.07742528555487448
        },
        "off_by_one_accuracy": {
          "mean": 0.7235231221598503,
          "std": 0.07297218324105874
        },
        "rmse": {
          "mean": 1.391716375820303,
          "std": 0.12273350711897985
        },
        "mae": {
          "mean": 1.0670408981555735,
          "std": 0.15017415952734334
        },
        "quadratic_weighted_kappa": {
          "mean": 0.258235272268696,
          "std": 0.09461884269801994
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6666666666666666,
        "micro_precision": 0.6666666666666666,
        "micro_recall": 0.6666666666666666,
        "micro_f1": 0.6666666666666666,
        "macro_precision": 0.6818918918918919,
        "macro_recall": 0.6818918918918919,
        "macro_f1": 0.6666666666666666,
        "mcc": 0.3637837837837838
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.1986582537134602,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.3706232999594884
        },
        "curiosity": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.18418699983352,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.41462607544672414
        },
        "surprise": {
          "perfect_accuracy": 0.21839080459770116,
          "off_by_one_accuracy": 0.6091954022988506,
          "rmse": 1.5610194134588469,
          "mae": 1.264367816091954,
          "quadratic_weighted_kappa": 0.1738039777817596
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6781609195402298,
        "micro_precision": 0.6781609195402298,
        "micro_recall": 0.6781609195402298,
        "micro_f1": 0.6781609195402298,
        "macro_precision": 0.680952380952381,
        "macro_recall": 0.6848648648648649,
        "macro_f1": 0.6770943796394485,
        "mcc": 0.365796322845036
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2865350418053538,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.26753975678203934
        },
        "curiosity": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1193183475751618,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4793279525613573
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.6781609195402298,
          "rmse": 1.450326954814696,
          "mae": 1.1149425287356323,
          "quadratic_weighted_kappa": 0.14195634599838325
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7476215644820297,
        "macro_recall": 0.7492021276595745,
        "macro_f1": 0.7468253968253968,
        "mcc": 0.4968211779838468
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.317433939105884,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.29176775028303414
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0985884360051028,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.5281264528126453
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2410599844719317,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.40954213938411677
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7848404255319148,
        "macro_recall": 0.7833333333333333,
        "macro_f1": 0.7814937210839391,
        "mcc": 0.568171760065713
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1295406451144276,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4107633168588688
        },
        "curiosity": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.124441112772009,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.44067796610169496
        },
        "surprise": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.259447059844805,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.28313828516837825
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6511627906976745,
        "micro_precision": 0.6511627906976745,
        "micro_recall": 0.6511627906976745,
        "micro_f1": 0.6511627906976745,
        "macro_precision": 0.6558265582655827,
        "macro_recall": 0.6610644257703081,
        "macro_f1": 0.6494565217391305,
        "mcc": 0.3168476929176511
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.1910519095164538,
          "mae": 0.9069767441860465,
          "quadratic_weighted_kappa": 0.4694579288025891
        },
        "curiosity": {
          "perfect_accuracy": 0.313953488372093,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.1613945106217463,
          "mae": 0.8837209302325582,
          "quadratic_weighted_kappa": 0.455933682373473
        },
        "surprise": {
          "perfect_accuracy": 0.19767441860465115,
          "off_by_one_accuracy": 0.7325581395348837,
          "rmse": 1.4467284665112363,
          "mae": 1.1627906976744187,
          "quadratic_weighted_kappa": 0.28273561301084227
        }
      }
    }
  ]
}