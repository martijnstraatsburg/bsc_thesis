{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7026730820636193,
        "std": 0.04332864013907953
      },
      "micro_precision": {
        "mean": 0.7026730820636193,
        "std": 0.04332864013907953
      },
      "micro_recall": {
        "mean": 0.7026730820636193,
        "std": 0.04332864013907953
      },
      "micro_f1": {
        "mean": 0.7026730820636193,
        "std": 0.04332864013907953
      },
      "macro_precision": {
        "mean": 0.7096542298599224,
        "std": 0.03978178953890198
      },
      "macro_recall": {
        "mean": 0.7112726805117294,
        "std": 0.038616791509472385
      },
      "macro_f1": {
        "mean": 0.7022970705904259,
        "std": 0.043480226756243225
      },
      "mcc": {
        "mean": 0.4209145087024525,
        "std": 0.078369781366513
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.34779470729751405,
          "std": 0.03403710032610735
        },
        "off_by_one_accuracy": {
          "mean": 0.8133921411387328,
          "std": 0.028344805599154296
        },
        "rmse": {
          "mean": 1.2390951406456774,
          "std": 0.06189196620668048
        },
        "mae": {
          "mean": 0.9033146217588881,
          "std": 0.04505024435568476
        },
        "quadratic_weighted_kappa": {
          "mean": 0.35725267341294875,
          "std": 0.05455179631305233
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3224806201550388,
          "std": 0.027117544718579294
        },
        "off_by_one_accuracy": {
          "mean": 0.8202085004009623,
          "std": 0.028267308833252583
        },
        "rmse": {
          "mean": 1.1865059734319539,
          "std": 0.07000510561725483
        },
        "mae": {
          "mean": 0.8964715316760226,
          "std": 0.0628689125700255
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4211896862389201,
          "std": 0.06472409948156246
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3132317562149158,
          "std": 0.07627749153109066
        },
        "off_by_one_accuracy": {
          "mean": 0.7234161988773056,
          "std": 0.09671067572354143
        },
        "rmse": {
          "mean": 1.362112414947418,
          "std": 0.19791399853394362
        },
        "mae": {
          "mean": 1.0371023790430367,
          "std": 0.20193746390878464
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2593856174752288,
          "std": 0.13197489483248018
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6436781609195402,
        "micro_precision": 0.6436781609195402,
        "micro_recall": 0.6436781609195402,
        "micro_f1": 0.6436781609195402,
        "macro_precision": 0.6583783783783784,
        "macro_recall": 0.6583783783783784,
        "macro_f1": 0.6436781609195402,
        "mcc": 0.31675675675675674
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2548755490797328,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.32877175198513275
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.299867367239363,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.3151807228915663
        },
        "surprise": {
          "perfect_accuracy": 0.20689655172413793,
          "off_by_one_accuracy": 0.5747126436781609,
          "rmse": 1.6435173942758734,
          "mae": 1.3448275862068966,
          "quadratic_weighted_kappa": 0.0790955362371063
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7176564156945917,
        "macro_recall": 0.721891891891892,
        "macro_f1": 0.7120349529988084,
        "mcc": 0.4395279006428649
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2456821978060995,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.3334657510924466
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1193183475751618,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.47587464765378884
        },
        "surprise": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7011494252873564,
          "rmse": 1.4343888121314305,
          "mae": 1.0689655172413792,
          "quadratic_weighted_kappa": 0.1607113985448666
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7404255319148936,
        "macro_recall": 0.7404255319148936,
        "macro_f1": 0.7356321839080461,
        "mcc": 0.4808510638297872
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.3217891045025334,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.28395061728395066
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.124441112772009,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.4998954849498328
        },
        "surprise": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1793237883215744,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.3947565112401541
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7617021276595746,
        "macro_recall": 0.7603174603174603,
        "macro_f1": 0.7584930601454064,
        "mcc": 0.5220177515449689
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1295406451144276,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.40896015668033536
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1547005383792515,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.4161073825503355
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0985884360051028,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.4212126972058545
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6627906976744186,
        "micro_precision": 0.6627906976744186,
        "micro_recall": 0.6627906976744186,
        "micro_f1": 0.6627906976744186,
        "macro_precision": 0.6701086956521739,
        "macro_recall": 0.6753501400560225,
        "macro_f1": 0.6616469949803283,
        "mcc": 0.3454190707378849
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.2435882067255932,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.43111509002287873
        },
        "curiosity": {
          "perfect_accuracy": 0.27906976744186046,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.234202501193985,
          "mae": 0.9651162790697675,
          "quadratic_weighted_kappa": 0.3988901931490768
        },
        "surprise": {
          "perfect_accuracy": 0.2558139534883721,
          "off_by_one_accuracy": 0.686046511627907,
          "rmse": 1.4547436440031083,
          "mae": 1.1395348837209303,
          "quadratic_weighted_kappa": 0.24115194414816243
        }
      }
    }
  ]
}