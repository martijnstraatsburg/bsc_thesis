{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7534349104517509,
        "std": 0.03150319923576233
      },
      "micro_precision": {
        "mean": 0.7534349104517509,
        "std": 0.03150319923576233
      },
      "micro_recall": {
        "mean": 0.7534349104517509,
        "std": 0.03150319923576233
      },
      "micro_f1": {
        "mean": 0.7534349104517509,
        "std": 0.03150319923576234
      },
      "macro_precision": {
        "mean": 0.7505826158941868,
        "std": 0.033305253502807435
      },
      "macro_recall": {
        "mean": 0.7517762099664477,
        "std": 0.030915367445253188
      },
      "macro_f1": {
        "mean": 0.7500765389396957,
        "std": 0.03257743479946272
      },
      "mcc": {
        "mean": 0.5023405352965234,
        "std": 0.0641426300475468
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.42397754611066557,
          "std": 0.034528771242356725
        },
        "off_by_one_accuracy": {
          "mean": 0.8549051055867416,
          "std": 0.042577221660529005
        },
        "rmse": {
          "mean": 1.0858304319721006,
          "std": 0.07137342324270507
        },
        "mae": {
          "mean": 0.7556802993851911,
          "std": 0.058253321412278986
        },
        "quadratic_weighted_kappa": {
          "mean": 0.46821520123378424,
          "std": 0.06332955830822735
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.32023523122159847,
          "std": 0.03478212902070301
        },
        "off_by_one_accuracy": {
          "mean": 0.8155840684309009,
          "std": 0.0322514191467466
        },
        "rmse": {
          "mean": 1.1636144835265279,
          "std": 0.07561737253136938
        },
        "mae": {
          "mean": 0.8895215183106121,
          "std": 0.07097974687706539
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44565546053936256,
          "std": 0.044569357713694274
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.37316225608126175,
          "std": 0.03650024797057969
        },
        "off_by_one_accuracy": {
          "mean": 0.7995455760491847,
          "std": 0.032943868476953166
        },
        "rmse": {
          "mean": 1.20826085545513,
          "std": 0.12062769436011134
        },
        "mae": {
          "mean": 0.8756214915797915,
          "std": 0.07277451067732627
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4118721054641695,
          "std": 0.08661281774262952
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7311170212765958,
        "macro_recall": 0.7348648648648648,
        "macro_f1": 0.7320926496184228,
        "mcc": 0.4659668141406542
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0827805840074194,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.4610712984331349
        },
        "curiosity": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2502873232999676,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.39638812366085097
        },
        "surprise": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3390681268239724,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.33574784651527023
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7103174603174603,
        "macro_recall": 0.7148648648648648,
        "macro_f1": 0.710193204530313,
        "mcc": 0.42515800681550237
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.174440439029407,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.40417760529619906
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1547005383792515,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.45318595578673604
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.3603583030377249,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.2833461243284727
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7712418300653594,
        "macro_recall": 0.7648936170212766,
        "macro_f1": 0.7663802363050483,
        "mcc": 0.5360978621613167
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1497126077675979,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.3968167842286128
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0283342182227606,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.5270062640349841
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0827805840074194,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.5076564580559255
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8044397463002114,
        "macro_recall": 0.8047619047619048,
        "macro_f1": 0.8044943820224719,
        "mcc": 0.6092015658800738
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9767410038007758,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.5216296787015569
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1695366997037857,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.430622009569378
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0827805840074194,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.4594298245614036
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7441860465116279,
        "micro_precision": 0.7441860465116279,
        "micro_recall": 0.7441860465116279,
        "micro_f1": 0.7441860465116278,
        "macro_precision": 0.7357970215113072,
        "macro_recall": 0.7394957983193278,
        "macro_f1": 0.7372222222222222,
        "mcc": 0.4752784274850699
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43023255813953487,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.0454775252553032,
          "mae": 0.7209302325581395,
          "quadratic_weighted_kappa": 0.5573806395094174
        },
        "curiosity": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.7790697674418605,
          "rmse": 1.2152136380268745,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.4210749496448637
        },
        "surprise": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.176316679399114,
          "mae": 0.8953488372093024,
          "quadratic_weighted_kappa": 0.47318027385977546
        }
      }
    }
  ]
}