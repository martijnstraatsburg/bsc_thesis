{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7473684210526315,
        "std": 0.057890367896216856
      },
      "micro_precision": {
        "mean": 0.7473684210526315,
        "std": 0.057890367896216856
      },
      "micro_recall": {
        "mean": 0.7473684210526315,
        "std": 0.057890367896216856
      },
      "micro_f1": {
        "mean": 0.7473684210526315,
        "std": 0.057890367896216856
      },
      "macro_precision": {
        "mean": 0.764405929038282,
        "std": 0.05297503124973005
      },
      "macro_recall": {
        "mean": 0.786686193923036,
        "std": 0.04279094670348037
      },
      "macro_f1": {
        "mean": 0.7436122264870472,
        "std": 0.05967496694498317
      },
      "weighted_precision": {
        "mean": 0.8186692419974154,
        "std": 0.034425593335943985
      },
      "weighted_recall": {
        "mean": 0.7473684210526315,
        "std": 0.057890367896216856
      },
      "weighted_f1": {
        "mean": 0.7534263374269414,
        "std": 0.053910843668148904
      },
      "mcc": {
        "mean": 0.5503520614457572,
        "std": 0.09535693745156638
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.26372688477951634,
          "std": 0.09172747755644639
        },
        "off_by_one_accuracy": {
          "mean": 0.8172119487908962,
          "std": 0.0972623530371168
        },
        "level_accuracy": {
          "mean": 0.5432432432432432,
          "std": 0.09061110602292007
        },
        "rmse": {
          "mean": 1.2152370525346208,
          "std": 0.22283837894608713
        },
        "mae": {
          "mean": 0.9674253200568991,
          "std": 0.2017761760147843
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3213297877256363,
          "std": 0.18121081883810078
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3386913229018492,
          "std": 0.06945466867308236
        },
        "off_by_one_accuracy": {
          "mean": 0.84950213371266,
          "std": 0.060547331676129496
        },
        "level_accuracy": {
          "mean": 0.5540540540540542,
          "std": 0.08108108108108106
        },
        "rmse": {
          "mean": 1.1208874401802946,
          "std": 0.13097064351110804
        },
        "mae": {
          "mean": 0.8439544807965863,
          "std": 0.13622499796408288
        },
        "quadratic_weighted_kappa": {
          "mean": 0.49794547570540404,
          "std": 0.11846224807236516
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.2694167852062589,
          "std": 0.07575584796928152
        },
        "off_by_one_accuracy": {
          "mean": 0.7368421052631579,
          "std": 0.05603179822077901
        },
        "level_accuracy": {
          "mean": 0.5541963015647227,
          "std": 0.07818490499354734
        },
        "rmse": {
          "mean": 1.361446853895369,
          "std": 0.1309941862094562
        },
        "mae": {
          "mean": 1.063869132290185,
          "std": 0.13103644264866143
        },
        "quadratic_weighted_kappa": {
          "mean": 0.22796220740496181,
          "std": 0.11441799938972827
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7368421052631579,
        "micro_precision": 0.7368421052631579,
        "micro_recall": 0.7368421052631579,
        "micro_f1": 0.7368421052631579,
        "macro_precision": 0.7472222222222222,
        "macro_recall": 0.7852564102564102,
        "macro_f1": 0.7301136363636362,
        "weighted_precision": 0.8198830409356725,
        "weighted_recall": 0.7368421052631579,
        "weighted_f1": 0.7458133971291865,
        "mcc": 0.531118531579246
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.21052631578947367,
          "off_by_one_accuracy": 0.8157894736842105,
          "level_accuracy": 0.5,
          "rmse": 1.266989801811655,
          "mae": 1.0263157894736843,
          "quadratic_weighted_kappa": 0.3327576280944158
        },
        "curiosity": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.8421052631578947,
          "level_accuracy": 0.5,
          "rmse": 1.180989772227204,
          "mae": 0.868421052631579,
          "quadratic_weighted_kappa": 0.44639912039582197
        },
        "surprise": {
          "perfect_accuracy": 0.15789473684210525,
          "off_by_one_accuracy": 0.6842105263157895,
          "level_accuracy": 0.47368421052631576,
          "rmse": 1.3860204297119676,
          "mae": 1.1842105263157894,
          "quadratic_weighted_kappa": 0.3047619047619048
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6756756756756757,
        "micro_precision": 0.6756756756756757,
        "micro_recall": 0.6756756756756757,
        "micro_f1": 0.6756756756756757,
        "macro_precision": 0.7068452380952381,
        "macro_recall": 0.7430069930069929,
        "macro_f1": 0.6696428571428571,
        "weighted_precision": 0.8003539253539254,
        "weighted_recall": 0.6756756756756757,
        "weighted_f1": 0.6877413127413128,
        "mcc": 0.44839642874286734
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.24324324324324326,
          "off_by_one_accuracy": 0.6486486486486487,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.5334116705410037,
          "mae": 1.2162162162162162,
          "quadratic_weighted_kappa": 0.12217071175347716
        },
        "curiosity": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5135135135135135,
          "rmse": 1.0780362527123855,
          "mae": 0.8378378378378378,
          "quadratic_weighted_kappa": 0.49411764705882355
        },
        "surprise": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.4864864864864865,
          "rmse": 1.4142135623730951,
          "mae": 1.0810810810810811,
          "quadratic_weighted_kappa": 0.21185952792170404
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "micro_precision": 0.8378378378378378,
        "micro_recall": 0.8378378378378378,
        "micro_f1": 0.8378378378378378,
        "macro_precision": 0.8422619047619048,
        "macro_recall": 0.8362573099415205,
        "macro_f1": 0.8367647058823531,
        "weighted_precision": 0.8413770913770914,
        "weighted_recall": 0.8378378378378378,
        "weighted_f1": 0.8371224165341813,
        "mcc": 0.6784926451795892
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.7027027027027027,
          "rmse": 0.8542421961772491,
          "mae": 0.6216216216216216,
          "quadratic_weighted_kappa": 0.6577595066803701
        },
        "curiosity": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.6756756756756757,
          "rmse": 0.944400281603035,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.6932931424265261
        },
        "surprise": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.6486486486486487,
          "rmse": 1.115008180796555,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.4032258064516129
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.8095238095238095,
        "macro_recall": 0.8333333333333333,
        "macro_f1": 0.7823529411764707,
        "weighted_precision": 0.8661518661518662,
        "weighted_recall": 0.7837837837837838,
        "weighted_f1": 0.7875993640699523,
        "mcc": 0.6424160744396211
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.16216216216216217,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.5135135135135135,
          "rmse": 1.2944789205219511,
          "mae": 1.0810810810810811,
          "quadratic_weighted_kappa": 0.25567813108371185
        },
        "curiosity": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.065427207806866,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.5267965895249695
        },
        "surprise": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.5135135135135135,
          "rmse": 1.506741607001768,
          "mae": 1.135135135135135,
          "quadratic_weighted_kappa": 0.090696313633704
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7027027027027027,
        "micro_precision": 0.7027027027027027,
        "micro_recall": 0.7027027027027027,
        "micro_f1": 0.7027027027027027,
        "macro_precision": 0.7161764705882353,
        "macro_recall": 0.7355769230769231,
        "macro_f1": 0.6991869918699187,
        "weighted_precision": 0.7655802861685215,
        "weighted_recall": 0.7027027027027027,
        "weighted_f1": 0.7088551966600748,
        "mcc": 0.4513366272874624
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.1270626736212455,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.23828296101620672
        },
        "curiosity": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.3355836865519823,
          "mae": 1.0810810810810811,
          "quadratic_weighted_kappa": 0.3291208791208792
        },
        "surprise": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.6486486486486487,
          "rmse": 1.3852504895934594,
          "mae": 1.1081081081081081,
          "quadratic_weighted_kappa": 0.1292674842558834
        }
      }
    }
  ]
}