{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8385490753911806,
        "std": 0.038747762366646475
      },
      "micro_precision": {
        "mean": 0.8385490753911806,
        "std": 0.038747762366646475
      },
      "micro_recall": {
        "mean": 0.8385490753911806,
        "std": 0.038747762366646475
      },
      "micro_f1": {
        "mean": 0.8385490753911806,
        "std": 0.038747762366646475
      },
      "macro_precision": {
        "mean": 0.8273510632589917,
        "std": 0.03551067607893721
      },
      "macro_recall": {
        "mean": 0.8435422034106244,
        "std": 0.040110704048869614
      },
      "macro_f1": {
        "mean": 0.8275878336119842,
        "std": 0.03862667327256467
      },
      "weighted_precision": {
        "mean": 0.8563161200353285,
        "std": 0.03281693864926524
      },
      "weighted_recall": {
        "mean": 0.8385490753911806,
        "std": 0.038747762366646475
      },
      "weighted_f1": {
        "mean": 0.8402760632003512,
        "std": 0.0390965982356344
      },
      "mcc": {
        "mean": 0.6702875036168747,
        "std": 0.07208561835025959
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.31778093883357045,
          "std": 0.07092775268782868
        },
        "off_by_one_accuracy": {
          "mean": 0.8655761024182077,
          "std": 0.03824844853413585
        },
        "level_accuracy": {
          "mean": 0.5650071123755334,
          "std": 0.10041666784035715
        },
        "rmse": {
          "mean": 1.0766076224657737,
          "std": 0.08653243462125418
        },
        "mae": {
          "mean": 0.8328591749644382,
          "std": 0.09916396270085238
        },
        "quadratic_weighted_kappa": {
          "mean": 0.41291164221106014,
          "std": 0.09042039924328499
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2799431009957326,
          "std": 0.07073235118865447
        },
        "off_by_one_accuracy": {
          "mean": 0.8115220483641536,
          "std": 0.05738413384710907
        },
        "level_accuracy": {
          "mean": 0.5327169274537695,
          "std": 0.06992156093715872
        },
        "rmse": {
          "mean": 1.2587279493441574,
          "std": 0.1571871185009763
        },
        "mae": {
          "mean": 0.97325746799431,
          "std": 0.13881316455684578
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42582689013897823,
          "std": 0.11781933610046882
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.34409672830725463,
          "std": 0.026361499649753345
        },
        "off_by_one_accuracy": {
          "mean": 0.7472261735419631,
          "std": 0.028176499516041537
        },
        "level_accuracy": {
          "mean": 0.5968705547652917,
          "std": 0.04407928806681981
        },
        "rmse": {
          "mean": 1.29617272782029,
          "std": 0.06099215882957803
        },
        "mae": {
          "mean": 0.9625889046941678,
          "std": 0.036164453873646786
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2178645873233669,
          "std": 0.09836357850104038
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.868421052631579,
        "micro_precision": 0.868421052631579,
        "micro_recall": 0.868421052631579,
        "micro_f1": 0.868421052631579,
        "macro_precision": 0.844927536231884,
        "macro_recall": 0.8814102564102564,
        "macro_f1": 0.8563869992441422,
        "weighted_precision": 0.8860411899313501,
        "weighted_recall": 0.868421052631579,
        "weighted_f1": 0.871703067191789,
        "mcc": 0.7254209813264596
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.21052631578947367,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.47368421052631576,
          "rmse": 1.0882143751650175,
          "mae": 0.9210526315789473,
          "quadratic_weighted_kappa": 0.42655935613682094
        },
        "curiosity": {
          "perfect_accuracy": 0.21052631578947367,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.4473684210526316,
          "rmse": 1.1470786693528088,
          "mae": 0.9473684210526315,
          "quadratic_weighted_kappa": 0.5187436676798378
        },
        "surprise": {
          "perfect_accuracy": 0.34210526315789475,
          "off_by_one_accuracy": 0.7631578947368421,
          "level_accuracy": 0.5789473684210527,
          "rmse": 1.224744871391589,
          "mae": 0.9210526315789473,
          "quadratic_weighted_kappa": 0.34003656307129804
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "micro_precision": 0.8378378378378378,
        "micro_recall": 0.8378378378378378,
        "micro_f1": 0.8378378378378378,
        "macro_precision": 0.8044871794871795,
        "macro_recall": 0.8321678321678322,
        "macro_f1": 0.815,
        "weighted_precision": 0.84996534996535,
        "weighted_recall": 0.8378378378378378,
        "weighted_f1": 0.8413513513513512,
        "mcc": 0.6360529736842806
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.196842693269434,
          "mae": 0.9459459459459459,
          "quadratic_weighted_kappa": 0.35044716793640285
        },
        "curiosity": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.6216216216216216,
          "rmse": 1.0266713466606798,
          "mae": 0.7297297297297297,
          "quadratic_weighted_kappa": 0.5979381443298969
        },
        "surprise": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.2302493704584911,
          "mae": 0.918918918918919,
          "quadratic_weighted_kappa": 0.2990527740189445
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.8365384615384616,
        "macro_recall": 0.8070175438596491,
        "macro_f1": 0.805701425356339,
        "weighted_precision": 0.8341995841995843,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8065529895987511,
        "mcc": 0.6428785635743144
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.6756756756756757,
          "rmse": 0.9725975251592747,
          "mae": 0.7297297297297297,
          "quadratic_weighted_kappa": 0.5807704758821626
        },
        "curiosity": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.461210161179813,
          "mae": 1.1081081081081081,
          "quadratic_weighted_kappa": 0.40889787664307375
        },
        "surprise": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.7837837837837838,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.3254270092150517,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.23820082356667727
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8918918918918919,
        "micro_precision": 0.8918918918918919,
        "micro_recall": 0.8918918918918919,
        "micro_f1": 0.8918918918918919,
        "macro_precision": 0.8772727272727273,
        "macro_recall": 0.8990384615384616,
        "macro_f1": 0.8850931677018633,
        "weighted_precision": 0.9002457002457003,
        "weighted_recall": 0.8918918918918919,
        "weighted_f1": 0.8934027194896761,
        "mcc": 0.7760060017070195
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.138989594902999,
          "mae": 0.8648648648648649,
          "quadratic_weighted_kappa": 0.32574031890660593
        },
        "curiosity": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.7837837837837838,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.2734290799340267,
          "mae": 0.972972972972973,
          "quadratic_weighted_kappa": 0.3084112149532712
        },
        "surprise": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.7027027027027027,
          "level_accuracy": 0.5945945945945946,
          "rmse": 1.3852504895934594,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.132717068339386
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7735294117647059,
        "macro_recall": 0.7980769230769231,
        "macro_f1": 0.7757575757575759,
        "weighted_precision": 0.8111287758346583,
        "weighted_recall": 0.7837837837837838,
        "weighted_f1": 0.7883701883701885,
        "mcc": 0.5710789977922993
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.6756756756756757,
          "rmse": 0.9863939238321437,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.3810408921933085
        },
        "curiosity": {
          "perfect_accuracy": 0.21621621621621623,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.4594594594594595,
          "rmse": 1.3852504895934594,
          "mae": 1.1081081081081081,
          "quadratic_weighted_kappa": 0.2951435470888114
        },
        "surprise": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.7297297297297297,
          "level_accuracy": 0.6756756756756757,
          "rmse": 1.3151918984428583,
          "mae": 0.972972972972973,
          "quadratic_weighted_kappa": 0.07931570762052875
        }
      }
    }
  ]
}