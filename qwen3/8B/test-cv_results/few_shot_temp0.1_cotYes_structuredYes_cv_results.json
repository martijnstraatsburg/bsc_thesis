{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8011379800853484,
        "std": 0.049810195600847346
      },
      "micro_precision": {
        "mean": 0.8011379800853484,
        "std": 0.049810195600847346
      },
      "micro_recall": {
        "mean": 0.8011379800853484,
        "std": 0.049810195600847346
      },
      "micro_f1": {
        "mean": 0.8011379800853484,
        "std": 0.04981019560084739
      },
      "macro_precision": {
        "mean": 0.781089277681383,
        "std": 0.056862295769454396
      },
      "macro_recall": {
        "mean": 0.7917009160430213,
        "std": 0.05475475708980472
      },
      "macro_f1": {
        "mean": 0.7843931916679954,
        "std": 0.05561432151516039
      },
      "weighted_precision": {
        "mean": 0.8087134164239428,
        "std": 0.04892668297199774
      },
      "weighted_recall": {
        "mean": 0.8011379800853484,
        "std": 0.049810195600847346
      },
      "weighted_f1": {
        "mean": 0.8031918080853242,
        "std": 0.04927225556138567
      },
      "mcc": {
        "mean": 0.572607245334978,
        "std": 0.1112464755470283
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.32802275960170696,
          "std": 0.0553969593863359
        },
        "off_by_one_accuracy": {
          "mean": 0.9408250355618776,
          "std": 0.020309039314452052
        },
        "level_accuracy": {
          "mean": 0.4354196301564722,
          "std": 0.045617780883609974
        },
        "rmse": {
          "mean": 0.9466784970072967,
          "std": 0.0815154802315298
        },
        "mae": {
          "mean": 0.7418207681365576,
          "std": 0.07974492376761133
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4293997632404937,
          "std": 0.1386357877816205
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3817923186344239,
          "std": 0.027177837828888753
        },
        "off_by_one_accuracy": {
          "mean": 0.800711237553343,
          "std": 0.05105952550035628
        },
        "level_accuracy": {
          "mean": 0.5109530583214793,
          "std": 0.05002098873730639
        },
        "rmse": {
          "mean": 1.1371068830284983,
          "std": 0.05858113008895518
        },
        "mae": {
          "mean": 0.833570412517781,
          "std": 0.03435211117638367
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4164813939355988,
          "std": 0.060150956157666496
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3173541963015647,
          "std": 0.05314120268045665
        },
        "off_by_one_accuracy": {
          "mean": 0.8815078236130868,
          "std": 0.04428811767947972
        },
        "level_accuracy": {
          "mean": 0.42503556187766717,
          "std": 0.051613701171190546
        },
        "rmse": {
          "mean": 1.0815890334167393,
          "std": 0.052071040258583765
        },
        "mae": {
          "mean": 0.8280227596017069,
          "std": 0.03199272694654724
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3417412699465794,
          "std": 0.05635079148738137
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7894736842105263,
        "micro_precision": 0.7894736842105263,
        "micro_recall": 0.7894736842105263,
        "micro_f1": 0.7894736842105263,
        "macro_precision": 0.7589285714285714,
        "macro_recall": 0.7788461538461539,
        "macro_f1": 0.7661538461538462,
        "weighted_precision": 0.8016917293233083,
        "weighted_recall": 0.7894736842105263,
        "weighted_f1": 0.7933603238866397,
        "mcc": 0.5374057545792984
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3157894736842105,
          "off_by_one_accuracy": 0.9473684210526315,
          "level_accuracy": 0.4473684210526316,
          "rmse": 0.9867543820659302,
          "mae": 0.7631578947368421,
          "quadratic_weighted_kappa": 0.3520737327188941
        },
        "curiosity": {
          "perfect_accuracy": 0.3684210526315789,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.47368421052631576,
          "rmse": 1.0760551736979407,
          "mae": 0.7894736842105263,
          "quadratic_weighted_kappa": 0.4675159235668789
        },
        "surprise": {
          "perfect_accuracy": 0.2894736842105263,
          "off_by_one_accuracy": 0.9210526315789473,
          "level_accuracy": 0.3684210526315789,
          "rmse": 1.038723913473187,
          "mae": 0.8157894736842105,
          "quadratic_weighted_kappa": 0.376301040832666
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "micro_precision": 0.7567567567567568,
        "micro_recall": 0.7567567567567568,
        "micro_f1": 0.7567567567567567,
        "macro_precision": 0.7116666666666667,
        "macro_recall": 0.7220279720279721,
        "macro_f1": 0.7161125319693095,
        "weighted_precision": 0.7636936936936938,
        "weighted_recall": 0.7567567567567568,
        "weighted_f1": 0.7596599156701458,
        "mcc": 0.4335708511693135
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.3783783783783784,
          "rmse": 0.9586025865388216,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.4762697751873439
        },
        "curiosity": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.065427207806866,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.43243243243243246
        },
        "surprise": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.0904995136125413,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.3833333333333334
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "micro_precision": 0.7567567567567568,
        "micro_recall": 0.7567567567567568,
        "micro_f1": 0.7567567567567567,
        "macro_precision": 0.7573099415204678,
        "macro_recall": 0.7573099415204678,
        "macro_f1": 0.7567567567567567,
        "weighted_precision": 0.757863126284179,
        "weighted_recall": 0.7567567567567568,
        "weighted_f1": 0.7567567567567568,
        "mcc": 0.5146198830409356
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.972972972972973,
          "level_accuracy": 0.5135135135135135,
          "rmse": 0.8053872662568292,
          "mae": 0.5945945945945946,
          "quadratic_weighted_kappa": 0.6803455723542117
        },
        "curiosity": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.150792911137501,
          "mae": 0.8378378378378378,
          "quadratic_weighted_kappa": 0.48654772019257997
        },
        "surprise": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.5135135135135135,
          "rmse": 1.1624763874381927,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.40206851971557844
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8918918918918919,
        "micro_precision": 0.8918918918918919,
        "micro_recall": 0.8918918918918919,
        "micro_f1": 0.8918918918918919,
        "macro_precision": 0.8814102564102564,
        "macro_recall": 0.8814102564102564,
        "macro_f1": 0.8814102564102564,
        "weighted_precision": 0.8918918918918919,
        "weighted_recall": 0.8918918918918919,
        "weighted_f1": 0.8918918918918919,
        "mcc": 0.7628205128205128
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.0526671402243484,
          "mae": 0.8378378378378378,
          "quadratic_weighted_kappa": 0.3012436665131276
        },
        "curiosity": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.7567567567567568,
          "level_accuracy": 0.5405405405405406,
          "rmse": 1.2192155209340498,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.3263819927176431
        },
        "surprise": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.8378378378378378,
          "level_accuracy": 0.3783783783783784,
          "rmse": 1.1028219331407116,
          "mae": 0.8918918918918919,
          "quadratic_weighted_kappa": 0.2732431252728067
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.7961309523809523,
        "macro_recall": 0.8189102564102564,
        "macro_f1": 0.8015325670498084,
        "weighted_precision": 0.828426640926641,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8142901522211866,
        "mcc": 0.6146192250648298
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2972972972972973,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.40540540540540543,
          "rmse": 0.9299811099505543,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.3370660694288913
        },
        "curiosity": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.7297297297297297,
          "level_accuracy": 0.5675675675675675,
          "rmse": 1.1740436015661335,
          "mae": 0.8378378378378378,
          "quadratic_weighted_kappa": 0.3695289007684598
        },
        "surprise": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.0134234194190634,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.27376033057851235
        }
      }
    }
  ]
}