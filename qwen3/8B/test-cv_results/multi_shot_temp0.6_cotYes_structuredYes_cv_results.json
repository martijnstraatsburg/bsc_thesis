{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8014224751066857,
        "std": 0.041672451604211826
      },
      "micro_precision": {
        "mean": 0.8014224751066857,
        "std": 0.041672451604211826
      },
      "micro_recall": {
        "mean": 0.8014224751066857,
        "std": 0.041672451604211826
      },
      "micro_f1": {
        "mean": 0.8014224751066857,
        "std": 0.041672451604211826
      },
      "macro_precision": {
        "mean": 0.7914484638168849,
        "std": 0.062359640028008555
      },
      "macro_recall": {
        "mean": 0.8048853923853925,
        "std": 0.04454047671198101
      },
      "macro_f1": {
        "mean": 0.7878089068654683,
        "std": 0.04911705377502196
      },
      "weighted_precision": {
        "mean": 0.8273091713881188,
        "std": 0.0426658012654175
      },
      "weighted_recall": {
        "mean": 0.8014224751066857,
        "std": 0.041672451604211826
      },
      "weighted_f1": {
        "mean": 0.8048650004350586,
        "std": 0.03828578330008111
      },
      "mcc": {
        "mean": 0.5956929447751593,
        "std": 0.10561283157951765
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4083926031294453,
          "std": 0.06548084156274617
        },
        "off_by_one_accuracy": {
          "mean": 0.9355618776671408,
          "std": 0.021316253422394533
        },
        "level_accuracy": {
          "mean": 0.4786628733997156,
          "std": 0.09943294320226745
        },
        "rmse": {
          "mean": 0.8841535847339506,
          "std": 0.05651727586532433
        },
        "mae": {
          "mean": 0.656045519203414,
          "std": 0.07254567260544742
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4004052210723392,
          "std": 0.08273704117757097
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.4570412517780939,
          "std": 0.101241461726093
        },
        "off_by_one_accuracy": {
          "mean": 0.8709815078236132,
          "std": 0.03577630941079571
        },
        "level_accuracy": {
          "mean": 0.5002844950213372,
          "std": 0.09878124354384808
        },
        "rmse": {
          "mean": 0.9758212305841478,
          "std": 0.06938427573545204
        },
        "mae": {
          "mean": 0.6773826458036984,
          "std": 0.10403108092720491
        },
        "quadratic_weighted_kappa": {
          "mean": 0.39996116676290266,
          "std": 0.17189035758053356
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.407823613086771,
          "std": 0.10013416493956842
        },
        "off_by_one_accuracy": {
          "mean": 0.9085348506401137,
          "std": 0.02774227639952794
        },
        "level_accuracy": {
          "mean": 0.4617354196301565,
          "std": 0.08841618276287327
        },
        "rmse": {
          "mean": 0.928177185186162,
          "std": 0.07112628130853314
        },
        "mae": {
          "mean": 0.6836415362731152,
          "std": 0.1047490424561169
        },
        "quadratic_weighted_kappa": {
          "mean": 0.363589980975212,
          "std": 0.13108967214603373
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7368421052631579,
        "micro_precision": 0.7368421052631579,
        "micro_recall": 0.7368421052631579,
        "micro_f1": 0.7368421052631579,
        "macro_precision": 0.7130681818181819,
        "macro_recall": 0.7403846153846154,
        "macro_f1": 0.7172619047619048,
        "weighted_precision": 0.7685406698564593,
        "weighted_recall": 0.7368421052631579,
        "weighted_f1": 0.7446741854636592,
        "mcc": 0.45262926523618835
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4473684210526316,
          "off_by_one_accuracy": 0.9210526315789473,
          "level_accuracy": 0.4473684210526316,
          "rmse": 0.8885233166386386,
          "mae": 0.631578947368421,
          "quadratic_weighted_kappa": 0.29802955665024644
        },
        "curiosity": {
          "perfect_accuracy": 0.4473684210526316,
          "off_by_one_accuracy": 0.868421052631579,
          "level_accuracy": 0.4473684210526316,
          "rmse": 0.9733285267845752,
          "mae": 0.6842105263157895,
          "quadratic_weighted_kappa": 0.4252100840336134
        },
        "surprise": {
          "perfect_accuracy": 0.5526315789473685,
          "off_by_one_accuracy": 0.9210526315789473,
          "level_accuracy": 0.5789473684210527,
          "rmse": 0.8271701918685112,
          "mae": 0.5263157894736842,
          "quadratic_weighted_kappa": 0.5180487804878049
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7451923076923077,
        "macro_recall": 0.7674825174825175,
        "macro_f1": 0.7533333333333334,
        "weighted_precision": 0.7978170478170479,
        "weighted_recall": 0.7837837837837838,
        "weighted_f1": 0.7884684684684686,
        "mcc": 0.5121900261773418
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.32432432432432434,
          "rmse": 0.9586025865388216,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.4353680430879713
        },
        "curiosity": {
          "perfect_accuracy": 0.6486486486486487,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.6756756756756757,
          "rmse": 0.86991767240168,
          "mae": 0.4864864864864865,
          "quadratic_weighted_kappa": 0.6111111111111112
        },
        "surprise": {
          "perfect_accuracy": 0.4864864864864865,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.4864864864864865,
          "rmse": 0.9153348228041135,
          "mae": 0.6216216216216216,
          "quadratic_weighted_kappa": 0.4899955535793685
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "micro_precision": 0.8648648648648649,
        "micro_recall": 0.8648648648648649,
        "micro_f1": 0.8648648648648649,
        "macro_precision": 0.8958333333333333,
        "macro_recall": 0.8611111111111112,
        "macro_f1": 0.8612153038259565,
        "weighted_precision": 0.893018018018018,
        "weighted_recall": 0.8648648648648649,
        "weighted_f1": 0.861823563999108,
        "mcc": 0.7561476438231222
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.5405405405405406,
          "rmse": 0.9299811099505543,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.5186991869918699
        },
        "curiosity": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.8918918918918919,
          "level_accuracy": 0.5405405405405406,
          "rmse": 0.944400281603035,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.5482796892341844
        },
        "surprise": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.8648648648648649,
          "level_accuracy": 0.5135135135135135,
          "rmse": 1.0266713466606798,
          "mae": 0.7837837837837838,
          "quadratic_weighted_kappa": 0.38464818763326225
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.8070175438596491,
        "macro_recall": 0.8365384615384616,
        "macro_f1": 0.805701425356339,
        "weighted_precision": 0.8487434803224276,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8150686320228705,
        "mcc": 0.6428785635743144
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5135135135135135,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.6216216216216216,
          "rmse": 0.8053872662568292,
          "mae": 0.5405405405405406,
          "quadratic_weighted_kappa": 0.43511450381679384
        },
        "curiosity": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.40540540540540543,
          "rmse": 1.0134234194190634,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.2646443514644352
        },
        "surprise": {
          "perfect_accuracy": 0.2702702702702703,
          "off_by_one_accuracy": 0.918918918918919,
          "level_accuracy": 0.32432432432432434,
          "rmse": 0.9863939238321437,
          "mae": 0.8108108108108109,
          "quadratic_weighted_kappa": 0.21830985915492962
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "micro_precision": 0.8108108108108109,
        "micro_recall": 0.8108108108108109,
        "micro_f1": 0.8108108108108109,
        "macro_precision": 0.7961309523809523,
        "macro_recall": 0.8189102564102564,
        "macro_f1": 0.8015325670498084,
        "weighted_precision": 0.828426640926641,
        "weighted_recall": 0.8108108108108109,
        "weighted_f1": 0.8142901522211866,
        "mcc": 0.6146192250648298
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.972972972972973,
          "level_accuracy": 0.4594594594594595,
          "rmse": 0.8382736442849094,
          "mae": 0.6486486486486487,
          "quadratic_weighted_kappa": 0.3148148148148149
        },
        "curiosity": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8108108108108109,
          "level_accuracy": 0.43243243243243246,
          "rmse": 1.0780362527123855,
          "mae": 0.7837837837837838,
          "quadratic_weighted_kappa": 0.15056059797116939
        },
        "surprise": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.9459459459459459,
          "level_accuracy": 0.40540540540540543,
          "rmse": 0.8853156407653622,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.20694752402069483
        }
      }
    }
  ]
}