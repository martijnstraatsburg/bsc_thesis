{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7880780539962577,
        "std": 0.025357617846943747
      },
      "micro_precision": {
        "mean": 0.7880780539962577,
        "std": 0.025357617846943747
      },
      "micro_recall": {
        "mean": 0.7880780539962577,
        "std": 0.025357617846943747
      },
      "micro_f1": {
        "mean": 0.7880780539962577,
        "std": 0.025357617846943733
      },
      "macro_precision": {
        "mean": 0.790454730968422,
        "std": 0.029683679020225815
      },
      "macro_recall": {
        "mean": 0.7798509065117324,
        "std": 0.021482024482649117
      },
      "macro_f1": {
        "mean": 0.7817779842541586,
        "std": 0.023338969251357682
      },
      "mcc": {
        "mean": 0.5701423435630385,
        "std": 0.05085857840917091
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.41927292167869556,
          "std": 0.029398556049582324
        },
        "off_by_one_accuracy": {
          "mean": 0.8894413258487035,
          "std": 0.024603742003038297
        },
        "rmse": {
          "mean": 0.9956178727978966,
          "std": 0.07877577930400369
        },
        "mae": {
          "mean": 0.7073777064955894,
          "std": 0.05465152724124341
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4667030000998652,
          "std": 0.05289240636014014
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.39387864207431167,
          "std": 0.03893956730813664
        },
        "off_by_one_accuracy": {
          "mean": 0.8385458433573912,
          "std": 0.03942845880646798
        },
        "rmse": {
          "mean": 1.0693383477588376,
          "std": 0.06686247253676826
        },
        "mae": {
          "mean": 0.7790697674418604,
          "std": 0.07135216648860597
        },
        "quadratic_weighted_kappa": {
          "mean": 0.41699940204055624,
          "std": 0.08142264080376979
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3916332531408714,
          "std": 0.054386441217495606
        },
        "off_by_one_accuracy": {
          "mean": 0.8272119754076449,
          "std": 0.016006026125759697
        },
        "rmse": {
          "mean": 1.1185615960123498,
          "std": 0.0819689784265944
        },
        "mae": {
          "mean": 0.8064688585939589,
          "std": 0.07668140205890744
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3410008020643013,
          "std": 0.10097248277593159
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7419871794871795,
        "macro_recall": 0.7448648648648648,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48684353956546655
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.9767410038007758,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4455194655609306
        },
        "curiosity": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1193183475751618,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.3568667344862665
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1596670152276025,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.30684371807967314
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8027192008879023,
        "macro_recall": 0.7948648648648649,
        "macro_f1": 0.7977574182961849,
        "mcc": 0.5975324468572771
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0057307059414877,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.46633207862818904
        },
        "curiosity": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0283342182227606,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.5133163079168187
        },
        "surprise": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2548755490797328,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.16269757639620652
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7712418300653594,
        "macro_recall": 0.7648936170212766,
        "macro_f1": 0.7663802363050483,
        "mcc": 0.5360978621613167
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1396712572986316,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.379473584548381
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 0.9767410038007758,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.5090760758719153
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.072112534837795,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.4319665709062418
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.819023569023569,
        "macro_recall": 0.8007936507936508,
        "macro_f1": 0.8008080808080807,
        "mcc": 0.6195490747820372
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.909717652294684,
          "mae": 0.6206896551724138,
          "quadratic_weighted_kappa": 0.5185242121445042
        },
        "curiosity": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0559083903140614,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.3950103950103949
        },
        "surprise": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0170952554312156,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.436122713524413
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.813953488372093,
        "micro_precision": 0.813953488372093,
        "micro_recall": 0.813953488372093,
        "micro_f1": 0.8139534883720931,
        "macro_precision": 0.8173018753781004,
        "macro_recall": 0.7938375350140057,
        "macro_f1": 0.8009259259259259,
        "mcc": 0.610688794449095
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.9069767441860465,
          "rmse": 0.9462287446539036,
          "mae": 0.7093023255813954,
          "quadratic_weighted_kappa": 0.5236656596173213
        },
        "curiosity": {
          "perfect_accuracy": 0.3372093023255814,
          "off_by_one_accuracy": 0.7674418604651163,
          "rmse": 1.1663897788814295,
          "mae": 0.8953488372093024,
          "quadratic_weighted_kappa": 0.310727496917386
        },
        "surprise": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.0890576254854043,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.3673734314149719
        }
      }
    }
  ]
}