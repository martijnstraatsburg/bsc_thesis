{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.741860465116279,
        "std": 0.01837587901326131
      },
      "micro_precision": {
        "mean": 0.741860465116279,
        "std": 0.01837587901326131
      },
      "micro_recall": {
        "mean": 0.741860465116279,
        "std": 0.01837587901326131
      },
      "micro_f1": {
        "mean": 0.741860465116279,
        "std": 0.01837587901326136
      },
      "macro_precision": {
        "mean": 0.7468894837181128,
        "std": 0.022945071211506848
      },
      "macro_recall": {
        "mean": 0.7269097056112075,
        "std": 0.030721049712197045
      },
      "macro_f1": {
        "mean": 0.7279083786756979,
        "std": 0.029693354046151695
      },
      "mcc": {
        "mean": 0.47305460428709634,
        "std": 0.052860081806481427
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3524458700882117,
          "std": 0.04331927218374049
        },
        "off_by_one_accuracy": {
          "mean": 0.8524993317294841,
          "std": 0.02253102165472902
        },
        "rmse": {
          "mean": 1.107797548979281,
          "std": 0.030090094462674404
        },
        "mae": {
          "mean": 0.8226677358994922,
          "std": 0.043698343424737066
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4036992061855906,
          "std": 0.021371214813971667
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3226677358994921,
          "std": 0.026345037600072466
        },
        "off_by_one_accuracy": {
          "mean": 0.7880245923549853,
          "std": 0.032941656071383614
        },
        "rmse": {
          "mean": 1.2299840282221146,
          "std": 0.08695767524809084
        },
        "mae": {
          "mean": 0.9307404437316226,
          "std": 0.07400945080805608
        },
        "quadratic_weighted_kappa": {
          "mean": 0.39596389522389336,
          "std": 0.06332165718287441
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.36180165731087943,
          "std": 0.08265410072538268
        },
        "off_by_one_accuracy": {
          "mean": 0.7879978615343493,
          "std": 0.054280181227317724
        },
        "rmse": {
          "mean": 1.2291485776858806,
          "std": 0.1467585327760228
        },
        "mae": {
          "mean": 0.9009088479016304,
          "std": 0.1560251141255458
        },
        "quadratic_weighted_kappa": {
          "mean": 0.30427524553922686,
          "std": 0.12896000221389217
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7413513513513514,
        "macro_recall": 0.7413513513513514,
        "macro_f1": 0.7413513513513514,
        "mcc": 0.4827027027027027
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1346172578623508,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.3880165808315539
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3687816547538927,
          "mae": 1.0459770114942528,
          "quadratic_weighted_kappa": 0.29605361131794494
        },
        "surprise": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.7126436781609196,
          "rmse": 1.3978637231524922,
          "mae": 1.103448275862069,
          "quadratic_weighted_kappa": 0.18941137783623818
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7321022727272728,
        "macro_recall": 0.7208108108108108,
        "macro_f1": 0.7238095238095239,
        "mcc": 0.4527723093650539
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1141720290623112,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.378817929393098
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2820601237537732,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.37947029777046226
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.3603583030377249,
          "mae": 1.0229885057471264,
          "quadratic_weighted_kappa": 0.15584885192551068
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7692972350230414,
        "macro_recall": 0.7486702127659575,
        "macro_f1": 0.7501709284835225,
        "mcc": 0.5175565697794349
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1295406451144276,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.4092494035602863
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1193183475751618,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.49253491732220267
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1346172578623508,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.36021011162179895
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7764976958525346,
        "macro_recall": 0.753968253968254,
        "macro_f1": 0.7522039875220399,
        "mcc": 0.5299873094401923
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0504514628777804,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4408890078993173
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.203443335628631,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.3942307692307693
        },
        "surprise": {
          "perfect_accuracy": 0.4942528735632184,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.515893827950112
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7093023255813954,
        "micro_precision": 0.7093023255813954,
        "micro_recall": 0.7093023255813954,
        "micro_f1": 0.7093023255813953,
        "macro_precision": 0.7151988636363636,
        "macro_recall": 0.6697478991596638,
        "macro_f1": 0.6720061022120518,
        "mcc": 0.3822541301480977
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.313953488372093,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.1102063499795358,
          "mae": 0.8604651162790697,
          "quadratic_weighted_kappa": 0.4015231092436974
        },
        "curiosity": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.176316679399114,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.4175298804780876
        },
        "surprise": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.7790697674418605,
          "rmse": 1.2529036043768351,
          "mae": 0.8953488372093024,
          "quadratic_weighted_kappa": 0.30001205836247435
        }
      }
    }
  ]
}