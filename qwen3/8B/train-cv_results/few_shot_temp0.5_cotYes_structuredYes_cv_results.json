{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7787757284148624,
        "std": 0.02005103783387624
      },
      "micro_precision": {
        "mean": 0.7787757284148624,
        "std": 0.02005103783387624
      },
      "micro_recall": {
        "mean": 0.7787757284148624,
        "std": 0.02005103783387624
      },
      "micro_f1": {
        "mean": 0.7787757284148624,
        "std": 0.020051037833876222
      },
      "macro_precision": {
        "mean": 0.7800152498181062,
        "std": 0.022997172389315926
      },
      "macro_recall": {
        "mean": 0.7708231922249444,
        "std": 0.020459190576161697
      },
      "macro_f1": {
        "mean": 0.7720843602785797,
        "std": 0.020994005378143353
      },
      "mcc": {
        "mean": 0.5506997491770973,
        "std": 0.042796200860405295
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4008821170809943,
          "std": 0.04224396678383881
        },
        "off_by_one_accuracy": {
          "mean": 0.8916867147821437,
          "std": 0.023751894760765554
        },
        "rmse": {
          "mean": 1.012450122048254,
          "std": 0.049505199717996856
        },
        "mae": {
          "mean": 0.7281208233092756,
          "std": 0.05882010029187767
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4364174323234516,
          "std": 0.042705910168487064
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.43090082865543977,
          "std": 0.029923240459277065
        },
        "off_by_one_accuracy": {
          "mean": 0.8641005078855921,
          "std": 0.03346869543258757
        },
        "rmse": {
          "mean": 1.0147330147114206,
          "std": 0.06771868951974835
        },
        "mae": {
          "mean": 0.7164929163325313,
          "std": 0.05849631974366573
        },
        "quadratic_weighted_kappa": {
          "mean": 0.490294020718166,
          "std": 0.07069809662486341
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3387329591018444,
          "std": 0.052852558189004924
        },
        "off_by_one_accuracy": {
          "mean": 0.8433306602512698,
          "std": 0.03599624354771939
        },
        "rmse": {
          "mean": 1.1180806416112103,
          "std": 0.08798394575709167
        },
        "mae": {
          "mean": 0.8432504677893611,
          "std": 0.08993776769733819
        },
        "quadratic_weighted_kappa": {
          "mean": 0.34268827463879453,
          "std": 0.0945300852437107
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7436373276776247,
        "macro_recall": 0.7483783783783784,
        "macro_f1": 0.7443910256410257,
        "mcc": 0.4919928632043762
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9468641529479986,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.47936166947982206
        },
        "curiosity": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.144702942944678,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.37028571428571433
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1547005383792515,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.31393609789259014
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8027192008879023,
        "macro_recall": 0.7948648648648649,
        "macro_f1": 0.7977574182961849,
        "mcc": 0.5975324468572771
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0339078862458586,
          "mae": 0.7241379310344828,
          "quadratic_weighted_kappa": 0.40026684456304207
        },
        "curiosity": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 0.988438917815802,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.5363927026518713
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.18903032065977,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.20961666297363168
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7846153846153847,
        "macro_recall": 0.7755319148936171,
        "macro_f1": 0.7773737373737373,
        "mcc": 0.5600736449120248
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.093344547181068,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.37271214642262884
        },
        "curiosity": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9767410038007758,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.5372043837723515
        },
        "surprise": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.203443335628631,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.29441297631307917
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.8038290788013318,
        "macro_recall": 0.7896825396825397,
        "macro_f1": 0.7897422126745436,
        "mcc": 0.593343000890973
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 1.0057307059414877,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.4528301886792453
        },
        "curiosity": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0114289425101135,
          "mae": 0.7241379310344828,
          "quadratic_weighted_kappa": 0.4494845360824743
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9649012813540153,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4772642979007492
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7674418604651163,
        "micro_precision": 0.7674418604651163,
        "micro_recall": 0.7674418604651163,
        "micro_f1": 0.7674418604651162,
        "macro_precision": 0.7652752571082879,
        "macro_recall": 0.7456582633053221,
        "macro_f1": 0.7511574074074074,
        "mcc": 0.5105567900208353
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 0.9824033179248569,
          "mae": 0.7325581395348837,
          "quadratic_weighted_kappa": 0.4769163124725194
        },
        "curiosity": {
          "perfect_accuracy": 0.4418604651162791,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 0.9523532664857335,
          "mae": 0.6744186046511628,
          "quadratic_weighted_kappa": 0.558102766798419
        },
        "surprise": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8488372093023255,
          "rmse": 1.0783277320343843,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.4182113381139224
        }
      }
    }
  ]
}