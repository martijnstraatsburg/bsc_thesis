{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7395883453622025,
        "std": 0.017839213248200265
      },
      "micro_precision": {
        "mean": 0.7395883453622025,
        "std": 0.017839213248200265
      },
      "micro_recall": {
        "mean": 0.7395883453622025,
        "std": 0.017839213248200265
      },
      "micro_f1": {
        "mean": 0.7395883453622025,
        "std": 0.017839213248200255
      },
      "macro_precision": {
        "mean": 0.7380578608321525,
        "std": 0.020516262888388367
      },
      "macro_recall": {
        "mean": 0.7358204088229119,
        "std": 0.023099960332957012
      },
      "macro_f1": {
        "mean": 0.7342675985098235,
        "std": 0.021580981414451958
      },
      "mcc": {
        "mean": 0.4738411158992001,
        "std": 0.04340242846696158
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.36634589681903235,
          "std": 0.05957687681805549
        },
        "off_by_one_accuracy": {
          "mean": 0.8041967388398824,
          "std": 0.04578311501331838
        },
        "rmse": {
          "mean": 1.2133179286698497,
          "std": 0.08514776131995788
        },
        "mae": {
          "mean": 0.8801924619085806,
          "std": 0.09902654657710432
        },
        "quadratic_weighted_kappa": {
          "mean": 0.319827306592585,
          "std": 0.0954314962120995
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.26030473135525256,
          "std": 0.04482285984663422
        },
        "off_by_one_accuracy": {
          "mean": 0.8156909917134456,
          "std": 0.037660301767891924
        },
        "rmse": {
          "mean": 1.268694669762795,
          "std": 0.07355151454849287
        },
        "mae": {
          "mean": 0.9884790163058005,
          "std": 0.08062382423899751
        },
        "quadratic_weighted_kappa": {
          "mean": 0.32470945142919905,
          "std": 0.054428449324564365
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.33408179631114676,
          "std": 0.04806567264052986
        },
        "off_by_one_accuracy": {
          "mean": 0.750975674953221,
          "std": 0.08805711709730217
        },
        "rmse": {
          "mean": 1.3190309615777864,
          "std": 0.15201448943247375
        },
        "mae": {
          "mean": 0.9840149692595563,
          "std": 0.1469920413690218
        },
        "quadratic_weighted_kappa": {
          "mean": 0.23077774242720145,
          "std": 0.09947143377949415
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7407211028632026,
        "macro_recall": 0.7454054054054055,
        "macro_f1": 0.7350721567589038,
        "mcc": 0.48610393883522696
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1596670152276025,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.3644877317849784
        },
        "curiosity": {
          "perfect_accuracy": 0.20689655172413793,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3978637231524922,
          "mae": 1.1264367816091954,
          "quadratic_weighted_kappa": 0.23825710754017304
        },
        "surprise": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.6206896551724138,
          "rmse": 1.5610194134588469,
          "mae": 1.2183908045977012,
          "quadratic_weighted_kappa": 0.05859534503879138
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7419871794871795,
        "macro_recall": 0.7448648648648648,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48684353956546655
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7241379310344828,
          "rmse": 1.3603583030377249,
          "mae": 1.0689655172413792,
          "quadratic_weighted_kappa": 0.13424809938809568
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.299867367239363,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.2891445722861431
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.3433531557819876,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.20527142607784954
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7238562091503268,
        "macro_recall": 0.7186170212765958,
        "macro_f1": 0.719656283566058,
        "mcc": 0.4424422115427734
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.1986582537134602,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.3268337975858867
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1938539928826468,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.3754052802223252
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1938539928826468,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.3065946779791747
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7722878625134264,
        "macro_recall": 0.7682539682539682,
        "macro_f1": 0.7686170212765957,
        "mcc": 0.5405267787135715
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.109001829336302,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.3933528836754644
        },
        "curiosity": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.217685764345488,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.3384615384615385
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.124441112772009,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.3464900300464354
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7114369501466276,
        "macro_recall": 0.7019607843137254,
        "macro_f1": 0.7049742710120069,
        "mcc": 0.4132891108389621
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.2389042420341585,
          "mae": 0.8837209302325582,
          "quadratic_weighted_kappa": 0.38021402052849973
        },
        "curiosity": {
          "perfect_accuracy": 0.23255813953488372,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.234202501193985,
          "mae": 0.9883720930232558,
          "quadratic_weighted_kappa": 0.3822787586358154
        },
        "surprise": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.6744186046511628,
          "rmse": 1.372487132993442,
          "mae": 1.0465116279069768,
          "quadratic_weighted_kappa": 0.23693723299375613
        }
      }
    }
  ]
}