{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7856722801390003,
        "std": 0.012480058789455397
      },
      "micro_precision": {
        "mean": 0.7856722801390003,
        "std": 0.012480058789455397
      },
      "micro_recall": {
        "mean": 0.7856722801390003,
        "std": 0.012480058789455397
      },
      "micro_f1": {
        "mean": 0.7856722801390004,
        "std": 0.012480058789455415
      },
      "macro_precision": {
        "mean": 0.7864811153028546,
        "std": 0.015646832872914046
      },
      "macro_recall": {
        "mean": 0.7791249561737672,
        "std": 0.015822046139011538
      },
      "macro_f1": {
        "mean": 0.7797530859261685,
        "std": 0.014733380290411229
      },
      "mcc": {
        "mean": 0.565513925511571,
        "std": 0.030679593299533743
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.38938786420743116,
          "std": 0.04775411542534584
        },
        "off_by_one_accuracy": {
          "mean": 0.9125100240577385,
          "std": 0.023500268356815113
        },
        "rmse": {
          "mean": 0.9567602735888527,
          "std": 0.06057106566496512
        },
        "mae": {
          "mean": 0.7072975140336808,
          "std": 0.06602501874936344
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4981171983029601,
          "std": 0.0509688728150791
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.37784014969259555,
          "std": 0.02979929057254542
        },
        "off_by_one_accuracy": {
          "mean": 0.8364341085271318,
          "std": 0.016621412564173117
        },
        "rmse": {
          "mean": 1.0814494996030055,
          "std": 0.028209376140469318
        },
        "mae": {
          "mean": 0.7972199946538359,
          "std": 0.025907998975602274
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44400580991233085,
          "std": 0.0561982587923039
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3732959101844427,
          "std": 0.0661849936866475
        },
        "off_by_one_accuracy": {
          "mean": 0.8480085538626035,
          "std": 0.02302676736086914
        },
        "rmse": {
          "mean": 1.087590461367397,
          "std": 0.08947093206776253
        },
        "mae": {
          "mean": 0.7994119219460037,
          "std": 0.09247065229077164
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3654689013256036,
          "std": 0.10793147217319038
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7793650793650794,
        "macro_recall": 0.7854054054054054,
        "macro_f1": 0.779746835443038,
        "mcc": 0.5647381826379504
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.9033780792243016,
          "mae": 0.632183908045977,
          "quadratic_weighted_kappa": 0.49538436402254715
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.109001829336302,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4015429122468659
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.144702942944678,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.2728739002932552
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8027192008879023,
        "macro_recall": 0.7948648648648649,
        "macro_f1": 0.7977574182961849,
        "mcc": 0.5975324468572771
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.988438917815802,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.46641171801717296
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0613372610104648,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4903156384505022
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.203443335628631,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.22155943757988916
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7846153846153847,
        "macro_recall": 0.7755319148936171,
        "macro_f1": 0.7773737373737373,
        "mcc": 0.5600736449120248
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0559083903140614,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.42767039674465923
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.072112534837795,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.4742567077592458
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1193183475751618,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.36351432982079324
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.8038290788013318,
        "macro_recall": 0.7896825396825397,
        "macro_f1": 0.7897422126745436,
        "mcc": 0.593343000890973
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9468641529479986,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.5230531346640428
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1193183475751618,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.3550295857988166
        },
        "surprise": {
          "perfect_accuracy": 0.4942528735632184,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 0.9589266029707683,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.5009321669295855
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7674418604651163,
        "micro_precision": 0.7674418604651163,
        "micro_recall": 0.7674418604651163,
        "micro_f1": 0.7674418604651162,
        "macro_precision": 0.7618768328445749,
        "macro_recall": 0.750140056022409,
        "macro_f1": 0.754145225843339,
        "mcc": 0.5118823522596299
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.9418604651162791,
          "rmse": 0.8892118276421005,
          "mae": 0.6744186046511628,
          "quadratic_weighted_kappa": 0.5780663780663781
        },
        "curiosity": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8488372093023255,
          "rmse": 1.0454775252553032,
          "mae": 0.7906976744186046,
          "quadratic_weighted_kappa": 0.4988842053062237
        },
        "surprise": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.0115610777177464,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.46846467200449493
        }
      }
    }
  ]
}