{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.781074578989575,
        "std": 0.025447965873409698
      },
      "micro_precision": {
        "mean": 0.781074578989575,
        "std": 0.025447965873409698
      },
      "micro_recall": {
        "mean": 0.781074578989575,
        "std": 0.025447965873409698
      },
      "micro_f1": {
        "mean": 0.781074578989575,
        "std": 0.02544796587340968
      },
      "macro_precision": {
        "mean": 0.7804310701381288,
        "std": 0.02555044630311029
      },
      "macro_recall": {
        "mean": 0.7781099959247644,
        "std": 0.02470058233130517
      },
      "macro_f1": {
        "mean": 0.7769143563690397,
        "std": 0.026285289147637354
      },
      "mcc": {
        "mean": 0.5585034367188821,
        "std": 0.04994319316256798
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.40772520716385996,
          "std": 0.0701303648116591
        },
        "off_by_one_accuracy": {
          "mean": 0.9193798449612404,
          "std": 0.014415423758824913
        },
        "rmse": {
          "mean": 0.9187354372610284,
          "std": 0.039429774875963663
        },
        "mae": {
          "mean": 0.6751937984496125,
          "std": 0.0706699606232897
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4564489206521866,
          "std": 0.03770547116221124
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.4584335739107191,
          "std": 0.036981778795205644
        },
        "off_by_one_accuracy": {
          "mean": 0.8524458700882116,
          "std": 0.03251812845131485
        },
        "rmse": {
          "mean": 0.9902528528498943,
          "std": 0.06023373844691471
        },
        "mae": {
          "mean": 0.6891205560010693,
          "std": 0.0596788544398368
        },
        "quadratic_weighted_kappa": {
          "mean": 0.41695178528134297,
          "std": 0.05964307119921846
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.36642608928094095,
          "std": 0.04673642242723609
        },
        "off_by_one_accuracy": {
          "mean": 0.8986367281475541,
          "std": 0.013263875219040494
        },
        "rmse": {
          "mean": 0.9851287946098832,
          "std": 0.042442867843085375
        },
        "mae": {
          "mean": 0.741860465116279,
          "std": 0.05507156300294112
        },
        "quadratic_weighted_kappa": {
          "mean": 0.37896397758487577,
          "std": 0.05102140168905751
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.75,
        "macro_recall": 0.7554054054054054,
        "macro_f1": 0.746288441145281,
        "mcc": 0.505376498667484
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.922266074754828,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.4071823204419889
        },
        "curiosity": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.0504514628777804,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.34983652498832307
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0449660391555822,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.2904970383723925
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8006535947712419,
        "macro_recall": 0.7983783783783784,
        "macro_f1": 0.7994032279940322,
        "mcc": 0.5990276523215711
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4942528735632184,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.8775619308793742,
          "mae": 0.5862068965517241,
          "quadratic_weighted_kappa": 0.48319886514761945
        },
        "curiosity": {
          "perfect_accuracy": 0.5172413793103449,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 0.9468641529479986,
          "mae": 0.6206896551724138,
          "quadratic_weighted_kappa": 0.4585926280516994
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.988438917815802,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.3628844662703541
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7706131078224101,
        "macro_recall": 0.7723404255319148,
        "macro_f1": 0.7698412698412699,
        "mcc": 0.5429507857582274
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.988438917815802,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4146283543101402
        },
        "curiosity": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.909717652294684,
          "mae": 0.6206896551724138,
          "quadratic_weighted_kappa": 0.5113122171945701
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0057307059414877,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.3878138493523109
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8190118152524167,
        "macro_recall": 0.8142857142857143,
        "macro_f1": 0.8148936170212766,
        "mcc": 0.633279894587498
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.8840866447369844,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.4971953085160632
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 0.9767410038007758,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.3941605839416058
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9160133513055991,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.43851118380337717
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7674418604651163,
        "micro_precision": 0.7674418604651163,
        "micro_recall": 0.7674418604651163,
        "micro_f1": 0.7674418604651162,
        "macro_precision": 0.7618768328445749,
        "macro_recall": 0.750140056022409,
        "macro_f1": 0.754145225843339,
        "mcc": 0.5118823522596299
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.9302325581395349,
          "rmse": 0.9213236181181537,
          "mae": 0.7093023255813954,
          "quadratic_weighted_kappa": 0.4800397548451216
        },
        "curiosity": {
          "perfect_accuracy": 0.4186046511627907,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.0674899923282326,
          "mae": 0.7674418604651163,
          "quadratic_weighted_kappa": 0.3708569722305165
        },
        "surprise": {
          "perfect_accuracy": 0.3953488372093023,
          "off_by_one_accuracy": 0.9069767441860465,
          "rmse": 0.9704949588309457,
          "mae": 0.7093023255813954,
          "quadratic_weighted_kappa": 0.41511335012594464
        }
      }
    }
  ]
}