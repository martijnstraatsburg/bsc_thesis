{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7787757284148624,
        "std": 0.02005103783387624
      },
      "micro_precision": {
        "mean": 0.7787757284148624,
        "std": 0.02005103783387624
      },
      "micro_recall": {
        "mean": 0.7787757284148624,
        "std": 0.02005103783387624
      },
      "micro_f1": {
        "mean": 0.7787757284148624,
        "std": 0.020051037833876253
      },
      "macro_precision": {
        "mean": 0.7778719410654894,
        "std": 0.021298650752931775
      },
      "macro_recall": {
        "mean": 0.7703256964276989,
        "std": 0.020166828367331732
      },
      "macro_f1": {
        "mean": 0.772297505776369,
        "std": 0.020538026001168545
      },
      "mcc": {
        "mean": 0.5481289932813683,
        "std": 0.04124737553935306
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4217054263565891,
          "std": 0.04783415934048168
        },
        "off_by_one_accuracy": {
          "mean": 0.8895482491312483,
          "std": 0.04260037471455179
        },
        "rmse": {
          "mean": 0.979899674299665,
          "std": 0.0831728256397035
        },
        "mae": {
          "mean": 0.7002405773857256,
          "std": 0.07837203098044863
        },
        "quadratic_weighted_kappa": {
          "mean": 0.46761770232354544,
          "std": 0.09222894111701505
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.4053461641272388,
          "std": 0.05493156974890903
        },
        "off_by_one_accuracy": {
          "mean": 0.8433039294306335,
          "std": 0.021412305034727696
        },
        "rmse": {
          "mean": 1.052267307900744,
          "std": 0.05875858914604889
        },
        "mae": {
          "mean": 0.7605453087409784,
          "std": 0.06753443305104559
        },
        "quadratic_weighted_kappa": {
          "mean": 0.45009208104857323,
          "std": 0.05909366231643959
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3640470462443197,
          "std": 0.055093667448314725
        },
        "off_by_one_accuracy": {
          "mean": 0.8411120021384656,
          "std": 0.03632151015689136
        },
        "rmse": {
          "mean": 1.1045302752382204,
          "std": 0.08854182833248053
        },
        "mae": {
          "mean": 0.8178829190056135,
          "std": 0.08033701664340585
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3491834163919269,
          "std": 0.11405546500478407
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7648648648648648,
        "macro_recall": 0.7648648648648648,
        "macro_f1": 0.7648648648648649,
        "mcc": 0.5297297297297298
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9529144646879353,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.4492347143200577
        },
        "curiosity": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0504514628777804,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.45962732919254656
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2223963651627971,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.1986679892305513
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8164983164983165,
        "macro_recall": 0.8048648648648649,
        "macro_f1": 0.8087912087912088,
        "mcc": 0.6212542683610841
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0449660391555822,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.37936472178418557
        },
        "curiosity": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0827805840074194,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4370003806623525
        },
        "surprise": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1346172578623508,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.27174887892376687
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7607142857142857,
        "macro_recall": 0.7523936170212766,
        "macro_f1": 0.7539393939393939,
        "mcc": 0.5130404334184475
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.072112534837795,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.3968386023294509
        },
        "curiosity": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9407749312478345,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.5550906555090656
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.1497126077675979,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.3284784213705617
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7854054054054054,
        "macro_recall": 0.7793650793650794,
        "macro_f1": 0.779746835443038,
        "mcc": 0.5647381826379504
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9942362632324556,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.4736916150815982
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.109001829336302,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.37669902912621356
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 0.9649012813540153,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.5237548151652363
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7674418604651163,
        "micro_precision": 0.7674418604651163,
        "micro_recall": 0.7674418604651163,
        "micro_f1": 0.7674418604651162,
        "macro_precision": 0.7618768328445749,
        "macro_recall": 0.750140056022409,
        "macro_f1": 0.754145225843339,
        "mcc": 0.5118823522596299
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4418604651162791,
          "off_by_one_accuracy": 0.9534883720930233,
          "rmse": 0.8352690695845568,
          "mae": 0.6046511627906976,
          "quadratic_weighted_kappa": 0.6389588581024349
        },
        "curiosity": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.0783277320343843,
          "mae": 0.8372093023255814,
          "quadratic_weighted_kappa": 0.42204301075268813
        },
        "surprise": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.051023864044341,
          "mae": 0.7790697674418605,
          "quadratic_weighted_kappa": 0.42326697726951856
        }
      }
    }
  ]
}