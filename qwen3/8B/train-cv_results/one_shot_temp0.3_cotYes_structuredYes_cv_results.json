{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7556802993851911,
        "std": 0.025404688422352696
      },
      "micro_precision": {
        "mean": 0.7556802993851911,
        "std": 0.025404688422352696
      },
      "micro_recall": {
        "mean": 0.7556802993851911,
        "std": 0.025404688422352696
      },
      "micro_f1": {
        "mean": 0.7556802993851911,
        "std": 0.025404688422352696
      },
      "macro_precision": {
        "mean": 0.7711116017238169,
        "std": 0.024441642114523966
      },
      "macro_recall": {
        "mean": 0.736453533454785,
        "std": 0.038328100158067216
      },
      "macro_f1": {
        "mean": 0.7375102624023486,
        "std": 0.037171764603805384
      },
      "mcc": {
        "mean": 0.5059377675935627,
        "std": 0.06310052597840325
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3523924084469393,
          "std": 0.04540209229018675
        },
        "off_by_one_accuracy": {
          "mean": 0.8825180433039295,
          "std": 0.03108025517769204
        },
        "rmse": {
          "mean": 1.0647706163475825,
          "std": 0.06517691835933882
        },
        "mae": {
          "mean": 0.792675755145683,
          "std": 0.052744346000933376
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42475632118164963,
          "std": 0.05873848681105367
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3456829724672547,
          "std": 0.04163368005949369
        },
        "off_by_one_accuracy": {
          "mean": 0.7765036086607858,
          "std": 0.027711546648042523
        },
        "rmse": {
          "mean": 1.2159619684029261,
          "std": 0.08619478745443805
        },
        "mae": {
          "mean": 0.9100507885592087,
          "std": 0.08314591573330075
        },
        "quadratic_weighted_kappa": {
          "mean": 0.410166249926265,
          "std": 0.06402475397716736
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.34787489975942265,
          "std": 0.07000221661108594
        },
        "off_by_one_accuracy": {
          "mean": 0.8041165463779738,
          "std": 0.031876052487845724
        },
        "rmse": {
          "mean": 1.242998044262444,
          "std": 0.10037337351892783
        },
        "mae": {
          "mean": 0.9101577118417536,
          "std": 0.11340058478938721
        },
        "quadratic_weighted_kappa": {
          "mean": 0.28726628818629835,
          "std": 0.11449448823124381
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7895604395604396,
        "macro_recall": 0.7848648648648648,
        "macro_f1": 0.7867647058823529,
        "mcc": 0.5744061123825042
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0613372610104648,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.436036512766239
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3476245597431757,
          "mae": 1.0344827586206897,
          "quadratic_weighted_kappa": 0.328546307151231
        },
        "surprise": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.3937462952891333,
          "mae": 1.0919540229885059,
          "quadratic_weighted_kappa": 0.1863759614852526
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7529761904761905,
        "macro_recall": 0.7067567567567568,
        "macro_f1": 0.7097054983316408,
        "mcc": 0.4574037021255367
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0880753861644934,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.36836540494819203
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2502873232999676,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.3794839521711769
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.3217891045025334,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.11910471622701846
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7758620689655172,
        "macro_recall": 0.7468085106382978,
        "macro_f1": 0.7478260869565216,
        "mcc": 0.5218624584427538
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.174440439029407,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.34586466165413543
        },
        "curiosity": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0827805840074194,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.521307584421189
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1547005383792515,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.3685396070579402
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.802360774818402,
        "macro_recall": 0.7642857142857142,
        "macro_f1": 0.760989010989011,
        "mcc": 0.5653658403011748
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.988438917815802,
          "mae": 0.7241379310344828,
          "quadratic_weighted_kappa": 0.4907375525101577
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2129568697262454,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.3943217665615142
        },
        "surprise": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1295406451144276,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.4189181057825381
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7347985347985349,
        "macro_recall": 0.6795518207282913,
        "macro_f1": 0.6822660098522167,
        "mcc": 0.41065072471584413
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.8953488372093024,
          "rmse": 1.0115610777177464,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.4827774740295243
        },
        "curiosity": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.7790697674418605,
          "rmse": 1.1861605052378226,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.4271716393262138
        },
        "surprise": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.2152136380268745,
          "mae": 0.9186046511627907,
          "quadratic_weighted_kappa": 0.34339305037874235
        }
      }
    }
  ]
}