{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7396150761828388,
        "std": 0.022682546492285512
      },
      "micro_precision": {
        "mean": 0.7396150761828388,
        "std": 0.022682546492285512
      },
      "micro_recall": {
        "mean": 0.7396150761828388,
        "std": 0.022682546492285512
      },
      "micro_f1": {
        "mean": 0.7396150761828388,
        "std": 0.022682546492285533
      },
      "macro_precision": {
        "mean": 0.7526587604875157,
        "std": 0.04138023862195795
      },
      "macro_recall": {
        "mean": 0.724076853359707,
        "std": 0.022687239085259957
      },
      "macro_f1": {
        "mean": 0.7250718994033889,
        "std": 0.021084600918146307
      },
      "mcc": {
        "mean": 0.475622123556876,
        "std": 0.06279933209894106
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.36629243517775995,
          "std": 0.0427000575339852
        },
        "off_by_one_accuracy": {
          "mean": 0.8593958834536221,
          "std": 0.020177077864468564
        },
        "rmse": {
          "mean": 1.1192761939462474,
          "std": 0.057695703311183184
        },
        "mae": {
          "mean": 0.8134990644212777,
          "std": 0.06409689611332728
        },
        "quadratic_weighted_kappa": {
          "mean": 0.38452590265988107,
          "std": 0.036793532954409076
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.32951082598235765,
          "std": 0.04642333239082194
        },
        "off_by_one_accuracy": {
          "mean": 0.797219994653836,
          "std": 0.03961850306290535
        },
        "rmse": {
          "mean": 1.2148917271719746,
          "std": 0.10213766957040876
        },
        "mae": {
          "mean": 0.914782143811815,
          "std": 0.09547961763118684
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3756359098233967,
          "std": 0.09524967194148445
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3433573910719059,
          "std": 0.057187590561058196
        },
        "off_by_one_accuracy": {
          "mean": 0.7880513231756215,
          "std": 0.04559547780147284
        },
        "rmse": {
          "mean": 1.2467918453993918,
          "std": 0.13829958162502293
        },
        "mae": {
          "mean": 0.9238973536487569,
          "std": 0.12609264420793034
        },
        "quadratic_weighted_kappa": {
          "mean": 0.28459034403659034,
          "std": 0.1307379860543604
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7011494252873564,
        "micro_precision": 0.7011494252873564,
        "micro_recall": 0.7011494252873564,
        "micro_f1": 0.7011494252873564,
        "macro_precision": 0.6939560439560439,
        "macro_recall": 0.6908108108108109,
        "macro_f1": 0.6919934640522876,
        "mcc": 0.38475399937575705
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1547005383792515,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.36703462117410934
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.3217891045025334,
          "mae": 1.0344827586206897,
          "quadratic_weighted_kappa": 0.26065078832606503
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7126436781609196,
          "rmse": 1.4383899044561526,
          "mae": 1.0804597701149425,
          "quadratic_weighted_kappa": 0.128644558201647
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.75,
        "macro_recall": 0.7272972972972973,
        "macro_f1": 0.7314814814814815,
        "mcc": 0.4767570631855361
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1346172578623508,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.3478784633917815
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2129568697262454,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.39484838604499517
        },
        "surprise": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.3603583030377249,
          "mae": 1.0459770114942528,
          "quadratic_weighted_kappa": 0.13617021276595742
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.8154761904761905,
        "macro_recall": 0.7537234042553191,
        "macro_f1": 0.7528409090909091,
        "mcc": 0.565839881977644
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1038074128205977,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.4021781408012447
        },
        "curiosity": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0227301753122633,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.5341571050308913
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1396712572986316,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.35241420196298
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7760290556900726,
        "macro_recall": 0.7412698412698413,
        "macro_f1": 0.7370879120879121,
        "mcc": 0.5161297761308022
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0170952554312156,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.44828072153325826
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.259447059844805,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.29591836734693877
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0613372610104648,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.4600379987333756
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7325581395348837,
        "micro_precision": 0.7325581395348837,
        "micro_recall": 0.7325581395348837,
        "micro_f1": 0.7325581395348836,
        "macro_precision": 0.7278325123152709,
        "macro_recall": 0.707282913165266,
        "macro_f1": 0.7119557303043542,
        "mcc": 0.4346298971146404
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3372093023255814,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.1861605052378226,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.35725756639901174
        },
        "curiosity": {
          "perfect_accuracy": 0.3372093023255814,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.2575354264740255,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.3926049023680931
        },
        "surprise": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.234202501193985,
          "mae": 0.8953488372093024,
          "quadratic_weighted_kappa": 0.3456847485189918
        }
      }
    }
  ]
}