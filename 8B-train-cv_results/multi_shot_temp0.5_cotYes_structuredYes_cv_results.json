{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7948676824378509,
        "std": 0.02614356253316184
      },
      "micro_precision": {
        "mean": 0.7948676824378509,
        "std": 0.02614356253316184
      },
      "micro_recall": {
        "mean": 0.7948676824378509,
        "std": 0.02614356253316184
      },
      "micro_f1": {
        "mean": 0.7948676824378509,
        "std": 0.02614356253316186
      },
      "macro_precision": {
        "mean": 0.7938353093175256,
        "std": 0.02714623483868312
      },
      "macro_recall": {
        "mean": 0.7937135557692503,
        "std": 0.024359556778163195
      },
      "macro_f1": {
        "mean": 0.7918256236715397,
        "std": 0.026488978771651503
      },
      "mcc": {
        "mean": 0.5875360883955169,
        "std": 0.05142884975704885
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.38719593691526333,
          "std": 0.04056466986476078
        },
        "off_by_one_accuracy": {
          "mean": 0.9262763966853782,
          "std": 0.011663217930067787
        },
        "rmse": {
          "mean": 0.9317723955554843,
          "std": 0.01978607169871727
        },
        "mae": {
          "mean": 0.6934509489441325,
          "std": 0.04165598529507109
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44603405770371934,
          "std": 0.04273598462293835
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.47928361400695,
          "std": 0.04977993678547413
        },
        "off_by_one_accuracy": {
          "mean": 0.8755412991178829,
          "std": 0.022494966309380138
        },
        "rmse": {
          "mean": 0.9511685707447983,
          "std": 0.0294124385296777
        },
        "mae": {
          "mean": 0.6474739374498798,
          "std": 0.03876776363293369
        },
        "quadratic_weighted_kappa": {
          "mean": 0.45442710489302185,
          "std": 0.03836326423459742
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3732959101844427,
          "std": 0.0429393838587651
        },
        "off_by_one_accuracy": {
          "mean": 0.8779470729751404,
          "std": 0.027549401563504185
        },
        "rmse": {
          "mean": 1.0009253008004524,
          "std": 0.05005662774521778
        },
        "mae": {
          "mean": 0.7510558674151296,
          "std": 0.05470210182812683
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3476742109031482,
          "std": 0.062483357435765614
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7730158730158729,
        "macro_recall": 0.778918918918919,
        "macro_f1": 0.7693531283138919,
        "mcc": 0.5519032239416333
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9407749312478345,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.3711630526612222
        },
        "curiosity": {
          "perfect_accuracy": 0.5632183908045977,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 0.9589266029707683,
          "mae": 0.5977011494252874,
          "quadratic_weighted_kappa": 0.4533459000942508
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0449660391555822,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.26877820047774925
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8390804597701149,
        "micro_precision": 0.8390804597701149,
        "micro_recall": 0.8390804597701149,
        "micro_f1": 0.8390804597701149,
        "macro_precision": 0.8373626373626374,
        "macro_recall": 0.8318918918918918,
        "macro_f1": 0.8341503267973855,
        "mcc": 0.6692321688858777
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.9284766908852593,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.4412092146955554
        },
        "curiosity": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.9284766908852593,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.44330688507806504
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0283342182227606,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.27657266811279824
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7936046511627908,
        "macro_recall": 0.7954787234042553,
        "macro_f1": 0.7928571428571428,
        "mcc": 0.5890803935326081
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9649012813540153,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.44270462633451957
        },
        "curiosity": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.909717652294684,
          "mae": 0.6206896551724138,
          "quadratic_weighted_kappa": 0.5169648365206663
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0504514628777804,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.37559808612440204
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8060897435897436,
        "macro_recall": 0.8031746031746032,
        "macro_f1": 0.8036638789326961,
        "mcc": 0.6092573727042999
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9425287356321839,
          "rmse": 0.909717652294684,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.49230021073107477
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9942362632324556,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.3971962616822431
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.9346460390922355,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.4064631956912028
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7674418604651163,
        "micro_precision": 0.7674418604651163,
        "micro_recall": 0.7674418604651163,
        "micro_f1": 0.7674418604651162,
        "macro_precision": 0.7591036414565826,
        "macro_recall": 0.7591036414565826,
        "macro_f1": 0.7591036414565826,
        "mcc": 0.5182072829131653
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43023255813953487,
          "off_by_one_accuracy": 0.9302325581395349,
          "rmse": 0.914991421995628,
          "mae": 0.6511627906976745,
          "quadratic_weighted_kappa": 0.4827931840962245
        },
        "curiosity": {
          "perfect_accuracy": 0.4883720930232558,
          "off_by_one_accuracy": 0.8604651162790697,
          "rmse": 0.9644856443408242,
          "mae": 0.6511627906976745,
          "quadratic_weighted_kappa": 0.46132164108988416
        },
        "surprise": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.9069767441860465,
          "rmse": 0.9462287446539036,
          "mae": 0.7093023255813954,
          "quadratic_weighted_kappa": 0.410958904109589
        }
      }
    }
  ]
}