{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7902165196471531,
        "std": 0.02660940079340364
      },
      "micro_precision": {
        "mean": 0.7902165196471531,
        "std": 0.02660940079340364
      },
      "micro_recall": {
        "mean": 0.7902165196471531,
        "std": 0.02660940079340364
      },
      "micro_f1": {
        "mean": 0.7902165196471531,
        "std": 0.02660940079340367
      },
      "macro_precision": {
        "mean": 0.7903017364320839,
        "std": 0.028977995986660288
      },
      "macro_recall": {
        "mean": 0.7821725752213862,
        "std": 0.03478164856433892
      },
      "macro_f1": {
        "mean": 0.7833484247234246,
        "std": 0.03220961054134952
      },
      "mcc": {
        "mean": 0.5723522910521193,
        "std": 0.06365209849367201
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.36856455493183643,
          "std": 0.03389543947739516
        },
        "off_by_one_accuracy": {
          "mean": 0.9101844426623897,
          "std": 0.029328473639014672
        },
        "rmse": {
          "mean": 0.9777529682553562,
          "std": 0.048502726899124445
        },
        "mae": {
          "mean": 0.7327452552793371,
          "std": 0.048830529798133744
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4835557821976145,
          "std": 0.032724832073984425
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.40093557872226676,
          "std": 0.04741857718920083
        },
        "off_by_one_accuracy": {
          "mean": 0.8087142475273991,
          "std": 0.01610926202406695
        },
        "rmse": {
          "mean": 1.1134502618496875,
          "std": 0.04742746490124492
        },
        "mae": {
          "mean": 0.8041700080192461,
          "std": 0.06371914478877524
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42761974689433924,
          "std": 0.06814022065633982
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.35477145148356054,
          "std": 0.05839748961235705
        },
        "off_by_one_accuracy": {
          "mean": 0.8294840951617214,
          "std": 0.022343896273091707
        },
        "rmse": {
          "mean": 1.135104315913523,
          "std": 0.07986954120130473
        },
        "mae": {
          "mean": 0.8433573910719059,
          "std": 0.08300873195095824
        },
        "quadratic_weighted_kappa": {
          "mean": 0.33214492814931745,
          "std": 0.10726313573513661
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8128313891834571,
        "macro_recall": 0.818918918918919,
        "macro_f1": 0.8141025641025641,
        "mcc": 0.6317209777814623
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.9540229885057471,
          "rmse": 0.9160133513055991,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.4989349112426035
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1295406451144276,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.4175863940654966
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1596670152276025,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.2565188810167264
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7920875420875421,
        "macro_recall": 0.7813513513513514,
        "macro_f1": 0.78489010989011,
        "mcc": 0.5733383806417452
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0283342182227606,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4286122215876642
        },
        "curiosity": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0504514628777804,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.5124343257443082
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2548755490797328,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.17384071532543144
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7846153846153847,
        "macro_recall": 0.7755319148936171,
        "macro_f1": 0.7773737373737373,
        "mcc": 0.5600736449120248
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.039451668003348,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4694433631763333
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.072112534837795,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.47741470446900525
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1346172578623508,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.34857601283594053
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8227124183006536,
        "macro_recall": 0.8134920634920635,
        "macro_f1": 0.8141025641025641,
        "mcc": 0.6361376641186587
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9649012813540153,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4952367308932024
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.18418699983352,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.31203007518797
        },
        "surprise": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0057307059414877,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.47847411444141696
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7441860465116279,
        "micro_precision": 0.7441860465116279,
        "micro_recall": 0.7441860465116279,
        "micro_f1": 0.7441860465116278,
        "macro_precision": 0.7392619479733817,
        "macro_recall": 0.7215686274509804,
        "macro_f1": 0.7262731481481481,
        "mcc": 0.46049078780670555
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.9302325581395349,
          "rmse": 0.9400643223910575,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.5255516840882695
        },
        "curiosity": {
          "perfect_accuracy": 0.4069767441860465,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.1309596665849142,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.41863323500491645
        },
        "surprise": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.1206310514564426,
          "mae": 0.8604651162790697,
          "quadratic_weighted_kappa": 0.4033149171270718
        }
      }
    }
  ]
}