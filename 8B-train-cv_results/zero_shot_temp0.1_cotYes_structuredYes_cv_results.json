{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7741245656241647,
        "std": 0.02837952197971566
      },
      "micro_precision": {
        "mean": 0.7741245656241647,
        "std": 0.02837952197971566
      },
      "micro_recall": {
        "mean": 0.7741245656241647,
        "std": 0.02837952197971566
      },
      "micro_f1": {
        "mean": 0.7741245656241647,
        "std": 0.02837952197971568
      },
      "macro_precision": {
        "mean": 0.772392749136825,
        "std": 0.03078028894862563
      },
      "macro_recall": {
        "mean": 0.7701836594327208,
        "std": 0.032058015008036754
      },
      "macro_f1": {
        "mean": 0.7693099223437546,
        "std": 0.03174354529483956
      },
      "mcc": {
        "mean": 0.5425345975879979,
        "std": 0.06259087082583271
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3732691793638065,
          "std": 0.05114957720647977
        },
        "off_by_one_accuracy": {
          "mean": 0.82956428762363,
          "std": 0.045408607342372405
        },
        "rmse": {
          "mean": 1.1635052833847062,
          "std": 0.08795648355362846
        },
        "mae": {
          "mean": 0.8409248863940123,
          "std": 0.08724984079325632
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3641662600875401,
          "std": 0.08556277702433189
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2765303394814221,
          "std": 0.024463593739666632
        },
        "off_by_one_accuracy": {
          "mean": 0.8180433039294306,
          "std": 0.040466224838940856
        },
        "rmse": {
          "mean": 1.2501863964040516,
          "std": 0.10176745674001249
        },
        "mae": {
          "mean": 0.9653033948142207,
          "std": 0.08335309400573344
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3747432383467766,
          "std": 0.07293018592830426
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3731889869018979,
          "std": 0.06800051775137383
        },
        "off_by_one_accuracy": {
          "mean": 0.7534081796311147,
          "std": 0.08129501349884437
        },
        "rmse": {
          "mean": 1.283187484751354,
          "std": 0.15448492273960943
        },
        "mae": {
          "mean": 0.9332531408714247,
          "std": 0.1609692554289195
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2590180971786,
          "std": 0.09881956782594864
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7595137420718816,
        "macro_recall": 0.7654054054054054,
        "macro_f1": 0.7574671445639187,
        "mcc": 0.5248860825850179
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1646123127807209,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.365512978986403
        },
        "curiosity": {
          "perfect_accuracy": 0.22988505747126436,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.4383899044561526,
          "mae": 1.1264367816091954,
          "quadratic_weighted_kappa": 0.24805531547104576
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.6091954022988506,
          "rmse": 1.5499351117303952,
          "mae": 1.206896551724138,
          "quadratic_weighted_kappa": 0.0993610381891128
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.765224358974359,
        "macro_recall": 0.7683783783783784,
        "macro_f1": 0.7663802363050484,
        "mcc": 0.5335934158813558
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2270888828592579,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.2964380517315883
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2775695315895637,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.3541405269761606
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.317433939105884,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.19636630574417324
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7712418300653594,
        "macro_recall": 0.7648936170212766,
        "macro_f1": 0.7663802363050483,
        "mcc": 0.5360978621613167
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2820601237537732,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.24366222870691234
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1695366997037857,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.41656804733727804
        },
        "surprise": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.1695366997037857,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.3420400381315538
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8275862068965517,
        "micro_precision": 0.8275862068965517,
        "micro_recall": 0.8275862068965517,
        "micro_f1": 0.8275862068965517,
        "macro_precision": 0.8293269230769231,
        "macro_recall": 0.8261904761904761,
        "macro_f1": 0.8267622461170848,
        "mcc": 0.6555098957630033
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0283342182227606,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.46159020583882693
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.18418699983352,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.39
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0985884360051028,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.3661971830985915
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7441860465116279,
        "micro_precision": 0.7441860465116279,
        "micro_recall": 0.7441860465116279,
        "micro_f1": 0.7441860465116278,
        "macro_precision": 0.7366568914956012,
        "macro_recall": 0.7260504201680672,
        "macro_f1": 0.729559748427673,
        "mcc": 0.462585731549296
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8604651162790697,
          "rmse": 1.1154308793070182,
          "mae": 0.8023255813953488,
          "quadratic_weighted_kappa": 0.4536278351739699
        },
        "curiosity": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.8488372093023255,
          "rmse": 1.1812488464372366,
          "mae": 0.9069767441860465,
          "quadratic_weighted_kappa": 0.4649523019493986
        },
        "surprise": {
          "perfect_accuracy": 0.3372093023255814,
          "off_by_one_accuracy": 0.7325581395348837,
          "rmse": 1.2804432372116032,
          "mae": 0.9651162790697675,
          "quadratic_weighted_kappa": 0.29112592072956855
        }
      }
    }
  ]
}