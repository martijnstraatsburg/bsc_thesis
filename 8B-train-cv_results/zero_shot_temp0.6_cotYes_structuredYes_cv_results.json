{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7671478214381181,
        "std": 0.03903252698915224
      },
      "micro_precision": {
        "mean": 0.7671478214381181,
        "std": 0.03903252698915224
      },
      "micro_recall": {
        "mean": 0.7671478214381181,
        "std": 0.03903252698915224
      },
      "micro_f1": {
        "mean": 0.7671478214381182,
        "std": 0.039032526989152265
      },
      "macro_precision": {
        "mean": 0.7658403507323732,
        "std": 0.044544016801824515
      },
      "macro_recall": {
        "mean": 0.7621711746611621,
        "std": 0.044831093056729845
      },
      "macro_f1": {
        "mean": 0.7614565734911976,
        "std": 0.04349801435269188
      },
      "mcc": {
        "mean": 0.5279623947272775,
        "std": 0.08915806664730637
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.36848436246992783,
          "std": 0.07484477029029016
        },
        "off_by_one_accuracy": {
          "mean": 0.8133654103180967,
          "std": 0.03361092186979565
        },
        "rmse": {
          "mean": 1.181948182494919,
          "std": 0.07979083466864191
        },
        "mae": {
          "mean": 0.8596097300187117,
          "std": 0.1035681014473446
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3455450532044662,
          "std": 0.06478916423802683
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2649558941459503,
          "std": 0.029770214669900298
        },
        "off_by_one_accuracy": {
          "mean": 0.8065223202352312,
          "std": 0.03774232848601309
        },
        "rmse": {
          "mean": 1.2549477735611112,
          "std": 0.07406526370062827
        },
        "mae": {
          "mean": 0.9815022721197542,
          "std": 0.06113062248276945
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3480910128965954,
          "std": 0.07288147148863713
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3684843624699279,
          "std": 0.05677691745437407
        },
        "off_by_one_accuracy": {
          "mean": 0.760358192996525,
          "std": 0.08207659191823831
        },
        "rmse": {
          "mean": 1.286398459840265,
          "std": 0.14985928392939082
        },
        "mae": {
          "mean": 0.9356054530874097,
          "std": 0.14621603486788828
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2547869738080573,
          "std": 0.09249834209707629
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7825052854122622,
        "macro_recall": 0.788918918918919,
        "macro_f1": 0.7805655117483075,
        "mcc": 0.5713882100645459
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1938539928826468,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.3176470588235294
        },
        "curiosity": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.735632183908046,
          "rmse": 1.3771534860493695,
          "mae": 1.0919540229885059,
          "quadratic_weighted_kappa": 0.24941176470588233
        },
        "surprise": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.6091954022988506,
          "rmse": 1.5387709679981694,
          "mae": 1.1724137931034482,
          "quadratic_weighted_kappa": 0.10345172586293139
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7413513513513514,
        "macro_recall": 0.7413513513513514,
        "macro_f1": 0.7413513513513514,
        "mcc": 0.4827027027027027
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.259447059844805,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.2664956011730204
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.3042811910348766,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.2905785123966941
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.3433531557819876,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.1897134721480691
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7744173140954496,
        "macro_recall": 0.7630319148936171,
        "macro_f1": 0.7648648648648648,
        "mcc": 0.5373286205163066
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.217685764345488,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.31370390753990096
        },
        "curiosity": {
          "perfect_accuracy": 0.22988505747126436,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1938539928826468,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.3690490115803018
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1695366997037857,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.3311583435622456
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8275862068965517,
        "micro_precision": 0.8275862068965517,
        "micro_recall": 0.8275862068965517,
        "micro_f1": 0.8275862068965517,
        "macro_precision": 0.8324324324324325,
        "macro_recall": 0.8253968253968254,
        "macro_f1": 0.8261159227181879,
        "mcc": 0.657791633186249
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4942528735632184,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0283342182227606,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.4556583242655059
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.18903032065977,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.3713798977853492
        },
        "surprise": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.109001829336302,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.3232279171210469
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7093023255813954,
        "micro_precision": 0.7093023255813954,
        "micro_recall": 0.7093023255813954,
        "micro_f1": 0.7093023255813953,
        "macro_precision": 0.6984953703703703,
        "macro_recall": 0.692156862745098,
        "macro_f1": 0.6943852167732764,
        "mcc": 0.39060080716658363
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.2104198771788934,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.37422037422037424
        },
        "curiosity": {
          "perfect_accuracy": 0.2558139534883721,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.2104198771788934,
          "mae": 0.9534883720930233,
          "quadratic_weighted_kappa": 0.46003587801474977
        },
        "surprise": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.7558139534883721,
          "rmse": 1.27132964638108,
          "mae": 0.9883720930232558,
          "quadratic_weighted_kappa": 0.3263834103459936
        }
      }
    }
  ]
}