{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7556535685645549,
        "std": 0.029563659225146456
      },
      "micro_precision": {
        "mean": 0.7556535685645549,
        "std": 0.029563659225146456
      },
      "micro_recall": {
        "mean": 0.7556535685645549,
        "std": 0.029563659225146456
      },
      "micro_f1": {
        "mean": 0.755653568564555,
        "std": 0.029563659225146498
      },
      "macro_precision": {
        "mean": 0.7738467499476406,
        "std": 0.03472361664811119
      },
      "macro_recall": {
        "mean": 0.734624522072582,
        "std": 0.04144829385304562
      },
      "macro_f1": {
        "mean": 0.7359620331512332,
        "std": 0.04124387198215006
      },
      "mcc": {
        "mean": 0.5066538994089479,
        "std": 0.07652319877404654
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3455225875434376,
          "std": 0.03317621152003802
        },
        "off_by_one_accuracy": {
          "mean": 0.8940390269981288,
          "std": 0.0274824037661243
        },
        "rmse": {
          "mean": 1.054885110354237,
          "std": 0.04926703659571522
        },
        "mae": {
          "mean": 0.7880780539962576,
          "std": 0.051489805685370045
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42422296746824006,
          "std": 0.04595723727473654
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.36645282010157715,
          "std": 0.04641662109852089
        },
        "off_by_one_accuracy": {
          "mean": 0.7696337877572842,
          "std": 0.020039488476190085
        },
        "rmse": {
          "mean": 1.2170665070321862,
          "std": 0.06669429076097948
        },
        "mae": {
          "mean": 0.896124031007752,
          "std": 0.06792944779180109
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4106571021517114,
          "std": 0.05849253627244103
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.37326917936380644,
          "std": 0.04626721292194437
        },
        "off_by_one_accuracy": {
          "mean": 0.8133386794974605,
          "std": 0.04456081517935513
        },
        "rmse": {
          "mean": 1.198155198932152,
          "std": 0.0963246401466847
        },
        "mae": {
          "mean": 0.8641005078855921,
          "std": 0.0970420243955383
        },
        "quadratic_weighted_kappa": {
          "mean": 0.30873045990820813,
          "std": 0.09808240350430819
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7859649122807018,
        "macro_recall": 0.7643243243243243,
        "macro_f1": 0.7694239084949086,
        "mcc": 0.5498635547808608
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9767410038007758,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4966892033177668
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.317433939105884,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.32034766413161586
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.317433939105884,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.22049486738266177
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7555555555555555,
        "macro_recall": 0.7237837837837837,
        "macro_f1": 0.728125,
        "mcc": 0.47828522531723344
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.1038074128205977,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.3644383184011025
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.2548755490797328,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.4182164299311759
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.217685764345488,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.2525474525474526
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7755359394703657,
        "macro_recall": 0.7324468085106384,
        "macro_f1": 0.7314814814814815,
        "mcc": 0.5061519525196635
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.109001829336302,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.38857142857142857
        },
        "curiosity": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.1596670152276025,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.4602577018929953
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.203443335628631,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.2785309990785836
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.8286924939467313,
        "macro_recall": 0.7873015873015874,
        "macro_f1": 0.78489010989011,
        "mcc": 0.6146019044715474
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 1.0283342182227606,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4457063711911359
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2223963651627971,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.37299035369774924
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0227301753122633,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4985114334579084
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7093023255813954,
        "micro_precision": 0.7093023255813954,
        "micro_recall": 0.7093023255813954,
        "micro_f1": 0.7093023255813953,
        "macro_precision": 0.7234848484848485,
        "macro_recall": 0.665266106442577,
        "macro_f1": 0.6658896658896658,
        "mcc": 0.38436685995543457
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.9069767441860465,
          "rmse": 1.0565410875907486,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.42570951585976635
        },
        "curiosity": {
          "perfect_accuracy": 0.4069767441860465,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.1309596665849142,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.4814733611050208
        },
        "surprise": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.2294827802684933,
          "mae": 0.8837209302325582,
          "quadratic_weighted_kappa": 0.29356754707443444
        }
      }
    }
  ]
}