{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7765570703020583,
        "std": 0.028287271285404293
      },
      "micro_precision": {
        "mean": 0.7765570703020583,
        "std": 0.028287271285404293
      },
      "micro_recall": {
        "mean": 0.7765570703020583,
        "std": 0.028287271285404293
      },
      "micro_f1": {
        "mean": 0.7765570703020583,
        "std": 0.028287271285404248
      },
      "macro_precision": {
        "mean": 0.7777827905434612,
        "std": 0.03202905224572963
      },
      "macro_recall": {
        "mean": 0.7710053147193323,
        "std": 0.02883775391779138
      },
      "macro_f1": {
        "mean": 0.7709515640582468,
        "std": 0.028798825841048235
      },
      "mcc": {
        "mean": 0.5486355599039132,
        "std": 0.05977404400097027
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3985030740443732,
          "std": 0.06821198443677703
        },
        "off_by_one_accuracy": {
          "mean": 0.8940122961774927,
          "std": 0.02659468139087222
        },
        "rmse": {
          "mean": 1.017747883437506,
          "std": 0.056475774157446874
        },
        "mae": {
          "mean": 0.7304731355252606,
          "std": 0.07485849749735991
        },
        "quadratic_weighted_kappa": {
          "mean": 0.45283041401129187,
          "std": 0.05017626836116287
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3753274525527934,
          "std": 0.06213753904606589
        },
        "off_by_one_accuracy": {
          "mean": 0.8595028067361667,
          "std": 0.037878468888742384
        },
        "rmse": {
          "mean": 1.0473679008807635,
          "std": 0.08158352659174323
        },
        "mae": {
          "mean": 0.7766639935846031,
          "std": 0.07034696796956012
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4391809601734288,
          "std": 0.08987892004619098
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.36164127238706223,
          "std": 0.05204652093878642
        },
        "off_by_one_accuracy": {
          "mean": 0.834135257952419,
          "std": 0.0112561832070437
        },
        "rmse": {
          "mean": 1.1179600800317846,
          "std": 0.032569033553943375
        },
        "mae": {
          "mean": 0.8272119754076449,
          "std": 0.04702698203516214
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3337759004032708,
          "std": 0.06589042983129578
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7730158730158729,
        "macro_recall": 0.778918918918919,
        "macro_f1": 0.7693531283138919,
        "mcc": 0.5519032239416333
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.9407749312478345,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.48298217179902747
        },
        "curiosity": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1346172578623508,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.3578489521550021
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1497126077675979,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.25574648515956266
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7178571428571429,
        "macro_recall": 0.7143243243243244,
        "macro_f1": 0.7156862745098039,
        "mcc": 0.4321670276274438
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0827805840074194,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.3665048543689321
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0985884360051028,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.3799633475870494
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1497126077675979,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.26233134262331337
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7917553191489362,
        "macro_recall": 0.7917553191489362,
        "macro_f1": 0.7917553191489362,
        "mcc": 0.5835106382978723
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0827805840074194,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.42674418604651154
        },
        "curiosity": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.8969937018449045,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.6109620544269836
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1295406451144276,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.38937717356939616
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7990196078431373,
        "macro_recall": 0.7904761904761906,
        "macro_f1": 0.7908653846153846,
        "mcc": 0.5894338862466558
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5057471264367817,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 1.0,
          "mae": 0.632183908045977,
          "quadratic_weighted_kappa": 0.4849268458659408
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0667385033281394,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4118811881188118
        },
        "surprise": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.093344547181068,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.4195535026943802
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8023255813953488,
        "micro_precision": 0.8023255813953488,
        "micro_recall": 0.8023255813953488,
        "micro_f1": 0.8023255813953488,
        "macro_precision": 0.8072660098522167,
        "macro_recall": 0.7795518207282913,
        "macro_f1": 0.7870977137032182,
        "mcc": 0.5861630234059609
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8953488372093024,
          "rmse": 0.9824033179248569,
          "mae": 0.7558139534883721,
          "quadratic_weighted_kappa": 0.5029940119760479
        },
        "curiosity": {
          "perfect_accuracy": 0.26744186046511625,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.0399016053633197,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.43524925857929664
        },
        "surprise": {
          "perfect_accuracy": 0.313953488372093,
          "off_by_one_accuracy": 0.8488372093023255,
          "rmse": 1.0674899923282326,
          "mae": 0.8372093023255814,
          "quadratic_weighted_kappa": 0.34187099796970166
        }
      }
    }
  ]
}