{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7580593424218123,
        "std": 0.03636535348487302
      },
      "micro_precision": {
        "mean": 0.7580593424218123,
        "std": 0.03636535348487302
      },
      "micro_recall": {
        "mean": 0.7580593424218123,
        "std": 0.03636535348487302
      },
      "micro_f1": {
        "mean": 0.7580593424218123,
        "std": 0.036365353484873034
      },
      "macro_precision": {
        "mean": 0.758792735042735,
        "std": 0.03333741333516383
      },
      "macro_recall": {
        "mean": 0.7563097417997293,
        "std": 0.029951183586358874
      },
      "macro_f1": {
        "mean": 0.7541634765814653,
        "std": 0.03502597425700825
      },
      "mcc": {
        "mean": 0.5150798341987952,
        "std": 0.06322070348665357
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3731087944399893,
          "std": 0.042202336531481345
        },
        "off_by_one_accuracy": {
          "mean": 0.8917936380646886,
          "std": 0.03939343084534249
        },
        "rmse": {
          "mean": 1.0200256990789618,
          "std": 0.05608512883204362
        },
        "mae": {
          "mean": 0.7535151029136595,
          "std": 0.05041211663848999
        },
        "quadratic_weighted_kappa": {
          "mean": 0.45761452796505486,
          "std": 0.04226104416596022
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.38468323977546104,
          "std": 0.05685265373314937
        },
        "off_by_one_accuracy": {
          "mean": 0.8478748997594225,
          "std": 0.022671518247227643
        },
        "rmse": {
          "mean": 1.0621874136889642,
          "std": 0.030351664119726205
        },
        "mae": {
          "mean": 0.7789361133386795,
          "std": 0.04742773807976519
        },
        "quadratic_weighted_kappa": {
          "mean": 0.41659389582103135,
          "std": 0.04524211466906239
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.34341085271317834,
          "std": 0.04281469791924146
        },
        "off_by_one_accuracy": {
          "mean": 0.8549051055867414,
          "std": 0.026514710477580652
        },
        "rmse": {
          "mean": 1.103407563672459,
          "std": 0.07438894957456767
        },
        "mae": {
          "mean": 0.8269981288425555,
          "std": 0.07003646408320659
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3388948785770789,
          "std": 0.09866332269489747
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6896551724137931,
        "micro_precision": 0.6896551724137931,
        "micro_recall": 0.6896551724137931,
        "micro_f1": 0.6896551724137931,
        "macro_precision": 0.6995192307692307,
        "macro_recall": 0.7018918918918919,
        "macro_f1": 0.6894910773298084,
        "mcc": 0.4014041104364277
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.9425287356321839,
          "rmse": 0.9284766908852593,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.48160800826249306
        },
        "curiosity": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0559083903140614,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.4162689354637892
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1346172578623508,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.27109515260323147
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7769607843137255,
        "macro_recall": 0.7748648648648648,
        "macro_f1": 0.7758036077580359,
        "mcc": 0.5518216688505776
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0504514628777804,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4255845942228337
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.0774597626964475,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.396455800535751
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.174440439029407,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.20873124147339706
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7949346405228759,
        "macro_recall": 0.788031914893617,
        "macro_f1": 0.7897422126745435,
        "mcc": 0.5829256874705884
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0774597626964475,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.45949437165528695
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0057307059414877,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.49068653539116547
        },
        "surprise": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1793237883215744,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.3095690955597823
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7753267973856209,
        "macro_recall": 0.7674603174603174,
        "macro_f1": 0.7676282051282051,
        "mcc": 0.5427301083746531
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0613372610104648,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4002532357906584
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0827805840074194,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.35169491525423724
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0170952554312156,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.43766159149669637
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7558139534883721,
        "micro_precision": 0.7558139534883721,
        "micro_recall": 0.7558139534883721,
        "micro_f1": 0.755813953488372,
        "macro_precision": 0.7472222222222222,
        "macro_recall": 0.7492997198879552,
        "macro_f1": 0.7481522800167341,
        "mcc": 0.496517595861729
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.9302325581395349,
          "rmse": 0.9824033179248569,
          "mae": 0.7790697674418605,
          "quadratic_weighted_kappa": 0.5211324298940023
        },
        "curiosity": {
          "perfect_accuracy": 0.3372093023255814,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.0890576254854043,
          "mae": 0.8372093023255814,
          "quadratic_weighted_kappa": 0.42786329246021393
        },
        "surprise": {
          "perfect_accuracy": 0.38372093023255816,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.0115610777177464,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.4674173117522872
        }
      }
    }
  ]
}