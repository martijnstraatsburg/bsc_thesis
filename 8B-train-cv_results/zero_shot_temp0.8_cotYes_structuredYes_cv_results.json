{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7671745522587543,
        "std": 0.030403649962649992
      },
      "micro_precision": {
        "mean": 0.7671745522587543,
        "std": 0.030403649962649992
      },
      "micro_recall": {
        "mean": 0.7671745522587543,
        "std": 0.030403649962649992
      },
      "micro_f1": {
        "mean": 0.7671745522587543,
        "std": 0.030403649962649992
      },
      "macro_precision": {
        "mean": 0.7643210510545361,
        "std": 0.03446393760835935
      },
      "macro_recall": {
        "mean": 0.7601739690700893,
        "std": 0.035619492701358904
      },
      "macro_f1": {
        "mean": 0.760941792143824,
        "std": 0.03495171240567448
      },
      "mcc": {
        "mean": 0.524455413662123,
        "std": 0.06997549026342309
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3802726543704892,
          "std": 0.0432073267172285
        },
        "off_by_one_accuracy": {
          "mean": 0.8133386794974605,
          "std": 0.03747462759407244
        },
        "rmse": {
          "mean": 1.1732477777468435,
          "std": 0.060459764306829825
        },
        "mae": {
          "mean": 0.8455493183640737,
          "std": 0.04716710678625212
        },
        "quadratic_weighted_kappa": {
          "mean": 0.36274293420737314,
          "std": 0.06803271407709277
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2603047313552526,
          "std": 0.019256880217871534
        },
        "off_by_one_accuracy": {
          "mean": 0.8226410050788558,
          "std": 0.0412810771266674
        },
        "rmse": {
          "mean": 1.234218177757374,
          "std": 0.08134665318971779
        },
        "mae": {
          "mean": 0.9677626303127506,
          "std": 0.06311657911747236
        },
        "quadratic_weighted_kappa": {
          "mean": 0.37034903911748374,
          "std": 0.07233682761822206
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.33413525795241916,
          "std": 0.05004820620737597
        },
        "off_by_one_accuracy": {
          "mean": 0.7694734028334669,
          "std": 0.07834576892337163
        },
        "rmse": {
          "mean": 1.268547690007464,
          "std": 0.13315939838408264
        },
        "mae": {
          "mean": 0.9493718257150494,
          "std": 0.13726744633551263
        },
        "quadratic_weighted_kappa": {
          "mean": 0.28315151085385964,
          "std": 0.0882583261576058
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7542553191489361,
        "macro_recall": 0.7583783783783784,
        "macro_f1": 0.7553889409559513,
        "mcc": 0.5126171165920201
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1396712572986316,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.36643681123928595
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.3771534860493695,
          "mae": 1.0689655172413792,
          "quadratic_weighted_kappa": 0.2323118883362747
        },
        "surprise": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.6436781609195402,
          "rmse": 1.4932799662056893,
          "mae": 1.1954022988505748,
          "quadratic_weighted_kappa": 0.1318794362719885
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7656593406593406,
        "macro_recall": 0.7613513513513513,
        "macro_f1": 0.7630718954248367,
        "mcc": 0.5269930841308174
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1596670152276025,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.3671743860739819
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1938539928826468,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.39946559786239144
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2640020369545641,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.26695762865975636
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7712418300653594,
        "macro_recall": 0.7648936170212766,
        "macro_f1": 0.7663802363050483,
        "mcc": 0.5360978621613167
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2865350418053538,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.23767798466593648
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.1295406451144276,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.43687678581841505
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1646123127807209,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.33972215075893997
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8190118152524167,
        "macro_recall": 0.8142857142857143,
        "macro_f1": 0.8148936170212766,
        "mcc": 0.633279894587498
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.109001829336302,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4034604293495675
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2410599844719317,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.3699059561128527
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.109001829336302,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.39540170163018773
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7114369501466276,
        "macro_recall": 0.7019607843137254,
        "macro_f1": 0.7049742710120069,
        "mcc": 0.4132891108389621
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4186046511627907,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.1713637450663281,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.43896505970809374
        },
        "curiosity": {
          "perfect_accuracy": 0.23255813953488372,
          "off_by_one_accuracy": 0.8488372093023255,
          "rmse": 1.2294827802684933,
          "mae": 0.9767441860465116,
          "quadratic_weighted_kappa": 0.4131849674574848
        },
        "surprise": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.7209302325581395,
          "rmse": 1.3118423047600423,
          "mae": 0.9767441860465116,
          "quadratic_weighted_kappa": 0.2817966369484256
        }
      }
    }
  ]
}