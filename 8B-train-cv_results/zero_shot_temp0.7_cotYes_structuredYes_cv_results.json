{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7556268377439187,
        "std": 0.034010344880855546
      },
      "micro_precision": {
        "mean": 0.7556268377439187,
        "std": 0.034010344880855546
      },
      "micro_recall": {
        "mean": 0.7556268377439187,
        "std": 0.034010344880855546
      },
      "micro_f1": {
        "mean": 0.7556268377439188,
        "std": 0.034010344880855595
      },
      "macro_precision": {
        "mean": 0.7537556497380364,
        "std": 0.039533802735911366
      },
      "macro_recall": {
        "mean": 0.7479905276275739,
        "std": 0.036379615198449934
      },
      "macro_f1": {
        "mean": 0.7489758803900964,
        "std": 0.036894583430507846
      },
      "mcc": {
        "mean": 0.5016839969267998,
        "std": 0.07572674300532528
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.37556802993851907,
          "std": 0.04899957019622639
        },
        "off_by_one_accuracy": {
          "mean": 0.80414327719861,
          "std": 0.03635937974886895
        },
        "rmse": {
          "mean": 1.2062342959465895,
          "std": 0.05971642400659751
        },
        "mae": {
          "mean": 0.8686714782143812,
          "std": 0.0601909944139856
        },
        "quadratic_weighted_kappa": {
          "mean": 0.31727412706766633,
          "std": 0.06524570244713374
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.28799786153434914,
          "std": 0.04031326807462141
        },
        "off_by_one_accuracy": {
          "mean": 0.811066559743384,
          "std": 0.03294616748610418
        },
        "rmse": {
          "mean": 1.2596541078922618,
          "std": 0.08842194897403531
        },
        "mae": {
          "mean": 0.9631649291633252,
          "std": 0.08914452552925267
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3557106092256027,
          "std": 0.06822099769455582
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.35717722534081797,
          "std": 0.05651034572088449
        },
        "off_by_one_accuracy": {
          "mean": 0.7603314621758888,
          "std": 0.09691588497101461
        },
        "rmse": {
          "mean": 1.2946388469956642,
          "std": 0.18929395619902778
        },
        "mae": {
          "mean": 0.9515904838278535,
          "std": 0.17916998097536252
        },
        "quadratic_weighted_kappa": {
          "mean": 0.24992729423767596,
          "std": 0.1377844684814097
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7311170212765958,
        "macro_recall": 0.7348648648648648,
        "macro_f1": 0.7320926496184228,
        "mcc": 0.4659668141406542
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.18903032065977,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.3399740948621477
        },
        "curiosity": {
          "perfect_accuracy": 0.21839080459770116,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.4223180044375192,
          "mae": 1.1264367816091954,
          "quadratic_weighted_kappa": 0.2221883572081682
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.5862068965517241,
          "rmse": 1.6081688022566922,
          "mae": 1.2528735632183907,
          "quadratic_weighted_kappa": 0.052562799477276045
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7815340909090909,
        "macro_recall": 0.7678378378378379,
        "macro_f1": 0.7718426501035196,
        "mcc": 0.5492011732934743
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2410599844719317,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.2497103874372506
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.2317635241028795,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.3676907829534193
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.3347693416475743,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.1558685446009389
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7846153846153847,
        "macro_recall": 0.7755319148936171,
        "macro_f1": 0.7773737373737373,
        "mcc": 0.5600736449120248
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2820601237537732,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.23046947485618863
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.174440439029407,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.4108352144469526
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.203443335628631,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.29286543671784293
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7854054054054054,
        "macro_recall": 0.7793650793650794,
        "macro_f1": 0.779746835443038,
        "mcc": 0.5647381826379504
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1038074128205977,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.382234726688103
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1938539928826468,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.39413680781758964
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0283342182227606,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.4590429845904299
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6976744186046512,
        "micro_precision": 0.6976744186046512,
        "micro_recall": 0.6976744186046512,
        "micro_f1": 0.6976744186046512,
        "macro_precision": 0.6861063464837049,
        "macro_recall": 0.6823529411764706,
        "macro_f1": 0.6838235294117646,
        "mcc": 0.3684401696498953
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.2152136380268745,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.38398195149464187
        },
        "curiosity": {
          "perfect_accuracy": 0.27906976744186046,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.275894579008856,
          "mae": 0.9767441860465116,
          "quadratic_weighted_kappa": 0.38370188370188363
        },
        "surprise": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.7441860465116279,
          "rmse": 1.2984785372226633,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.28929670580189204
        }
      }
    }
  ]
}