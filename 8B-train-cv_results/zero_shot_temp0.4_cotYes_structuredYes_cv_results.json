{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7742047580860733,
        "std": 0.028608422730110186
      },
      "micro_precision": {
        "mean": 0.7742047580860733,
        "std": 0.028608422730110186
      },
      "micro_recall": {
        "mean": 0.7742047580860733,
        "std": 0.028608422730110186
      },
      "micro_f1": {
        "mean": 0.7742047580860733,
        "std": 0.028608422730110165
      },
      "macro_precision": {
        "mean": 0.7720843269752299,
        "std": 0.02994854023399197
      },
      "macro_recall": {
        "mean": 0.7696229617781556,
        "std": 0.028675081561677005
      },
      "macro_f1": {
        "mean": 0.7695133325494043,
        "std": 0.029520781921547685
      },
      "mcc": {
        "mean": 0.5416813142504113,
        "std": 0.058458589436831083
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.35712376369954557,
          "std": 0.04860307158863173
        },
        "off_by_one_accuracy": {
          "mean": 0.8065223202352312,
          "std": 0.05534206979009439
        },
        "rmse": {
          "mean": 1.1828169080911262,
          "std": 0.09107764604282051
        },
        "mae": {
          "mean": 0.8731622560812615,
          "std": 0.0974533282018492
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3433518696713399,
          "std": 0.10945870479663349
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.26722801390002676,
          "std": 0.04474595658101467
        },
        "off_by_one_accuracy": {
          "mean": 0.806495589414595,
          "std": 0.03853453393088893
        },
        "rmse": {
          "mean": 1.2668522565217928,
          "std": 0.0888224252673765
        },
        "mae": {
          "mean": 0.9861801657310879,
          "std": 0.09149244164495374
        },
        "quadratic_weighted_kappa": {
          "mean": 0.34729541174983874,
          "std": 0.07253681717977294
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.35247260090884786,
          "std": 0.04865526320016291
        },
        "off_by_one_accuracy": {
          "mean": 0.7649291633253141,
          "std": 0.09167644271355373
        },
        "rmse": {
          "mean": 1.2860183223428028,
          "std": 0.16083588447772593
        },
        "mae": {
          "mean": 0.9470729751403368,
          "std": 0.16166326513566864
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2523156081610235,
          "std": 0.10475314336775422
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7463002114164905,
        "macro_recall": 0.7518918918918919,
        "macro_f1": 0.7454787234042554,
        "mcc": 0.49816072196459943
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.2082094665009577,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.3147906976744186
        },
        "curiosity": {
          "perfect_accuracy": 0.21839080459770116,
          "off_by_one_accuracy": 0.735632183908046,
          "rmse": 1.4263529572376852,
          "mae": 1.1379310344827587,
          "quadratic_weighted_kappa": 0.2321615557217651
        },
        "surprise": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.5977011494252874,
          "rmse": 1.5829551877538357,
          "mae": 1.2413793103448276,
          "quadratic_weighted_kappa": 0.06173938854259431
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7532679738562091,
        "macro_recall": 0.7513513513513514,
        "macro_f1": 0.7522039875220399,
        "mcc": 0.5046156853795842
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7241379310344828,
          "rmse": 1.299867367239363,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.19368261774163043
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.2685406585123122,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.32242990654205606
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.2502873232999676,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.23447204968944102
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7583783783783784,
        "macro_recall": 0.7542553191489361,
        "macro_f1": 0.7553889409559513,
        "mcc": 0.5126171165920201
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2502873232999676,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.27712609970674473
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1547005383792515,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.44298487691798205
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1938539928826468,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.3248216297408938
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8275862068965517,
        "micro_precision": 0.8275862068965517,
        "micro_recall": 0.8275862068965517,
        "micro_f1": 0.8275862068965517,
        "macro_precision": 0.8293269230769231,
        "macro_recall": 0.8261904761904761,
        "macro_f1": 0.8267622461170848,
        "mcc": 0.6555098957630033
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0613372610104648,
          "mae": 0.7126436781609196,
          "quadratic_weighted_kappa": 0.43076512217919616
        },
        "curiosity": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2317635241028795,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.3355704697986577
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.109001829336302,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.36348717948717946
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7790697674418605,
        "micro_precision": 0.7790697674418605,
        "micro_recall": 0.7790697674418605,
        "micro_f1": 0.7790697674418605,
        "macro_precision": 0.7731481481481481,
        "macro_recall": 0.7644257703081232,
        "macro_f1": 0.76773276474769,
        "mcc": 0.5375031515528498
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.0943831224048783,
          "mae": 0.8255813953488372,
          "quadratic_weighted_kappa": 0.5003948110547096
        },
        "curiosity": {
          "perfect_accuracy": 0.2441860465116279,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.2529036043768351,
          "mae": 0.9883720930232558,
          "quadratic_weighted_kappa": 0.40333024976873266
        },
        "surprise": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.7441860465116279,
          "rmse": 1.293993278441261,
          "mae": 0.9767441860465116,
          "quadratic_weighted_kappa": 0.2770577933450088
        }
      }
    }
  ]
}