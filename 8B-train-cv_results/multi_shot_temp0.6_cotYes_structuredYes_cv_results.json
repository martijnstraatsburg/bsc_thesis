{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7650093557872226,
        "std": 0.02334235909628203
      },
      "micro_precision": {
        "mean": 0.7650093557872226,
        "std": 0.02334235909628203
      },
      "micro_recall": {
        "mean": 0.7650093557872226,
        "std": 0.02334235909628203
      },
      "micro_f1": {
        "mean": 0.7650093557872227,
        "std": 0.02334235909628199
      },
      "macro_precision": {
        "mean": 0.7625106854911028,
        "std": 0.022691876805948516
      },
      "macro_recall": {
        "mean": 0.7643750803369075,
        "std": 0.02099809223130104
      },
      "macro_f1": {
        "mean": 0.7622041929814467,
        "std": 0.02296532633270251
      },
      "mcc": {
        "mean": 0.5268733129086826,
        "std": 0.04362872090368947
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3801657310879444,
          "std": 0.06407292394797953
        },
        "off_by_one_accuracy": {
          "mean": 0.9261962042234696,
          "std": 0.027080102421002686
        },
        "rmse": {
          "mean": 0.9204163161356194,
          "std": 0.0746573111392672
        },
        "mae": {
          "mean": 0.6959369152632985,
          "std": 0.08715018259309192
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4654952956905465,
          "std": 0.07668153705221606
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.46311146752205296,
          "std": 0.037730626712209094
        },
        "off_by_one_accuracy": {
          "mean": 0.8570970328789093,
          "std": 0.01430296248815529
        },
        "rmse": {
          "mean": 0.9822103177266257,
          "std": 0.02933130737931426
        },
        "mae": {
          "mean": 0.6797914995990377,
          "std": 0.040226501379404866
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4028752606470465,
          "std": 0.027030037960936764
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3941192194600374,
          "std": 0.03573005915195187
        },
        "off_by_one_accuracy": {
          "mean": 0.8686447473937449,
          "std": 0.025898068353528838
        },
        "rmse": {
          "mean": 1.0206762351740344,
          "std": 0.06540051152032814
        },
        "mae": {
          "mean": 0.7464581662657044,
          "std": 0.0594624686716053
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3162076316920609,
          "std": 0.08802149331023741
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7233086680761099,
        "macro_recall": 0.7283783783783784,
        "macro_f1": 0.7223404255319149,
        "mcc": 0.4516585944850714
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.9160133513055991,
          "mae": 0.7011494252873564,
          "quadratic_weighted_kappa": 0.43611826334014026
        },
        "curiosity": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 0.982607368881035,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.39372822299651555
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.039451668003348,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.2683843263553408
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7667020148462353,
        "macro_recall": 0.7718918918918919,
        "macro_f1": 0.7676282051282051,
        "mcc": 0.5385689013967382
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.9425287356321839,
          "rmse": 0.9033780792243016,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.4542804134640869
        },
        "curiosity": {
          "perfect_accuracy": 0.5172413793103449,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 0.9284766908852593,
          "mae": 0.6091954022988506,
          "quadratic_weighted_kappa": 0.44330688507806504
        },
        "surprise": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1038074128205977,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.17939135077415913
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7581923890063424,
        "macro_recall": 0.7598404255319149,
        "macro_f1": 0.758109360518999,
        "mcc": 0.5180301930525275
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0170952554312156,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.3841434638980651
        },
        "curiosity": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 0.9942362632324556,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.42080817464003717
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.039451668003348,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.33436431710890435
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7928571428571429,
        "macro_recall": 0.7928571428571429,
        "macro_f1": 0.7928571428571429,
        "mcc": 0.5857142857142857
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.9655172413793104,
          "rmse": 0.795099935886035,
          "mae": 0.5632183908045977,
          "quadratic_weighted_kappa": 0.6111968798244901
        },
        "curiosity": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 0.988438917815802,
          "mae": 0.7241379310344828,
          "quadratic_weighted_kappa": 0.36408977556109723
        },
        "surprise": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9033780792243016,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.441551396799566
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7790697674418605,
        "micro_precision": 0.7790697674418605,
        "micro_recall": 0.7790697674418605,
        "micro_f1": 0.7790697674418605,
        "macro_precision": 0.7714932126696833,
        "macro_recall": 0.76890756302521,
        "macro_f1": 0.7700858308709722,
        "mcc": 0.5403945898947902
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8953488372093024,
          "rmse": 0.9704949588309457,
          "mae": 0.7325581395348837,
          "quadratic_weighted_kappa": 0.44173745792594965
        },
        "curiosity": {
          "perfect_accuracy": 0.45348837209302323,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.017292347818577,
          "mae": 0.7093023255813954,
          "quadratic_weighted_kappa": 0.39244324495951743
        },
        "surprise": {
          "perfect_accuracy": 0.4418604651162791,
          "off_by_one_accuracy": 0.8604651162790697,
          "rmse": 1.017292347818577,
          "mae": 0.7093023255813954,
          "quadratic_weighted_kappa": 0.3573467674223342
        }
      }
    }
  ]
}