{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.75800588078054,
        "std": 0.024720387752607858
      },
      "micro_precision": {
        "mean": 0.75800588078054,
        "std": 0.024720387752607858
      },
      "micro_recall": {
        "mean": 0.75800588078054,
        "std": 0.024720387752607858
      },
      "micro_f1": {
        "mean": 0.7580058807805401,
        "std": 0.024720387752607865
      },
      "macro_precision": {
        "mean": 0.7550836803217503,
        "std": 0.026661333486280067
      },
      "macro_recall": {
        "mean": 0.7543172863548332,
        "std": 0.025923173142781118
      },
      "macro_f1": {
        "mean": 0.753557769330869,
        "std": 0.026818922810353904
      },
      "mcc": {
        "mean": 0.5093685178306324,
        "std": 0.05232076008220331
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4054530874097835,
          "std": 0.035809483707699624
        },
        "off_by_one_accuracy": {
          "mean": 0.8594493450948943,
          "std": 0.027566929103960677
        },
        "rmse": {
          "mean": 1.099955133342192,
          "std": 0.04583495499956092
        },
        "mae": {
          "mean": 0.7742582197273457,
          "std": 0.05396263519506555
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44241250992147274,
          "std": 0.056876704788189486
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.2948409516172147,
          "std": 0.024871444955123116
        },
        "off_by_one_accuracy": {
          "mean": 0.8087409783480352,
          "std": 0.01193344789390521
        },
        "rmse": {
          "mean": 1.2042416961361304,
          "std": 0.03767163303688101
        },
        "mae": {
          "mean": 0.9309542902967121,
          "std": 0.0362722166392346
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4437374517217762,
          "std": 0.03923029942042737
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3431168136861802,
          "std": 0.07393255969802258
        },
        "off_by_one_accuracy": {
          "mean": 0.8156375300721732,
          "std": 0.03861337128862371
        },
        "rmse": {
          "mean": 1.2107038709561269,
          "std": 0.1169053745695766
        },
        "mae": {
          "mean": 0.8942261427425822,
          "std": 0.11385803447534998
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3857633196356227,
          "std": 0.07666944328356948
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7432659932659933,
        "macro_recall": 0.7343243243243243,
        "macro_f1": 0.7370879120879121,
        "mcc": 0.4775066052030673
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.072112534837795,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.4177486280283764
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1986582537134602,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.4446146774934887
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3130643285972254,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.3217255717255718
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7419871794871795,
        "macro_recall": 0.7448648648648648,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48684353956546655
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1396712572986316,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.40175257104606577
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2548755490797328,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.41253881413573856
        },
        "surprise": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.3433531557819876,
          "mae": 1.0229885057471264,
          "quadratic_weighted_kappa": 0.2695331301139098
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7583783783783784,
        "macro_recall": 0.7542553191489361,
        "macro_f1": 0.7553889409559513,
        "mcc": 0.5126171165920201
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1547005383792515,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.37472118959107803
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1396712572986316,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.49149123260745875
        },
        "surprise": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0667385033281394,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.46239310904437925
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8046129374337222,
        "macro_recall": 0.803968253968254,
        "macro_f1": 0.8041837680391897,
        "mcc": 0.6085808499381804
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 1.0283342182227606,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.4933535890619066
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2223963651627971,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.3887147335423198
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0774597626964475,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.4539862051823774
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7325581395348837,
        "micro_precision": 0.7325581395348837,
        "micro_recall": 0.7325581395348837,
        "micro_f1": 0.7325581395348836,
        "macro_precision": 0.7271739130434782,
        "macro_recall": 0.7341736694677872,
        "macro_f1": 0.7281099656357388,
        "mcc": 0.4612944778544278
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8604651162790697,
          "rmse": 1.1049571179725208,
          "mae": 0.8023255813953488,
          "quadratic_weighted_kappa": 0.5244865718799367
        },
        "curiosity": {
          "perfect_accuracy": 0.2558139534883721,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.2056070554260303,
          "mae": 0.9651162790697675,
          "quadratic_weighted_kappa": 0.4813278008298755
        },
        "surprise": {
          "perfect_accuracy": 0.2558139534883721,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.2529036043768351,
          "mae": 0.9883720930232558,
          "quadratic_weighted_kappa": 0.42117858211187553
        }
      }
    }
  ]
}