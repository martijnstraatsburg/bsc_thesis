{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7395348837209302,
        "std": 0.0330463006717668
      },
      "micro_precision": {
        "mean": 0.7395348837209302,
        "std": 0.0330463006717668
      },
      "micro_recall": {
        "mean": 0.7395348837209302,
        "std": 0.0330463006717668
      },
      "micro_f1": {
        "mean": 0.7395348837209302,
        "std": 0.03304630067176681
      },
      "macro_precision": {
        "mean": 0.7355280375399668,
        "std": 0.03599077972078524
      },
      "macro_recall": {
        "mean": 0.73696011155085,
        "std": 0.03481315399143903
      },
      "macro_f1": {
        "mean": 0.7357452396476984,
        "std": 0.03545273182987655
      },
      "mcc": {
        "mean": 0.47248028684816007,
        "std": 0.07078455213998437
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.42143811815022725,
          "std": 0.07756445886695465
        },
        "off_by_one_accuracy": {
          "mean": 0.8272921678695535,
          "std": 0.04626057165600871
        },
        "rmse": {
          "mean": 1.138238434691356,
          "std": 0.0916305520345922
        },
        "mae": {
          "mean": 0.7927292167869554,
          "std": 0.10238519861757335
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42032258670147404,
          "std": 0.0854350703674774
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.31331194867682444,
          "std": 0.044096165088088654
        },
        "off_by_one_accuracy": {
          "mean": 0.834108527131783,
          "std": 0.04017762388422067
        },
        "rmse": {
          "mean": 1.1379477555956128,
          "std": 0.06817046578048605
        },
        "mae": {
          "mean": 0.8756214915797914,
          "std": 0.06134787978826852
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44796589225694267,
          "std": 0.04652177663000565
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.37321571772253403,
          "std": 0.01897278252636682
        },
        "off_by_one_accuracy": {
          "mean": 0.8088211708099438,
          "std": 0.036483956922535046
        },
        "rmse": {
          "mean": 1.2032925347106957,
          "std": 0.10139069205061266
        },
        "mae": {
          "mean": 0.8686180165731088,
          "std": 0.05854220598790804
        },
        "quadratic_weighted_kappa": {
          "mean": 0.39242619904330545,
          "std": 0.07241064384819254
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7419871794871795,
        "macro_recall": 0.7448648648648648,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48684353956546655
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.109001829336302,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.45379334624185874
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2548755490797328,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.3791217377715268
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3476245597431757,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.30610802624936895
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7079787234042554,
        "macro_recall": 0.7113513513513514,
        "macro_f1": 0.7087963582808943,
        "mcc": 0.4193165116892884
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.203443335628631,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.3750997605746209
        },
        "curiosity": {
          "perfect_accuracy": 0.2413793103448276,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1346172578623508,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.41666666666666663
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.299867367239363,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.3210702341137124
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7459720730397421,
        "macro_recall": 0.7436170212765958,
        "macro_f1": 0.7443910256410255,
        "mcc": 0.4895834300756971
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2685406585123122,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.27551748750892224
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0449660391555822,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.5080064289541044
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0880753861644934,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4686629113548769
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7933403805496828,
        "macro_recall": 0.7936507936507937,
        "macro_f1": 0.7930761099365751,
        "mcc": 0.5869910921240294
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5172413793103449,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0,
          "mae": 0.632183908045977,
          "quadratic_weighted_kappa": 0.5059076963248254
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.109001829336302,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.4493996569468268
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1346172578623508,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.38546922300706354
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6976744186046512,
        "micro_precision": 0.6976744186046512,
        "micro_recall": 0.6976744186046512,
        "micro_f1": 0.6976744186046512,
        "macro_precision": 0.6883618312189741,
        "macro_recall": 0.6913165266106442,
        "macro_f1": 0.6894444444444444,
        "mcc": 0.379666860786319
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32558139534883723,
          "off_by_one_accuracy": 0.872093023255814,
          "rmse": 1.1102063499795358,
          "mae": 0.8372093023255814,
          "quadratic_weighted_kappa": 0.49129464285714275
        },
        "curiosity": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.146278102544096,
          "mae": 0.8953488372093024,
          "quadratic_weighted_kappa": 0.48663497094558894
        },
        "surprise": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.146278102544096,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.48082060049150555
        }
      }
    }
  ]
}