{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7003475006682706,
        "std": 0.033663857773710046
      },
      "micro_precision": {
        "mean": 0.7003475006682706,
        "std": 0.033663857773710046
      },
      "micro_recall": {
        "mean": 0.7003475006682706,
        "std": 0.033663857773710046
      },
      "micro_f1": {
        "mean": 0.7003475006682706,
        "std": 0.03366385777371009
      },
      "macro_precision": {
        "mean": 0.7067794192600717,
        "std": 0.03150828763753661
      },
      "macro_recall": {
        "mean": 0.7085896739757815,
        "std": 0.029311191999980942
      },
      "macro_f1": {
        "mean": 0.6999809618754599,
        "std": 0.03384514497190378
      },
      "mcc": {
        "mean": 0.41535694226047803,
        "std": 0.06081936846266691
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.33627372360331464,
          "std": 0.04174803101920265
        },
        "off_by_one_accuracy": {
          "mean": 0.8018978882651696,
          "std": 0.02910425432381165
        },
        "rmse": {
          "mean": 1.2424459401656576,
          "std": 0.08112970209435694
        },
        "mae": {
          "mean": 0.919353114140604,
          "std": 0.06583012608517277
        },
        "quadratic_weighted_kappa": {
          "mean": 0.35309912203340466,
          "std": 0.08624120587919322
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3201817695803261,
          "std": 0.03514361893793825
        },
        "off_by_one_accuracy": {
          "mean": 0.82485966319166,
          "std": 0.030465349765337837
        },
        "rmse": {
          "mean": 1.1500331031144806,
          "std": 0.09678425699012072
        },
        "mae": {
          "mean": 0.8802993851911254,
          "std": 0.08393007748998432
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44686420758527223,
          "std": 0.08011795491525449
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.2924351777599572,
          "std": 0.07199062114165075
        },
        "off_by_one_accuracy": {
          "mean": 0.7049986634589682,
          "std": 0.08333889688818875
        },
        "rmse": {
          "mean": 1.4184626839615737,
          "std": 0.14399861217561105
        },
        "mae": {
          "mean": 1.087837476610532,
          "std": 0.16088575460952595
        },
        "quadratic_weighted_kappa": {
          "mean": 0.2253085469031964,
          "std": 0.09542472195765736
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6781609195402298,
        "micro_precision": 0.6781609195402298,
        "micro_recall": 0.6781609195402298,
        "micro_f1": 0.6781609195402298,
        "macro_precision": 0.6853723404255319,
        "macro_recall": 0.6883783783783783,
        "macro_f1": 0.6777777777777778,
        "mcc": 0.373738629983931
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2270888828592579,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.3404132183575439
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.3261299671054765,
          "mae": 1.0229885057471264,
          "quadratic_weighted_kappa": 0.29448242963905236
        },
        "surprise": {
          "perfect_accuracy": 0.22988505747126436,
          "off_by_one_accuracy": 0.5747126436781609,
          "rmse": 1.618854426800759,
          "mae": 1.3103448275862069,
          "quadratic_weighted_kappa": 0.11049327354260086
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7011494252873564,
        "micro_precision": 0.7011494252873564,
        "micro_recall": 0.7011494252873564,
        "micro_f1": 0.7011494252873564,
        "macro_precision": 0.7085106382978723,
        "macro_recall": 0.711891891891892,
        "macro_f1": 0.7007936507936507,
        "mcc": 0.4203889324352968
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.308680128282278,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.28472107267008784
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0774597626964475,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.5099548268362055
        },
        "surprise": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.6896551724137931,
          "rmse": 1.454284198062962,
          "mae": 1.103448275862069,
          "quadratic_weighted_kappa": 0.1286740692357936
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7272004241781549,
        "macro_recall": 0.7279255319148936,
        "macro_f1": 0.7241014799154335,
        "mcc": 0.45512537847101164
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.3603583030377249,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.25188271110398974
        },
        "curiosity": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0985884360051028,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.5072549759965478
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.3042811910348766,
          "mae": 0.896551724137931,
          "quadratic_weighted_kappa": 0.3059508408796894
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7516025641025641,
        "macro_recall": 0.7492063492063492,
        "macro_f1": 0.7468253968253968,
        "mcc": 0.5008031807045816
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1497126077675979,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.39183028387332075
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0667385033281394,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.481675392670157
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.2129568697262454,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.35376044568245124
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6511627906976745,
        "micro_precision": 0.6511627906976745,
        "micro_recall": 0.6511627906976745,
        "micro_f1": 0.6511627906976745,
        "macro_precision": 0.6612111292962357,
        "macro_recall": 0.665546218487395,
        "macro_f1": 0.6504065040650406,
        "mcc": 0.3267285897075694
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.27906976744186046,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.1663897788814295,
          "mae": 0.9186046511627907,
          "quadratic_weighted_kappa": 0.49664832416208105
        },
        "curiosity": {
          "perfect_accuracy": 0.27906976744186046,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.1812488464372366,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.4409534127843987
        },
        "surprise": {
          "perfect_accuracy": 0.20930232558139536,
          "off_by_one_accuracy": 0.6744186046511628,
          "rmse": 1.5019367341830254,
          "mae": 1.2093023255813953,
          "quadratic_weighted_kappa": 0.22766410517544677
        }
      }
    }
  ]
}