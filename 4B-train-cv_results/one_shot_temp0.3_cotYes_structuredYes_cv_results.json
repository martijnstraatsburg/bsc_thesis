{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7533814488104784,
        "std": 0.027544732586636755
      },
      "micro_precision": {
        "mean": 0.7533814488104784,
        "std": 0.027544732586636755
      },
      "micro_recall": {
        "mean": 0.7533814488104784,
        "std": 0.027544732586636755
      },
      "micro_f1": {
        "mean": 0.7533814488104784,
        "std": 0.02754473258663673
      },
      "macro_precision": {
        "mean": 0.7491262301844609,
        "std": 0.03032445082494762
      },
      "macro_recall": {
        "mean": 0.7485112004548802,
        "std": 0.03139566406216446
      },
      "macro_f1": {
        "mean": 0.7483867409186558,
        "std": 0.031258564084646785
      },
      "mcc": {
        "mean": 0.49761924827447224,
        "std": 0.061624698282936693
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.40082865543972196,
          "std": 0.04117587706809882
        },
        "off_by_one_accuracy": {
          "mean": 0.859502806736167,
          "std": 0.037878468888742384
        },
        "rmse": {
          "mean": 1.0947079992263655,
          "std": 0.0811562016616106
        },
        "mae": {
          "mean": 0.7765303394814221,
          "std": 0.07495962703531328
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4411606314570907,
          "std": 0.0798871879432104
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3017642341619888,
          "std": 0.023637724769735646
        },
        "off_by_one_accuracy": {
          "mean": 0.8156909917134456,
          "std": 0.025011821895259544
        },
        "rmse": {
          "mean": 1.1823672937308938,
          "std": 0.054741420140711504
        },
        "mae": {
          "mean": 0.9125100240577385,
          "std": 0.0432832658663425
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4534126798203427,
          "std": 0.04025996708537439
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.34774124565624165,
          "std": 0.07178270106350233
        },
        "off_by_one_accuracy": {
          "mean": 0.8110932905640202,
          "std": 0.049501669230619515
        },
        "rmse": {
          "mean": 1.2001880923142072,
          "std": 0.11580650521069205
        },
        "mae": {
          "mean": 0.8872226677358995,
          "std": 0.11747155280679995
        },
        "quadratic_weighted_kappa": {
          "mean": 0.38737942995619923,
          "std": 0.09488163102257462
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7188552188552189,
        "macro_recall": 0.7108108108108109,
        "macro_f1": 0.7131868131868131,
        "mcc": 0.4295907174837284
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0170952554312156,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.46347814170206936
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.18418699983352,
          "mae": 0.9195402298850575,
          "quadratic_weighted_kappa": 0.4616555082166769
        },
        "surprise": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.7241379310344828,
          "rmse": 1.3261299671054765,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.30276046304541404
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7532223415682062,
        "macro_recall": 0.7548648648648648,
        "macro_f1": 0.7539393939393939,
        "mcc": 0.5080845514854611
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1547005383792515,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.37238805970149247
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2502873232999676,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.41448931116389554
        },
        "surprise": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.3347693416475743,
          "mae": 1.0229885057471264,
          "quadratic_weighted_kappa": 0.24415671767277614
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7686170212765957,
        "macro_recall": 0.7686170212765957,
        "macro_f1": 0.7686170212765957,
        "mcc": 0.5372340425531915
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.217685764345488,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.3258244728779961
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0827805840074194,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.5168245671349232
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0827805840074194,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4669629985583854
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7928571428571429,
        "macro_recall": 0.7928571428571429,
        "macro_f1": 0.7928571428571429,
        "mcc": 0.5857142857142857
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 1.0057307059414877,
          "mae": 0.6896551724137931,
          "quadratic_weighted_kappa": 0.5099846390168971
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.1986582537134602,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.40570522979397783
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0613372610104648,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.46431264136717776
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7120794263651407,
        "macro_recall": 0.715406162464986,
        "macro_f1": 0.7133333333333334,
        "mcc": 0.42747264413569447
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.0783277320343843,
          "mae": 0.7906976744186046,
          "quadratic_weighted_kappa": 0.534127843986999
        },
        "curiosity": {
          "perfect_accuracy": 0.26744186046511625,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.195923307800101,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.4683887827922404
        },
        "surprise": {
          "perfect_accuracy": 0.26744186046511625,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.195923307800101,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.4587043291372428
        }
      }
    }
  ]
}