{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.748757016840417,
        "std": 0.023403196032420002
      },
      "micro_precision": {
        "mean": 0.748757016840417,
        "std": 0.023403196032420002
      },
      "micro_recall": {
        "mean": 0.748757016840417,
        "std": 0.023403196032420002
      },
      "micro_f1": {
        "mean": 0.7487570168404172,
        "std": 0.023403196032420064
      },
      "macro_precision": {
        "mean": 0.745056798710056,
        "std": 0.025839017041150762
      },
      "macro_recall": {
        "mean": 0.7442025287400756,
        "std": 0.024497826009448588
      },
      "macro_f1": {
        "mean": 0.7439975600292814,
        "std": 0.025388391821042793
      },
      "mcc": {
        "mean": 0.4892439175099663,
        "std": 0.05022826838892587
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4008019246190858,
          "std": 0.03831174760065745
        },
        "off_by_one_accuracy": {
          "mean": 0.8524993317294841,
          "std": 0.03135715538187363
        },
        "rmse": {
          "mean": 1.1108363588549195,
          "std": 0.05954767164653784
        },
        "mae": {
          "mean": 0.7858593958834537,
          "std": 0.06573371314337305
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42795227089053123,
          "std": 0.05899053633588492
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3018176958032612,
          "std": 0.02191151309041938
        },
        "off_by_one_accuracy": {
          "mean": 0.8018711574445335,
          "std": 0.016562240445643632
        },
        "rmse": {
          "mean": 1.1907840549272237,
          "std": 0.037946150173041225
        },
        "mae": {
          "mean": 0.9216786955359529,
          "std": 0.0351251527153587
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4453567661748853,
          "std": 0.031161294403576973
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3409248863940123,
          "std": 0.049062118411915046
        },
        "off_by_one_accuracy": {
          "mean": 0.815610799251537,
          "std": 0.04679509401320963
        },
        "rmse": {
          "mean": 1.197638746524082,
          "std": 0.11249095742615743
        },
        "mae": {
          "mean": 0.889494787489976,
          "std": 0.10003323115639545
        },
        "quadratic_weighted_kappa": {
          "mean": 0.39311965179385217,
          "std": 0.08353536878050707
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7417582417582418,
        "macro_recall": 0.7378378378378379,
        "macro_f1": 0.7393790849673203,
        "mcc": 0.4795800558791306
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0985884360051028,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.3943512563813565
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2317635241028795,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.4447345517841601
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.735632183908046,
          "rmse": 1.3433531557819876,
          "mae": 1.0,
          "quadratic_weighted_kappa": 0.3079495364037088
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7532223415682062,
        "macro_recall": 0.7548648648648648,
        "macro_f1": 0.7539393939393939,
        "mcc": 0.5080845514854611
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1646123127807209,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.36840162421557776
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2082094665009577,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.4310211648385601
        },
        "surprise": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.299867367239363,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.2756159728122345
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7475490196078431,
        "macro_recall": 0.7417553191489361,
        "macro_f1": 0.7430182599355531,
        "mcc": 0.48927003685204506
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.144702942944678,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.3808988764044945
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1193183475751618,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.4918823340298988
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0774597626964475,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.4515323637725486
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7815482502651114,
        "macro_recall": 0.780952380952381,
        "macro_f1": 0.7811465642790945,
        "mcc": 0.5625003156086575
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 1.0,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.5165122963909294
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.1938539928826468,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.3980582524271845
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0667385033281394,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.4627954843136032
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7093023255813954,
        "micro_precision": 0.7093023255813954,
        "micro_recall": 0.7093023255813954,
        "micro_f1": 0.7093023255813953,
        "macro_precision": 0.7012061403508771,
        "macro_recall": 0.7056022408963585,
        "macro_f1": 0.7025044970250449,
        "mcc": 0.40678462772453716
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.146278102544096,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.47959730106029785
        },
        "curiosity": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.200774943574473,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.4610875277946229
        },
        "surprise": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.200774943574473,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.46770490166716594
        }
      }
    }
  ]
}