{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7534081796311146,
        "std": 0.039186143131404325
      },
      "micro_precision": {
        "mean": 0.7534081796311146,
        "std": 0.039186143131404325
      },
      "micro_recall": {
        "mean": 0.7534081796311146,
        "std": 0.039186143131404325
      },
      "micro_f1": {
        "mean": 0.7534081796311148,
        "std": 0.03918614313140434
      },
      "macro_precision": {
        "mean": 0.7502855101313926,
        "std": 0.042491687780772475
      },
      "macro_recall": {
        "mean": 0.7503596884028674,
        "std": 0.040701311518175236
      },
      "macro_f1": {
        "mean": 0.7492771875803231,
        "std": 0.04127194412230485
      },
      "mcc": {
        "mean": 0.5006336450484528,
        "std": 0.08314961385760078
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4353916065223202,
          "std": 0.032478288081653914
        },
        "off_by_one_accuracy": {
          "mean": 0.8480085538626035,
          "std": 0.03779726695301155
        },
        "rmse": {
          "mean": 1.0855356635997377,
          "std": 0.05815413466979634
        },
        "mae": {
          "mean": 0.7488372093023256,
          "std": 0.0432998371116386
        },
        "quadratic_weighted_kappa": {
          "mean": 0.46841300483662174,
          "std": 0.05575573086086198
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3063886661320503,
          "std": 0.03627930768908529
        },
        "off_by_one_accuracy": {
          "mean": 0.82485966319166,
          "std": 0.033756867374189745
        },
        "rmse": {
          "mean": 1.1474330834674242,
          "std": 0.07839162790655581
        },
        "mae": {
          "mean": 0.8894947874899758,
          "std": 0.0667659918857599
        },
        "quadratic_weighted_kappa": {
          "mean": 0.44945601124321277,
          "std": 0.05502127501784458
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.37770649558941455,
          "std": 0.041367013721688835
        },
        "off_by_one_accuracy": {
          "mean": 0.813392141138733,
          "std": 0.01658181558117762
        },
        "rmse": {
          "mean": 1.1961791627618026,
          "std": 0.09492662504817698
        },
        "mae": {
          "mean": 0.8595295375568031,
          "std": 0.05818839795453854
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4132639775435999,
          "std": 0.06297290171253565
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7079787234042554,
        "macro_recall": 0.7113513513513514,
        "macro_f1": 0.7087963582808943,
        "mcc": 0.4193165116892884
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0613372610104648,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.4780852105778648
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2317635241028795,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.3931515535827521
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2909944487358056,
          "mae": 0.8850574712643678,
          "quadratic_weighted_kappa": 0.35915671831343665
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7241379310344828,
        "micro_precision": 0.7241379310344828,
        "micro_recall": 0.7241379310344828,
        "micro_f1": 0.7241379310344829,
        "macro_precision": 0.7205726405090138,
        "macro_recall": 0.7248648648648648,
        "macro_f1": 0.721153846153846,
        "mcc": 0.44541682501201413
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.1646123127807209,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4089129433440811
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.174440439029407,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.43062827225130895
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.3261299671054765,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.31790930053804756
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7818918918918919,
        "macro_recall": 0.7773936170212765,
        "macro_f1": 0.7786852322934797,
        "mcc": 0.559267419043386
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.144702942944678,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.4096428571428572
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.5546861210801906
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1193183475751618,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.4721402727525744
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8181336161187699,
        "macro_recall": 0.8174603174603174,
        "macro_f1": 0.8160676532769555,
        "mcc": 0.6355935769589351
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.0227301753122633,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.48694187026116253
        },
        "curiosity": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1497126077675979,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.427860696517413
        },
        "surprise": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0880753861644934,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.44763607224311164
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7325581395348837,
        "micro_precision": 0.7325581395348837,
        "micro_recall": 0.7325581395348837,
        "micro_f1": 0.7325581395348836,
        "macro_precision": 0.7228506787330318,
        "macro_recall": 0.7207282913165266,
        "macro_f1": 0.7216828478964401,
        "mcc": 0.44357389253864027
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3953488372093023,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.034295625950562,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.5584821428571429
        },
        "curiosity": {
          "perfect_accuracy": 0.27906976744186046,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.1812488464372366,
          "mae": 0.9302325581395349,
          "quadratic_weighted_kappa": 0.4409534127843988
        },
        "surprise": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.156377664228076,
          "mae": 0.8953488372093024,
          "quadratic_weighted_kappa": 0.4694775238708293
        }
      }
    }
  ]
}