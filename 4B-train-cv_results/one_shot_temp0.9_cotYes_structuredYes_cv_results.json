{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7464314354450681,
        "std": 0.03579559313973636
      },
      "micro_precision": {
        "mean": 0.7464314354450681,
        "std": 0.03579559313973636
      },
      "micro_recall": {
        "mean": 0.7464314354450681,
        "std": 0.03579559313973636
      },
      "micro_f1": {
        "mean": 0.7464314354450681,
        "std": 0.03579559313973636
      },
      "macro_precision": {
        "mean": 0.7424495791695666,
        "std": 0.03947925792578042
      },
      "macro_recall": {
        "mean": 0.7408758129665515,
        "std": 0.0384932575711883
      },
      "macro_f1": {
        "mean": 0.7410422717869138,
        "std": 0.038785411818161857
      },
      "mcc": {
        "mean": 0.48331255988622973,
        "std": 0.0779260960823469
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.412296177492649,
          "std": 0.06758207006867496
        },
        "off_by_one_accuracy": {
          "mean": 0.8502539427960439,
          "std": 0.03476379964290136
        },
        "rmse": {
          "mean": 1.1126542987927706,
          "std": 0.07899316129177311
        },
        "mae": {
          "mean": 0.7789093825180433,
          "std": 0.09798595691573636
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4253802445787603,
          "std": 0.07368480592336683
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.28572574178027266,
          "std": 0.01989793163743925
        },
        "off_by_one_accuracy": {
          "mean": 0.7949746057203957,
          "std": 0.020662768738393636
        },
        "rmse": {
          "mean": 1.230187198558441,
          "std": 0.020798075661256955
        },
        "mae": {
          "mean": 0.9561881849772786,
          "std": 0.022372339531587612
        },
        "quadratic_weighted_kappa": {
          "mean": 0.41339549823318855,
          "std": 0.04770085541450257
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3685912857524726,
          "std": 0.06781954253386031
        },
        "off_by_one_accuracy": {
          "mean": 0.8317562149157979,
          "std": 0.029862334808152452
        },
        "rmse": {
          "mean": 1.170669352956733,
          "std": 0.10916801385301754
        },
        "mae": {
          "mean": 0.8479818230419675,
          "std": 0.11358395937195884
        },
        "quadratic_weighted_kappa": {
          "mean": 0.419100952660253,
          "std": 0.0875962371965477
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7061598224195338,
        "macro_recall": 0.7008108108108109,
        "macro_f1": 0.7025844386708602,
        "mcc": 0.406935479390428
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0057307059414877,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.4949868073878627
        },
        "curiosity": {
          "perfect_accuracy": 0.27586206896551724,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.203443335628631,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.46547688706846113
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.2640020369545641,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.37143302666458755
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7648648648648648,
        "macro_recall": 0.7648648648648648,
        "macro_f1": 0.7648648648648649,
        "mcc": 0.5297297297297298
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3563218390804598,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.18418699983352,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.34658950997291316
        },
        "curiosity": {
          "perfect_accuracy": 0.25287356321839083,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.2410599844719317,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.4058103975535168
        },
        "surprise": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.3130643285972254,
          "mae": 0.9885057471264368,
          "quadratic_weighted_kappa": 0.2749999999999999
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7586206896551724,
        "micro_precision": 0.7586206896551724,
        "micro_recall": 0.7586206896551724,
        "micro_f1": 0.7586206896551724,
        "macro_precision": 0.7572115384615385,
        "macro_recall": 0.7561170212765957,
        "macro_f1": 0.756562291805463,
        "mcc": 0.5133273928741374
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.2129568697262454,
          "mae": 0.8735632183908046,
          "quadratic_weighted_kappa": 0.3272924972816239
        },
        "curiosity": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.217685764345488,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.4269008834192922
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1141720290623112,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4429689352620346
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7956498388829216,
        "macro_recall": 0.7912698412698413,
        "macro_f1": 0.7917553191489362,
        "mcc": 0.5869033366505347
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5057471264367817,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0449660391555822,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.4600509570784609
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7586206896551724,
          "rmse": 1.2640020369545641,
          "mae": 0.9770114942528736,
          "quadratic_weighted_kappa": 0.3263327948303716
        },
        "surprise": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0057307059414877,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.5212606303151575
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.6976744186046512,
        "micro_precision": 0.6976744186046512,
        "micro_recall": 0.6976744186046512,
        "micro_f1": 0.6976744186046512,
        "macro_precision": 0.6883618312189741,
        "macro_recall": 0.6913165266106442,
        "macro_f1": 0.6894444444444444,
        "mcc": 0.379666860786319
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8604651162790697,
          "rmse": 1.1154308793070182,
          "mae": 0.8255813953488372,
          "quadratic_weighted_kappa": 0.49798145117294057
        },
        "curiosity": {
          "perfect_accuracy": 0.29069767441860467,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.224744871391589,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.44245652829430093
        },
        "surprise": {
          "perfect_accuracy": 0.3372093023255814,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.156377664228076,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.48484217105948535
        }
      }
    }
  ]
}