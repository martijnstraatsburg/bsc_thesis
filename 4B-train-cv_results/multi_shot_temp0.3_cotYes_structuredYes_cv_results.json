{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7556802993851911,
        "std": 0.04609900328636926
      },
      "micro_precision": {
        "mean": 0.7556802993851911,
        "std": 0.04609900328636926
      },
      "micro_recall": {
        "mean": 0.7556802993851911,
        "std": 0.04609900328636926
      },
      "micro_f1": {
        "mean": 0.7556802993851911,
        "std": 0.04609900328636926
      },
      "macro_precision": {
        "mean": 0.7524627459430657,
        "std": 0.04814510216800461
      },
      "macro_recall": {
        "mean": 0.7548741608585162,
        "std": 0.04575599781104258
      },
      "macro_f1": {
        "mean": 0.752840513896944,
        "std": 0.047606555132468004
      },
      "mcc": {
        "mean": 0.5073222736628863,
        "std": 0.09390596044967692
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.439909115209837,
          "std": 0.05433104887990536
        },
        "off_by_one_accuracy": {
          "mean": 0.8801924619085806,
          "std": 0.03131748083222547
        },
        "rmse": {
          "mean": 1.009394272472992,
          "std": 0.06495099482217356
        },
        "mae": {
          "mean": 0.7006148088746325,
          "std": 0.072560072825775
        },
        "quadratic_weighted_kappa": {
          "mean": 0.45962100375478626,
          "std": 0.0570915145206613
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.41242983159583,
          "std": 0.007764095583083142
        },
        "off_by_one_accuracy": {
          "mean": 0.8500935578722265,
          "std": 0.047705461438288216
        },
        "rmse": {
          "mean": 1.031844130584669,
          "std": 0.08487401068247545
        },
        "mae": {
          "mean": 0.7443998930767174,
          "std": 0.050501701191252954
        },
        "quadratic_weighted_kappa": {
          "mean": 0.47866568917888774,
          "std": 0.07565718213729178
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.41689387864207433,
          "std": 0.048377497972111466
        },
        "off_by_one_accuracy": {
          "mean": 0.8501737503341351,
          "std": 0.047869668232584095
        },
        "rmse": {
          "mean": 1.0819452903719409,
          "std": 0.12755216858056787
        },
        "mae": {
          "mean": 0.7628708901363271,
          "std": 0.09294304413229842
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4142008833638148,
          "std": 0.11101034037597117
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7011494252873564,
        "micro_precision": 0.7011494252873564,
        "micro_recall": 0.7011494252873564,
        "micro_f1": 0.7011494252873564,
        "macro_precision": 0.6975079533404029,
        "macro_recall": 0.7013513513513514,
        "macro_f1": 0.6979166666666667,
        "mcc": 0.39884078681965207
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9589266029707683,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.486498450641877
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1141720290623112,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4099472494348154
        },
        "surprise": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.2410599844719317,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.2945661382064626
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.7311170212765958,
        "macro_recall": 0.7348648648648648,
        "macro_f1": 0.7320926496184228,
        "mcc": 0.4659668141406542
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.0985884360051028,
          "mae": 0.7471264367816092,
          "quadratic_weighted_kappa": 0.3598906874080303
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0170952554312156,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.47987245914707055
        },
        "surprise": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.1695366997037857,
          "mae": 0.8390804597701149,
          "quadratic_weighted_kappa": 0.2841734080066376
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8045977011494253,
        "micro_precision": 0.8045977011494253,
        "micro_recall": 0.8045977011494253,
        "micro_f1": 0.8045977011494253,
        "macro_precision": 0.8036858974358974,
        "macro_recall": 0.8023936170212767,
        "macro_f1": 0.802931379080613,
        "mcc": 0.606078136757938
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0504514628777804,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.43345543345543347
        },
        "curiosity": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.9310344827586207,
          "rmse": 0.8969937018449045,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.614019520851819
        },
        "surprise": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9407749312478345,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.5511557788944723
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8160919540229885,
        "micro_precision": 0.8160919540229885,
        "micro_recall": 0.8160919540229885,
        "micro_f1": 0.8160919540229885,
        "macro_precision": 0.8158730158730159,
        "macro_recall": 0.8158730158730159,
        "macro_f1": 0.8158730158730159,
        "mcc": 0.6317460317460317
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5172413793103449,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9160133513055991,
          "mae": 0.5862068965517241,
          "quadratic_weighted_kappa": 0.5045635384975427
        },
        "curiosity": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0,
          "mae": 0.7241379310344828,
          "quadratic_weighted_kappa": 0.485207100591716
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.922266074754828,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.5219780219780219
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7141298417894163,
        "macro_recall": 0.7198879551820728,
        "macro_f1": 0.7153888582460011,
        "mcc": 0.43397959885015563
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8837209302325582,
          "rmse": 1.0229915092057102,
          "mae": 0.7674418604651163,
          "quadratic_weighted_kappa": 0.513696908771048
        },
        "curiosity": {
          "perfect_accuracy": 0.4069767441860465,
          "off_by_one_accuracy": 0.7906976744186046,
          "rmse": 1.1309596665849142,
          "mae": 0.813953488372093,
          "quadratic_weighted_kappa": 0.40428211586901763
        },
        "surprise": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.1360887616813242,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.41913106973347936
        }
      }
    }
  ]
}