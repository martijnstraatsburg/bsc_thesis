{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7465650895482491,
        "std": 0.028877502370226488
      },
      "micro_precision": {
        "mean": 0.7465650895482491,
        "std": 0.028877502370226488
      },
      "micro_recall": {
        "mean": 0.7465650895482491,
        "std": 0.028877502370226488
      },
      "micro_f1": {
        "mean": 0.7465650895482491,
        "std": 0.028877502370226512
      },
      "macro_precision": {
        "mean": 0.7431739404111847,
        "std": 0.03081077989675982
      },
      "macro_recall": {
        "mean": 0.7437284142715932,
        "std": 0.028358042594020614
      },
      "macro_f1": {
        "mean": 0.742723790793502,
        "std": 0.02964572400198035
      },
      "mcc": {
        "mean": 0.48688852747169237,
        "std": 0.059108004789476025
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4331194867682438,
          "std": 0.04214371381659388
        },
        "off_by_one_accuracy": {
          "mean": 0.8525795241913927,
          "std": 0.038588048274889895
        },
        "rmse": {
          "mean": 1.0956441040183624,
          "std": 0.06614790279604169
        },
        "mae": {
          "mean": 0.7534349104517509,
          "std": 0.05525839310351172
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4605128553758847,
          "std": 0.06051774618185034
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.31093290564020315,
          "std": 0.04862876297423334
        },
        "off_by_one_accuracy": {
          "mean": 0.8225608126169472,
          "std": 0.033095044614013726
        },
        "rmse": {
          "mean": 1.1482095502467407,
          "std": 0.08194552641580277
        },
        "mae": {
          "mean": 0.8872493985565356,
          "std": 0.08066676096952125
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4612578570269223,
          "std": 0.055715747341696376
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3731087944399893,
          "std": 0.04860407127855278
        },
        "off_by_one_accuracy": {
          "mean": 0.8180165731087945,
          "std": 0.03989521025418091
        },
        "rmse": {
          "mean": 1.1853695761833258,
          "std": 0.11825723569069534
        },
        "mae": {
          "mean": 0.8572039561614542,
          "std": 0.07496027522811166
        },
        "quadratic_weighted_kappa": {
          "mean": 0.41272454494056515,
          "std": 0.07939964460148558
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7079787234042554,
        "macro_recall": 0.7113513513513514,
        "macro_f1": 0.7087963582808943,
        "mcc": 0.4193165116892884
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1141720290623112,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.44263850990627596
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2502873232999676,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.3854783421626675
        },
        "surprise": {
          "perfect_accuracy": 0.4367816091954023,
          "off_by_one_accuracy": 0.7471264367816092,
          "rmse": 1.3347693416475743,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.3415848835506078
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7126436781609196,
        "micro_precision": 0.7126436781609196,
        "micro_recall": 0.7126436781609196,
        "micro_f1": 0.7126436781609196,
        "macro_precision": 0.7079787234042554,
        "macro_recall": 0.7113513513513514,
        "macro_f1": 0.7087963582808943,
        "mcc": 0.4193165116892884
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.18903032065977,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.38368945458734094
        },
        "curiosity": {
          "perfect_accuracy": 0.26436781609195403,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.1695366997037857,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.42911497105045493
        },
        "surprise": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.317433939105884,
          "mae": 0.9540229885057471,
          "quadratic_weighted_kappa": 0.29586750281395724
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7701149425287356,
        "micro_precision": 0.7701149425287356,
        "micro_recall": 0.7701149425287356,
        "micro_f1": 0.7701149425287356,
        "macro_precision": 0.7712418300653594,
        "macro_recall": 0.7648936170212766,
        "macro_f1": 0.7663802363050483,
        "mcc": 0.5360978621613167
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.1295406451144276,
          "mae": 0.8160919540229885,
          "quadratic_weighted_kappa": 0.4201044856782561
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8735632183908046,
          "rmse": 1.0057307059414877,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.5541059988351776
        },
        "surprise": {
          "perfect_accuracy": 0.40229885057471265,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.0613372610104648,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4978798586572438
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7814482029598309,
        "macro_recall": 0.7817460317460317,
        "macro_f1": 0.7814937210839392,
        "mcc": 0.5631941559568391
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4827586206896552,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.5022686920497139
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8275862068965517,
          "rmse": 1.124441112772009,
          "mae": 0.8275862068965517,
          "quadratic_weighted_kappa": 0.47115384615384615
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.072112534837795,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.4526236315590789
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7558139534883721,
        "micro_precision": 0.7558139534883721,
        "micro_recall": 0.7558139534883721,
        "micro_f1": 0.755813953488372,
        "macro_precision": 0.7472222222222222,
        "macro_recall": 0.7492997198879552,
        "macro_f1": 0.7481522800167341,
        "mcc": 0.496517595861729
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.4069767441860465,
          "off_by_one_accuracy": 0.872093023255814,
          "rmse": 1.0454775252553032,
          "mae": 0.7441860465116279,
          "quadratic_weighted_kappa": 0.5538631346578367
        },
        "curiosity": {
          "perfect_accuracy": 0.2558139534883721,
          "off_by_one_accuracy": 0.813953488372093,
          "rmse": 1.1910519095164538,
          "mae": 0.9534883720930233,
          "quadratic_weighted_kappa": 0.4664361269324654
        },
        "surprise": {
          "perfect_accuracy": 0.3023255813953488,
          "off_by_one_accuracy": 0.8372093023255814,
          "rmse": 1.1411948043149114,
          "mae": 0.8837209302325582,
          "quadratic_weighted_kappa": 0.47566684812193794
        }
      }
    }
  ]
}