{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7533814488104784,
        "std": 0.028487882211879076
      },
      "micro_precision": {
        "mean": 0.7533814488104784,
        "std": 0.028487882211879076
      },
      "micro_recall": {
        "mean": 0.7533814488104784,
        "std": 0.028487882211879076
      },
      "micro_f1": {
        "mean": 0.7533814488104785,
        "std": 0.0284878822118791
      },
      "macro_precision": {
        "mean": 0.7494064858408274,
        "std": 0.032071481861632535
      },
      "macro_recall": {
        "mean": 0.7498306551679518,
        "std": 0.03015936484653569
      },
      "macro_f1": {
        "mean": 0.7492209553146979,
        "std": 0.03091895794478206
      },
      "mcc": {
        "mean": 0.4992299536784606,
        "std": 0.06220412423381406
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.42397754611066557,
          "std": 0.04455270068397085
        },
        "off_by_one_accuracy": {
          "mean": 0.8502272119754076,
          "std": 0.02622014191969904
        },
        "rmse": {
          "mean": 1.1040108631722032,
          "std": 0.049373547818414784
        },
        "mae": {
          "mean": 0.7649826249665865,
          "std": 0.05465688748870828
        },
        "quadratic_weighted_kappa": {
          "mean": 0.45622903581450236,
          "std": 0.04204041114914913
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.3017642341619888,
          "std": 0.023637724769735646
        },
        "off_by_one_accuracy": {
          "mean": 0.8087409783480352,
          "std": 0.04027563889991585
        },
        "rmse": {
          "mean": 1.170748849015132,
          "std": 0.07029860090285463
        },
        "mae": {
          "mean": 0.9102111734830259,
          "std": 0.05595166240665734
        },
        "quadratic_weighted_kappa": {
          "mean": 0.43334825658737036,
          "std": 0.05054656819275642
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3870088211708099,
          "std": 0.05459122091292332
        },
        "off_by_one_accuracy": {
          "mean": 0.811039828922748,
          "std": 0.033890885758272885
        },
        "rmse": {
          "mean": 1.1942602400535205,
          "std": 0.10654925463104982
        },
        "mae": {
          "mean": 0.8525795241913926,
          "std": 0.07092105347581343
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4160347422059174,
          "std": 0.06687625605478488
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.729860365198711,
        "macro_recall": 0.7313513513513514,
        "macro_f1": 0.7305050505050505,
        "mcc": 0.46120930654459663
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.41379310344827586,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0985884360051028,
          "mae": 0.7701149425287356,
          "quadratic_weighted_kappa": 0.45917944467467886
        },
        "curiosity": {
          "perfect_accuracy": 0.2988505747126437,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2502873232999676,
          "mae": 0.9655172413793104,
          "quadratic_weighted_kappa": 0.37673830594184576
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.7701149425287356,
          "rmse": 1.2820601237537732,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.37353341054433753
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.735632183908046,
        "micro_precision": 0.735632183908046,
        "micro_recall": 0.735632183908046,
        "micro_f1": 0.735632183908046,
        "macro_precision": 0.729860365198711,
        "macro_recall": 0.7313513513513514,
        "macro_f1": 0.7305050505050505,
        "mcc": 0.46120930654459663
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.144702942944678,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4176159718144451
        },
        "curiosity": {
          "perfect_accuracy": 0.28735632183908044,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.18903032065977,
          "mae": 0.9310344827586207,
          "quadratic_weighted_kappa": 0.40816326530612246
        },
        "surprise": {
          "perfect_accuracy": 0.3793103448275862,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.3476245597431757,
          "mae": 0.9425287356321839,
          "quadratic_weighted_kappa": 0.30806402899426155
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7816091954022989,
        "micro_precision": 0.7816091954022989,
        "micro_recall": 0.7816091954022989,
        "micro_f1": 0.781609195402299,
        "macro_precision": 0.7818918918918919,
        "macro_recall": 0.7773936170212765,
        "macro_f1": 0.7786852322934797,
        "mcc": 0.559267419043386
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3448275862068966,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.144702942944678,
          "mae": 0.8505747126436781,
          "quadratic_weighted_kappa": 0.4034644532659689
        },
        "curiosity": {
          "perfect_accuracy": 0.3218390804597701,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 1.039451668003348,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.5195629185759605
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0559083903140614,
          "mae": 0.7241379310344828,
          "quadratic_weighted_kappa": 0.47955596669750233
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7933403805496828,
        "macro_recall": 0.7936507936507937,
        "macro_f1": 0.7930761099365751,
        "mcc": 0.5869910921240294
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 1.0114289425101135,
          "mae": 0.6781609195402298,
          "quadratic_weighted_kappa": 0.5183802948311252
        },
        "curiosity": {
          "perfect_accuracy": 0.3333333333333333,
          "off_by_one_accuracy": 0.7816091954022989,
          "rmse": 1.1986582537134602,
          "mae": 0.9080459770114943,
          "quadratic_weighted_kappa": 0.4038155802861686
        },
        "surprise": {
          "perfect_accuracy": 0.3103448275862069,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.1193183475751618,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.43624041376850364
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7209302325581395,
        "micro_precision": 0.7209302325581395,
        "micro_recall": 0.7209302325581395,
        "micro_f1": 0.7209302325581395,
        "macro_precision": 0.7120794263651407,
        "macro_recall": 0.715406162464986,
        "macro_f1": 0.7133333333333334,
        "mcc": 0.42747264413569447
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43023255813953487,
          "off_by_one_accuracy": 0.8488372093023255,
          "rmse": 1.1206310514564426,
          "mae": 0.7674418604651163,
          "quadratic_weighted_kappa": 0.4825050144862938
        },
        "curiosity": {
          "perfect_accuracy": 0.26744186046511625,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.176316679399114,
          "mae": 0.9418604651162791,
          "quadratic_weighted_kappa": 0.4584612128267541
        },
        "surprise": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.1663897788814295,
          "mae": 0.872093023255814,
          "quadratic_weighted_kappa": 0.482779891024982
        }
      }
    }
  ]
}