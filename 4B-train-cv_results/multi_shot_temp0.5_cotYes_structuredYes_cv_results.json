{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7580326116011762,
        "std": 0.050513018936167484
      },
      "micro_precision": {
        "mean": 0.7580326116011762,
        "std": 0.050513018936167484
      },
      "micro_recall": {
        "mean": 0.7580326116011762,
        "std": 0.050513018936167484
      },
      "micro_f1": {
        "mean": 0.7580326116011762,
        "std": 0.050513018936167484
      },
      "macro_precision": {
        "mean": 0.7545376459950127,
        "std": 0.05267212025543933
      },
      "macro_recall": {
        "mean": 0.7572426781331663,
        "std": 0.05156804129682279
      },
      "macro_f1": {
        "mean": 0.7551360343940404,
        "std": 0.05235771136533537
      },
      "mcc": {
        "mean": 0.5117660497116739,
        "std": 0.10422145985811197
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.4421812349639135,
          "std": 0.06283833193127242
        },
        "off_by_one_accuracy": {
          "mean": 0.8732691793638064,
          "std": 0.02299602644552441
        },
        "rmse": {
          "mean": 1.019157935097666,
          "std": 0.053946827871329275
        },
        "mae": {
          "mean": 0.7052659716653301,
          "std": 0.07160719368098688
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4450082824705609,
          "std": 0.05259493013105191
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.41002405773857264,
          "std": 0.04111912742248003
        },
        "off_by_one_accuracy": {
          "mean": 0.8570168404170009,
          "std": 0.04512130851689882
        },
        "rmse": {
          "mean": 1.033448305248815,
          "std": 0.09227643176767408
        },
        "mae": {
          "mean": 0.744480085538626,
          "std": 0.08095690177235725
        },
        "quadratic_weighted_kappa": {
          "mean": 0.47572022087248084,
          "std": 0.0876648897375187
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.43533814488104794,
          "std": 0.0483837009842161
        },
        "off_by_one_accuracy": {
          "mean": 0.84557604918471,
          "std": 0.04870701746558143
        },
        "rmse": {
          "mean": 1.0731752360972409,
          "std": 0.13792992434928522
        },
        "mae": {
          "mean": 0.7467254744720663,
          "std": 0.10850750985011333
        },
        "quadratic_weighted_kappa": {
          "mean": 0.42786085022139275,
          "std": 0.12579622202715723
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.6781609195402298,
        "micro_precision": 0.6781609195402298,
        "micro_recall": 0.6781609195402298,
        "micro_f1": 0.6781609195402298,
        "macro_precision": 0.672275641025641,
        "macro_recall": 0.6743243243243243,
        "macro_f1": 0.6729323308270676,
        "mcc": 0.34659391061779904
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5057471264367817,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9767410038007758,
          "mae": 0.632183908045977,
          "quadratic_weighted_kappa": 0.45091628013078855
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.8160919540229885,
          "rmse": 1.1141720290623112,
          "mae": 0.7816091954022989,
          "quadratic_weighted_kappa": 0.3861230889847118
        },
        "surprise": {
          "perfect_accuracy": 0.4482758620689655,
          "off_by_one_accuracy": 0.8045977011494253,
          "rmse": 1.1938539928826468,
          "mae": 0.8045977011494253,
          "quadratic_weighted_kappa": 0.36443973135383534
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7471264367816092,
        "micro_precision": 0.7471264367816092,
        "micro_recall": 0.7471264367816092,
        "micro_f1": 0.7471264367816093,
        "macro_precision": 0.7436373276776247,
        "macro_recall": 0.7483783783783784,
        "macro_f1": 0.7443910256410257,
        "mcc": 0.4919928632043762
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8390804597701149,
          "rmse": 1.093344547181068,
          "mae": 0.735632183908046,
          "quadratic_weighted_kappa": 0.3503733486502011
        },
        "curiosity": {
          "perfect_accuracy": 0.47126436781609193,
          "off_by_one_accuracy": 0.896551724137931,
          "rmse": 0.9468641529479986,
          "mae": 0.6436781609195402,
          "quadratic_weighted_kappa": 0.5543735224586288
        },
        "surprise": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.7931034482758621,
          "rmse": 1.217685764345488,
          "mae": 0.8620689655172413,
          "quadratic_weighted_kappa": 0.2507510514720608
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7931034482758621,
        "micro_precision": 0.7931034482758621,
        "micro_recall": 0.7931034482758621,
        "micro_f1": 0.7931034482758621,
        "macro_precision": 0.7917553191489362,
        "macro_recall": 0.7917553191489362,
        "macro_f1": 0.7917553191489362,
        "mcc": 0.5835106382978723
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39080459770114945,
          "off_by_one_accuracy": 0.8620689655172413,
          "rmse": 1.039451668003348,
          "mae": 0.7586206896551724,
          "quadratic_weighted_kappa": 0.4365440264572137
        },
        "curiosity": {
          "perfect_accuracy": 0.42528735632183906,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.9033780792243016,
          "mae": 0.6551724137931034,
          "quadratic_weighted_kappa": 0.6060335480579118
        },
        "surprise": {
          "perfect_accuracy": 0.5057471264367817,
          "off_by_one_accuracy": 0.9195402298850575,
          "rmse": 0.8576900278702358,
          "mae": 0.5747126436781609,
          "quadratic_weighted_kappa": 0.6275086968156276
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8275862068965517,
        "micro_precision": 0.8275862068965517,
        "micro_recall": 0.8275862068965517,
        "micro_f1": 0.8275862068965517,
        "macro_precision": 0.827431289640592,
        "macro_recall": 0.8277777777777777,
        "macro_f1": 0.8274950429610046,
        "mcc": 0.6552089758033085
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.5057471264367817,
          "off_by_one_accuracy": 0.9080459770114943,
          "rmse": 0.9407749312478345,
          "mae": 0.6091954022988506,
          "quadratic_weighted_kappa": 0.48882106066386877
        },
        "curiosity": {
          "perfect_accuracy": 0.367816091954023,
          "off_by_one_accuracy": 0.8505747126436781,
          "rmse": 1.0667385033281394,
          "mae": 0.7931034482758621,
          "quadratic_weighted_kappa": 0.4233009708737864
        },
        "surprise": {
          "perfect_accuracy": 0.45977011494252873,
          "off_by_one_accuracy": 0.8850574712643678,
          "rmse": 0.9708391914381,
          "mae": 0.6666666666666666,
          "quadratic_weighted_kappa": 0.48727899956877974
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7441860465116279,
        "micro_precision": 0.7441860465116279,
        "micro_recall": 0.7441860465116279,
        "micro_f1": 0.7441860465116278,
        "macro_precision": 0.7375886524822695,
        "macro_recall": 0.7439775910364146,
        "macro_f1": 0.7391064533921676,
        "mcc": 0.48152386063501346
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3488372093023256,
          "off_by_one_accuracy": 0.872093023255814,
          "rmse": 1.0454775252553032,
          "mae": 0.7906976744186046,
          "quadratic_weighted_kappa": 0.4983866964507322
        },
        "curiosity": {
          "perfect_accuracy": 0.36046511627906974,
          "off_by_one_accuracy": 0.8023255813953488,
          "rmse": 1.1360887616813242,
          "mae": 0.8488372093023255,
          "quadratic_weighted_kappa": 0.40876997398736525
        },
        "surprise": {
          "perfect_accuracy": 0.37209302325581395,
          "off_by_one_accuracy": 0.8255813953488372,
          "rmse": 1.1258072039497333,
          "mae": 0.8255813953488372,
          "quadratic_weighted_kappa": 0.4093257718966604
        }
      }
    }
  ]
}