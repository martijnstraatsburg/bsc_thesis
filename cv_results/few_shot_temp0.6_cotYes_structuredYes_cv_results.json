{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7796586059743955,
        "std": 0.039102285709093514
      },
      "precision": {
        "mean": 0.7616696335999742,
        "std": 0.03688745090353933
      },
      "recall": {
        "mean": 0.7738687482108535,
        "std": 0.03350441443043203
      },
      "f1": {
        "mean": 0.7639773203917525,
        "std": 0.036087925255295694
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.36059743954480805,
          "std": 0.09567453785801583
        },
        "tolerance1_accuracy": {
          "mean": 0.9246088193456614,
          "std": 0.04663462661199292
        },
        "tolerance2_accuracy": {
          "mean": 0.9893314366998578,
          "std": 0.013068203787033666
        },
        "rmse": {
          "mean": 0.9487841398311891,
          "std": 0.13684873007707996
        },
        "kappa": {
          "mean": 0.1567154777131922,
          "std": 0.1340700324402072
        },
        "weighted_kappa": {
          "mean": 0.4351880261863994,
          "std": 0.19215532364938473
        },
        "pearson_correlation": {
          "mean": 0.44313091203032623,
          "std": 0.19335505512737786
        },
        "pearson_p_value": {
          "mean": 0.0705779140462864,
          "std": 0.12409290617001126
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.36031294452347085,
          "std": 0.05066008844153744
        },
        "tolerance1_accuracy": {
          "mean": 0.8388335704125179,
          "std": 0.028752300411089924
        },
        "tolerance2_accuracy": {
          "mean": 0.9839260312944523,
          "std": 0.013126909809455826
        },
        "rmse": {
          "mean": 1.0955711871916713,
          "std": 0.05727094867509768
        },
        "kappa": {
          "mean": 0.13883642541261298,
          "std": 0.06441529686774125
        },
        "weighted_kappa": {
          "mean": 0.4422599784944918,
          "std": 0.0735385851318514
        },
        "pearson_correlation": {
          "mean": 0.4806520902621599,
          "std": 0.0960645125466056
        },
        "pearson_p_value": {
          "mean": 0.008153565704928426,
          "std": 0.008647663963906378
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.3172119487908962,
          "std": 0.07125450286682834
        },
        "tolerance1_accuracy": {
          "mean": 0.8442389758179232,
          "std": 0.05182574831722972
        },
        "tolerance2_accuracy": {
          "mean": 0.9731152204836414,
          "std": 0.0002844950213371167
        },
        "rmse": {
          "mean": 1.1293412507343061,
          "std": 0.09530666675002061
        },
        "kappa": {
          "mean": 0.07979820244404501,
          "std": 0.10055804847159576
        },
        "weighted_kappa": {
          "mean": 0.32668751479590086,
          "std": 0.1211122635503363
        },
        "pearson_correlation": {
          "mean": 0.3357726666149263,
          "std": 0.11770148622162434
        },
        "pearson_p_value": {
          "mean": 0.09193846217085778,
          "std": 0.10389190515769363
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7631578947368421,
        "precision": 0.7464985994397759,
        "recall": 0.782051282051282,
        "f1": 0.7490829053558328
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2894736842105263,
          "tolerance1_accuracy": 0.9473684210526315,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.0,
          "kappa": 0.019120458891013548,
          "weighted_kappa": 0.3507194244604317,
          "pearson_correlation": 0.3613118957310796,
          "pearson_p_value": 0.025829319601663823
        },
        "curiosity": {
          "accuracy": 0.34210526315789475,
          "tolerance1_accuracy": 0.8157894736842105,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.1584926685818493,
          "kappa": 0.07407407407407407,
          "weighted_kappa": 0.3474747474747475,
          "pearson_correlation": 0.3696343353908134,
          "pearson_p_value": 0.022370054049101286
        },
        "surprise": {
          "accuracy": 0.3157894736842105,
          "tolerance1_accuracy": 0.8157894736842105,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.1697953037312037,
          "kappa": 0.11071107110711065,
          "weighted_kappa": 0.30763840224246675,
          "pearson_correlation": 0.31475551457194423,
          "pearson_p_value": 0.05426608751109216
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.7733333333333333,
        "recall": 0.7867132867132867,
        "f1": 0.7791986359761296
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9725975251592747,
          "kappa": 0.10261194029850751,
          "weighted_kappa": 0.4742184328055217,
          "pearson_correlation": 0.479507518212293,
          "pearson_p_value": 0.0026738920183776594
        },
        "curiosity": {
          "accuracy": 0.4594594594594595,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0134234194190634,
          "kappa": 0.2570281124497992,
          "weighted_kappa": 0.5,
          "pearson_correlation": 0.5303499391453557,
          "pearson_p_value": 0.0007344087569092643
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1740436015661335,
          "kappa": 0.09224730127576053,
          "weighted_kappa": 0.2705836876691148,
          "pearson_correlation": 0.28794737113289215,
          "pearson_p_value": 0.08394965690668219
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "precision": 0.7573099415204678,
        "recall": 0.7573099415204678,
        "f1": 0.7567567567567567
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.5405405405405406,
          "tolerance1_accuracy": 0.972972972972973,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.7352146220938077,
          "kappa": 0.41104868913857684,
          "weighted_kappa": 0.7559366754617415,
          "pearson_correlation": 0.7650309362926786,
          "pearson_p_value": 3.5156532817650676e-08
        },
        "curiosity": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.065427207806866,
          "kappa": 0.12818096135721024,
          "weighted_kappa": 0.546938775510204,
          "pearson_correlation": 0.6380686635272865,
          "pearson_p_value": 2.1526347689120364e-05
        },
        "surprise": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0134234194190634,
          "kappa": 0.17625231910946193,
          "weighted_kappa": 0.5344370860927152,
          "pearson_correlation": 0.5382943480540741,
          "pearson_p_value": 0.0005890070058378429
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "precision": 0.8221153846153846,
        "recall": 0.8221153846153846,
        "f1": 0.8221153846153846
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.150792911137501,
          "kappa": 0.09925093632958792,
          "weighted_kappa": 0.16490096729617687,
          "pearson_correlation": 0.16874182076749014,
          "pearson_p_value": 0.3181000404921729
        },
        "curiosity": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1624763874381927,
          "kappa": 0.14533205004812322,
          "weighted_kappa": 0.3812709030100334,
          "pearson_correlation": 0.40137978743021824,
          "pearson_p_value": 0.013807764515897552
        },
        "surprise": {
          "accuracy": 0.1891891891891892,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.2627725822944504,
          "kappa": -0.11334002006018062,
          "weighted_kappa": 0.16583874665647702,
          "pearson_correlation": 0.17785857605773417,
          "pearson_p_value": 0.2922654982251028
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7297297297297297,
        "precision": 0.7090909090909091,
        "recall": 0.7211538461538461,
        "f1": 0.7127329192546583
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8853156407653622,
          "kappa": 0.1515453639082751,
          "weighted_kappa": 0.4301646309081253,
          "pearson_correlation": 0.44106238914808976,
          "pearson_p_value": 0.006286282962684824
        },
        "curiosity": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0780362527123855,
          "kappa": 0.08956692913385822,
          "weighted_kappa": 0.4356154664774743,
          "pearson_correlation": 0.46382772581712545,
          "pearson_p_value": 0.003834074855044912
        },
        "surprise": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0266713466606798,
          "kappa": 0.13312034078807256,
          "weighted_kappa": 0.3549396513187305,
          "pearson_correlation": 0.3600075232579867,
          "pearson_p_value": 0.02862206120557392
        }
      }
    }
  ]
}