{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.8226173541963016,
        "std": 0.027241791020259632
      },
      "precision": {
        "mean": 0.8289281082901774,
        "std": 0.0432397964074765
      },
      "recall": {
        "mean": 0.7824566515355988,
        "std": 0.017505824644616277
      },
      "f1": {
        "mean": 0.7932514634212747,
        "std": 0.021922038536528174
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.3655761024182077,
          "std": 0.040112789148255064
        },
        "tolerance1_accuracy": {
          "mean": 0.9300142247510669,
          "std": 0.03679126750572336
        },
        "tolerance2_accuracy": {
          "mean": 0.9785206258890469,
          "std": 0.02018912659938568
        },
        "rmse": {
          "mean": 0.9689567393420117,
          "std": 0.11358226607641671
        },
        "kappa": {
          "mean": 0.18840847694916665,
          "std": 0.058541388304212356
        },
        "weighted_kappa": {
          "mean": 0.4324967029530368,
          "std": 0.13291372220042283
        },
        "pearson_correlation": {
          "mean": 0.44486068866998635,
          "std": 0.13126927502198896
        },
        "pearson_p_value": {
          "mean": 0.022636348625442754,
          "std": 0.027903225179282624
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.3546230440967283,
          "std": 0.0505681397515308
        },
        "tolerance1_accuracy": {
          "mean": 0.8332859174964439,
          "std": 0.020523116696297496
        },
        "tolerance2_accuracy": {
          "mean": 0.9731152204836414,
          "std": 0.0002844950213371167
        },
        "rmse": {
          "mean": 1.1304583231114322,
          "std": 0.04480045428141375
        },
        "kappa": {
          "mean": 0.14532396972609252,
          "std": 0.045192911957482
        },
        "weighted_kappa": {
          "mean": 0.47080620240376636,
          "std": 0.05988245123418797
        },
        "pearson_correlation": {
          "mean": 0.506089574369572,
          "std": 0.06736975877074382
        },
        "pearson_p_value": {
          "mean": 0.004320422155651351,
          "std": 0.006928019619054508
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.3817923186344239,
          "std": 0.05803698435277383
        },
        "tolerance1_accuracy": {
          "mean": 0.8438122332859175,
          "std": 0.04389344231443042
        },
        "tolerance2_accuracy": {
          "mean": 0.9677098150782362,
          "std": 0.010885420466406273
        },
        "rmse": {
          "mean": 1.114241746596586,
          "std": 0.08177552358763682
        },
        "kappa": {
          "mean": 0.1491590100306674,
          "std": 0.07733431890689742
        },
        "weighted_kappa": {
          "mean": 0.34153250496648513,
          "std": 0.151369627921687
        },
        "pearson_correlation": {
          "mean": 0.37546371109587573,
          "std": 0.13954198651741498
        },
        "pearson_p_value": {
          "mean": 0.06835793834407063,
          "std": 0.061584107959238125
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.8157894736842105,
        "precision": 0.8026819923371648,
        "recall": 0.7532051282051282,
        "f1": 0.7696969696969697
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3684210526315789,
          "tolerance1_accuracy": 0.9473684210526315,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 0.9597148699373931,
          "kappa": 0.14205079962370648,
          "weighted_kappa": 0.4252376836646501,
          "pearson_correlation": 0.45911905526363483,
          "pearson_p_value": 0.003738119206445274
        },
        "curiosity": {
          "accuracy": 0.39473684210526316,
          "tolerance1_accuracy": 0.8421052631578947,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.1002392084403616,
          "kappa": 0.16920152091254748,
          "weighted_kappa": 0.49362688296639623,
          "pearson_correlation": 0.52254875431443,
          "pearson_p_value": 0.00076405964046386
        },
        "surprise": {
          "accuracy": 0.3684210526315789,
          "tolerance1_accuracy": 0.8947368421052632,
          "tolerance2_accuracy": 0.9736842105263158,
          "rmse": 1.038723913473187,
          "kappa": 0.14366197183098595,
          "weighted_kappa": 0.4301389904901244,
          "pearson_correlation": 0.4690212280780693,
          "pearson_p_value": 0.002974649939790546
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "precision": 0.8174603174603174,
        "recall": 0.7797202797202798,
        "f1": 0.7944444444444445
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 0.9459459459459459,
          "rmse": 1.1624763874381927,
          "kappa": 0.16891284815813112,
          "weighted_kappa": 0.2890084550345887,
          "pearson_correlation": 0.29450954283166414,
          "pearson_p_value": 0.07682314411787342
        },
        "curiosity": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.065427207806866,
          "kappa": 0.18924302788844627,
          "weighted_kappa": 0.5116279069767442,
          "pearson_correlation": 0.5494063678788257,
          "pearson_p_value": 0.00042861617887297984
        },
        "surprise": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.9459459459459459,
          "rmse": 1.2192155209340498,
          "kappa": 0.13618677042801552,
          "weighted_kappa": 0.2791356712716967,
          "pearson_correlation": 0.29799270495390956,
          "pearson_p_value": 0.07323702237747419
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "precision": 0.8157051282051282,
        "recall": 0.7880116959064327,
        "f1": 0.7797619047619048
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.43243243243243246,
          "tolerance1_accuracy": 0.972972972972973,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8053872662568292,
          "kappa": 0.3037634408602151,
          "weighted_kappa": 0.6828571428571428,
          "pearson_correlation": 0.6853196266246253,
          "pearson_p_value": 2.871818061427379e-06
        },
        "curiosity": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.138989594902999,
          "kappa": 0.12818096135721013,
          "weighted_kappa": 0.5398963730569948,
          "pearson_correlation": 0.5832701488517862,
          "pearson_p_value": 0.00015140577385364863
        },
        "surprise": {
          "accuracy": 0.4594594594594595,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0,
          "kappa": 0.2808551992225462,
          "weighted_kappa": 0.5941298547287281,
          "pearson_correlation": 0.6036648456631386,
          "pearson_p_value": 7.638618182570659e-05
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8648648648648649,
        "precision": 0.9137931034482758,
        "recall": 0.8076923076923077,
        "f1": 0.8337825696316263
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 0.9586025865388216,
          "kappa": 0.16975609756097543,
          "weighted_kappa": 0.3778437190900099,
          "pearson_correlation": 0.38624735399473037,
          "pearson_p_value": 0.018212495348841753
        },
        "curiosity": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.150792911137501,
          "kappa": 0.1753875968992249,
          "weighted_kappa": 0.3715771230502599,
          "pearson_correlation": 0.38656826125287114,
          "pearson_p_value": 0.018108150552096806
        },
        "surprise": {
          "accuracy": 0.43243243243243246,
          "tolerance1_accuracy": 0.7837837837837838,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.1624763874381927,
          "kappa": 0.1470911086717892,
          "weighted_kappa": 0.19354838709677424,
          "pearson_correlation": 0.27190858875627966,
          "pearson_p_value": 0.10351918995794901
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.7949999999999999,
        "recall": 0.7836538461538461,
        "f1": 0.7885714285714285
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9586025865388216,
          "kappa": 0.1575591985428051,
          "weighted_kappa": 0.38753651411879264,
          "pearson_correlation": 0.399107864635277,
          "pearson_p_value": 0.014405112635991892
        },
        "curiosity": {
          "accuracy": 0.2702702702702703,
          "tolerance1_accuracy": 0.8108108108108109,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.196842693269434,
          "kappa": 0.06460674157303381,
          "weighted_kappa": 0.4373027259684362,
          "pearson_correlation": 0.48865433954994697,
          "pearson_p_value": 0.0021498786329694586
        },
        "surprise": {
          "accuracy": 0.2972972972972973,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.150792911137501,
          "kappa": 0.038000000000000034,
          "weighted_kappa": 0.21070962124510229,
          "pearson_correlation": 0.23473118802798157,
          "pearson_p_value": 0.16198244326331368
        }
      }
    }
  ]
}