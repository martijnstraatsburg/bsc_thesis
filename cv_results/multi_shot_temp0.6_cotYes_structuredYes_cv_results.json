{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7637268847795164,
        "std": 0.03330657952525117
      },
      "precision": {
        "mean": 0.7486592411043884,
        "std": 0.039021898945249725
      },
      "recall": {
        "mean": 0.7684481454218297,
        "std": 0.03894538466969262
      },
      "f1": {
        "mean": 0.7506837066201213,
        "std": 0.03803522553930859
      }
    },
    "rating_metrics": {
      "suspense": {
        "accuracy": {
          "mean": 0.3812233285917496,
          "std": 0.0796077870818391
        },
        "tolerance1_accuracy": {
          "mean": 0.9354196301564723,
          "std": 0.013482783056697303
        },
        "tolerance2_accuracy": {
          "mean": 1.0,
          "std": 0.0
        },
        "rmse": {
          "mean": 0.899439509726274,
          "std": 0.059383072353941295
        },
        "kappa": {
          "mean": 0.11274438732637768,
          "std": 0.11036295075360311
        },
        "weighted_kappa": {
          "mean": 0.3739005454609848,
          "std": 0.10435084059567178
        },
        "pearson_correlation": {
          "mean": 0.42562345275082614,
          "std": 0.11673200775892763
        },
        "pearson_p_value": {
          "mean": 0.030549053185914537,
          "std": 0.04478197742932943
        }
      },
      "curiosity": {
        "accuracy": {
          "mean": 0.45149359886201995,
          "std": 0.029215851886065982
        },
        "tolerance1_accuracy": {
          "mean": 0.8497866287339972,
          "std": 0.0346640576857453
        },
        "tolerance2_accuracy": {
          "mean": 1.0,
          "std": 0.0
        },
        "rmse": {
          "mean": 0.9981566567679065,
          "std": 0.053195897265711646
        },
        "kappa": {
          "mean": 0.21315024275325758,
          "std": 0.04957034377861492
        },
        "weighted_kappa": {
          "mean": 0.38138998915199634,
          "std": 0.06677811104100917
        },
        "pearson_correlation": {
          "mean": 0.4066489533685919,
          "std": 0.07619593439261607
        },
        "pearson_p_value": {
          "mean": 0.023454201688805174,
          "std": 0.022618760670174543
        }
      },
      "surprise": {
        "accuracy": {
          "mean": 0.40284495021337136,
          "std": 0.05583210263563772
        },
        "tolerance1_accuracy": {
          "mean": 0.9354196301564723,
          "std": 0.021770840932812504
        },
        "tolerance2_accuracy": {
          "mean": 0.9945945945945945,
          "std": 0.010810810810810789
        },
        "rmse": {
          "mean": 0.9011689579085937,
          "std": 0.07627382018870008
        },
        "kappa": {
          "mean": 0.14889305340975328,
          "std": 0.05317272557413778
        },
        "weighted_kappa": {
          "mean": 0.3942243588090277,
          "std": 0.06362307460097527
        },
        "pearson_correlation": {
          "mean": 0.4301527637516772,
          "std": 0.061190158754200336
        },
        "pearson_p_value": {
          "mean": 0.013951050534737325,
          "std": 0.01510799841878853
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7105263157894737,
        "precision": 0.6932773109243697,
        "recall": 0.7211538461538461,
        "f1": 0.6933235509904623
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.47368421052631576,
          "tolerance1_accuracy": 0.9473684210526315,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8271701918685112,
          "kappa": 0.22920892494929002,
          "weighted_kappa": 0.39312039312039315,
          "pearson_correlation": 0.43010752688172044,
          "pearson_p_value": 0.007033990477368373
        },
        "curiosity": {
          "accuracy": 0.47368421052631576,
          "tolerance1_accuracy": 0.7894736842105263,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0760551736979407,
          "kappa": 0.24901185770751,
          "weighted_kappa": 0.3044925124792013,
          "pearson_correlation": 0.33622441003330117,
          "pearson_p_value": 0.03902653170406176
        },
        "surprise": {
          "accuracy": 0.47368421052631576,
          "tolerance1_accuracy": 0.9473684210526315,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8271701918685112,
          "kappa": 0.2284263959390862,
          "weighted_kappa": 0.48488008342022937,
          "pearson_correlation": 0.5036690259734471,
          "pearson_p_value": 0.001265597847097275
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "precision": 0.7204968944099379,
        "recall": 0.7482517482517483,
        "f1": 0.7281632653061225
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.24324324324324326,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0,
          "kappa": 0.018009478672985746,
          "weighted_kappa": 0.4008752735229759,
          "pearson_correlation": 0.4243907388060103,
          "pearson_p_value": 0.008847071325913365
        },
        "curiosity": {
          "accuracy": 0.4864864864864865,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9586025865388216,
          "kappa": 0.2891809908998988,
          "weighted_kappa": 0.43333333333333335,
          "pearson_correlation": 0.4823136822600392,
          "pearson_p_value": 0.0025023944669010324
        },
        "surprise": {
          "accuracy": 0.32432432432432434,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9153348228041135,
          "kappa": 0.1071428571428571,
          "weighted_kappa": 0.4262131065532767,
          "pearson_correlation": 0.47523810293397856,
          "pearson_p_value": 0.0029545066801374047
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7567567567567568,
        "precision": 0.7573529411764706,
        "recall": 0.7558479532163742,
        "f1": 0.756043956043956
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9153348228041135,
          "kappa": 0.2335216572504708,
          "weighted_kappa": 0.5376864167674326,
          "pearson_correlation": 0.6243359098260455,
          "pearson_p_value": 3.6339952849636154e-05
        },
        "curiosity": {
          "accuracy": 0.40540540540540543,
          "tolerance1_accuracy": 0.8378378378378378,
          "tolerance2_accuracy": 1.0,
          "rmse": 1.0397504898200727,
          "kappa": 0.1810865191146881,
          "weighted_kappa": 0.46953405017921157,
          "pearson_correlation": 0.5036554565203675,
          "pearson_p_value": 0.0014836330955734906
        },
        "surprise": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 0.972972972972973,
          "rmse": 1.0397504898200727,
          "kappa": 0.1785714285714286,
          "weighted_kappa": 0.4041867954911432,
          "pearson_correlation": 0.4511769487746906,
          "pearson_p_value": 0.005067115839659047
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8108108108108109,
        "precision": 0.8070175438596491,
        "recall": 0.8365384615384616,
        "f1": 0.805701425356339
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.35135135135135137,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9004503377814963,
          "kappa": -0.041031652989449,
          "weighted_kappa": 0.2215988779803647,
          "pearson_correlation": 0.2604977629156744,
          "pearson_p_value": 0.11942701641014446
        },
        "curiosity": {
          "accuracy": 0.4594594594594595,
          "tolerance1_accuracy": 0.8918918918918919,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9299811099505543,
          "kappa": 0.19565217391304357,
          "weighted_kappa": 0.3940634595701126,
          "pearson_correlation": 0.3985772074635513,
          "pearson_p_value": 0.01454773220706602
        },
        "surprise": {
          "accuracy": 0.3783783783783784,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8853156407653622,
          "kappa": 0.07700650759219085,
          "weighted_kappa": 0.29546946815495734,
          "pearson_correlation": 0.3369502088474949,
          "pearson_p_value": 0.04141925553686081
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "precision": 0.7651515151515151,
        "recall": 0.780448717948718,
        "f1": 0.7701863354037266
      },
      "rating_metrics": {
        "suspense": {
          "accuracy": 0.43243243243243246,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8542421961772491,
          "kappa": 0.12401352874859084,
          "weighted_kappa": 0.3162217659137576,
          "pearson_correlation": 0.38878532532468,
          "pearson_p_value": 0.017400847763296867
        },
        "curiosity": {
          "accuracy": 0.43243243243243246,
          "tolerance1_accuracy": 0.8648648648648649,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.9863939238321437,
          "kappa": 0.15081967213114744,
          "weighted_kappa": 0.305526590198123,
          "pearson_correlation": 0.3124740105657008,
          "pearson_p_value": 0.05971071697042357
        },
        "surprise": {
          "accuracy": 0.4594594594594595,
          "tolerance1_accuracy": 0.9459459459459459,
          "tolerance2_accuracy": 1.0,
          "rmse": 0.8382736442849094,
          "kappa": 0.1533180778032036,
          "weighted_kappa": 0.3603723404255319,
          "pearson_correlation": 0.3837295322287749,
          "pearson_p_value": 0.0190487767699321
        }
      }
    }
  ]
}