{
  "average_metrics": {
    "story_classification": {
      "accuracy": {
        "mean": 0.7852062588904694,
        "std": 0.03198513643824796
      },
      "micro_precision": {
        "mean": 0.7852062588904694,
        "std": 0.03198513643824796
      },
      "micro_recall": {
        "mean": 0.7852062588904694,
        "std": 0.03198513643824796
      },
      "micro_f1": {
        "mean": 0.7852062588904694,
        "std": 0.03198513643824796
      },
      "macro_precision": {
        "mean": 0.7677111124169949,
        "std": 0.03874807900744299
      },
      "macro_recall": {
        "mean": 0.7855702776755409,
        "std": 0.038890111524130605
      },
      "macro_f1": {
        "mean": 0.7709905392987235,
        "std": 0.03749212212320451
      },
      "mcc": {
        "mean": 0.5528459195687507,
        "std": 0.07668706925818343
      }
    },
    "rating_metrics": {
      "suspense": {
        "perfect_accuracy": {
          "mean": 0.3762446657183499,
          "std": 0.036929601666421535
        },
        "off_by_one_accuracy": {
          "mean": 0.957041251778094,
          "std": 0.027456349055919854
        },
        "rmse": {
          "mean": 0.8660189562589073,
          "std": 0.05140764872663394
        },
        "mae": {
          "mean": 0.6667140825035561,
          "std": 0.046629419626851513
        },
        "quadratic_weighted_kappa": {
          "mean": 0.4035912578765103,
          "std": 0.1257660276936903
        }
      },
      "curiosity": {
        "perfect_accuracy": {
          "mean": 0.4623044096728308,
          "std": 0.04558139421563652
        },
        "off_by_one_accuracy": {
          "mean": 0.8603129445234708,
          "std": 0.019366568904827904
        },
        "rmse": {
          "mean": 0.9768635179407882,
          "std": 0.04994420960535975
        },
        "mae": {
          "mean": 0.6773826458036984,
          "std": 0.061725586069749254
        },
        "quadratic_weighted_kappa": {
          "mean": 0.43649800515400994,
          "std": 0.047015638410677615
        }
      },
      "surprise": {
        "perfect_accuracy": {
          "mean": 0.3812233285917497,
          "std": 0.055887162465283295
        },
        "off_by_one_accuracy": {
          "mean": 0.9354196301564721,
          "std": 0.0367494454764341
        },
        "rmse": {
          "mean": 0.9249602002921826,
          "std": 0.10497839238783045
        },
        "mae": {
          "mean": 0.6941678520625889,
          "std": 0.06780298883535125
        },
        "quadratic_weighted_kappa": {
          "mean": 0.3531876716781022,
          "std": 0.10875709641714632
        }
      }
    }
  },
  "fold_metrics": [
    {
      "story_classification": {
        "accuracy": 0.7368421052631579,
        "micro_precision": 0.7368421052631579,
        "micro_recall": 0.7368421052631579,
        "micro_f1": 0.7368421052631579,
        "macro_precision": 0.7130681818181819,
        "macro_recall": 0.7403846153846154,
        "macro_f1": 0.7172619047619048,
        "mcc": 0.45262926523618835
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.39473684210526316,
          "off_by_one_accuracy": 0.9473684210526315,
          "rmse": 0.8735890880367281,
          "mae": 0.6578947368421053,
          "quadratic_weighted_kappa": 0.31382316313823166
        },
        "curiosity": {
          "perfect_accuracy": 0.47368421052631576,
          "off_by_one_accuracy": 0.8421052631578947,
          "rmse": 1.0,
          "mae": 0.6842105263157895,
          "quadratic_weighted_kappa": 0.41013071895424835
        },
        "surprise": {
          "perfect_accuracy": 0.47368421052631576,
          "off_by_one_accuracy": 0.9473684210526315,
          "rmse": 0.8271701918685112,
          "mae": 0.5789473684210527,
          "quadratic_weighted_kappa": 0.4670981661272924
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7451923076923077,
        "macro_recall": 0.7674825174825175,
        "macro_f1": 0.7533333333333334,
        "mcc": 0.5121900261773418
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.918918918918919,
          "rmse": 0.9586025865388216,
          "mae": 0.7567567567567568,
          "quadratic_weighted_kappa": 0.4408888888888889
        },
        "curiosity": {
          "perfect_accuracy": 0.4864864864864865,
          "off_by_one_accuracy": 0.8648648648648649,
          "rmse": 0.9586025865388216,
          "mae": 0.6486486486486487,
          "quadratic_weighted_kappa": 0.5142857142857142
        },
        "surprise": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.9459459459459459,
          "rmse": 0.8853156407653622,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.4858648778150455
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7872023809523809,
        "macro_recall": 0.7821637426900585,
        "macro_f1": 0.7823529411764706,
        "mcc": 0.5693438283463509
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.35135135135135137,
          "off_by_one_accuracy": 1.0,
          "rmse": 0.8053872662568292,
          "mae": 0.6486486486486487,
          "quadratic_weighted_kappa": 0.6342668863261944
        },
        "curiosity": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.8378378378378378,
          "rmse": 1.0526671402243484,
          "mae": 0.7837837837837838,
          "quadratic_weighted_kappa": 0.4358497582744515
        },
        "surprise": {
          "perfect_accuracy": 0.40540540540540543,
          "off_by_one_accuracy": 0.8648648648648649,
          "rmse": 1.1270626736212455,
          "mae": 0.7837837837837838,
          "quadratic_weighted_kappa": 0.28875255623721885
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.8378378378378378,
        "micro_precision": 0.8378378378378378,
        "micro_recall": 0.8378378378378378,
        "micro_f1": 0.8378378378378378,
        "macro_precision": 0.8279411764705882,
        "macro_recall": 0.8573717948717949,
        "macro_f1": 0.8318181818181818,
        "mcc": 0.6846807339122728
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.43243243243243246,
          "off_by_one_accuracy": 0.9459459459459459,
          "rmse": 0.8542421961772491,
          "mae": 0.6216216216216216,
          "quadratic_weighted_kappa": 0.297962052002811
        },
        "curiosity": {
          "perfect_accuracy": 0.5135135135135135,
          "off_by_one_accuracy": 0.8918918918918919,
          "rmse": 0.9004503377814963,
          "mae": 0.5945945945945946,
          "quadratic_weighted_kappa": 0.4499504459861249
        },
        "surprise": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.972972972972973,
          "rmse": 0.86991767240168,
          "mae": 0.7027027027027027,
          "quadratic_weighted_kappa": 0.32464146023468066
        }
      }
    },
    {
      "story_classification": {
        "accuracy": 0.7837837837837838,
        "micro_precision": 0.7837837837837838,
        "micro_recall": 0.7837837837837838,
        "micro_f1": 0.7837837837837838,
        "macro_precision": 0.7651515151515151,
        "macro_recall": 0.780448717948718,
        "macro_f1": 0.7701863354037266,
        "mcc": 0.5453857441716
      },
      "rating_metrics": {
        "suspense": {
          "perfect_accuracy": 0.3783783783783784,
          "off_by_one_accuracy": 0.972972972972973,
          "rmse": 0.8382736442849094,
          "mae": 0.6486486486486487,
          "quadratic_weighted_kappa": 0.3310152990264257
        },
        "curiosity": {
          "perfect_accuracy": 0.4594594594594595,
          "off_by_one_accuracy": 0.8648648648648649,
          "rmse": 0.9725975251592747,
          "mae": 0.6756756756756757,
          "quadratic_weighted_kappa": 0.3722733882695104
        },
        "surprise": {
          "perfect_accuracy": 0.32432432432432434,
          "off_by_one_accuracy": 0.9459459459459459,
          "rmse": 0.9153348228041135,
          "mae": 0.7297297297297297,
          "quadratic_weighted_kappa": 0.19958129797627344
        }
      }
    }
  ]
}